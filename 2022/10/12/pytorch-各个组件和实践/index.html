<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ - ğŸ&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="ğŸ&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="ğŸ&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="æœ¬ç« ä»‹ç»pytorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„å„ä¸ªç»„ä»¶å’Œå®è·µï¼Œå±‚å±‚æ­å»ºç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶        æ•°æ®é¢„å¤„ç†å®Œæˆä¸€é¡¹æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶çš„æ­¥éª¤ï¼Œé¦–å…ˆéœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå…¶ä¸­é‡è¦çš„æ­¥éª¤åŒ…æ‹¬æ•°æ®æ ¼å¼çš„ç»Ÿä¸€å’Œå¿…è¦çš„æ•°æ®å˜æ¢ï¼ŒåŒæ—¶åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ æ¨¡å‹è®¾è®¡é€‰æ‹©æ¨¡å‹ã€‚ æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡è®¾å®šæŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ï¼Œä»¥åŠå¯¹åº”çš„è¶…å‚æ•°ï¼ˆå½“ç„¶å¯ä»¥ä½¿ç”¨sklearnè¿™æ ·çš„æœºå™¨å­¦ä¹ åº“ä¸­æ¨¡å‹è‡ªå¸¦çš„æŸå¤±"><meta property="og:type" content="blog"><meta property="og:title" content="pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ"><meta property="og:url" content="http://example.com/2022/10/12/pytorch-%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E5%92%8C%E5%AE%9E%E8%B7%B5/"><meta property="og:site_name" content="ğŸ&#039;s Blog"><meta property="og:description" content="æœ¬ç« ä»‹ç»pytorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„å„ä¸ªç»„ä»¶å’Œå®è·µï¼Œå±‚å±‚æ­å»ºç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶        æ•°æ®é¢„å¤„ç†å®Œæˆä¸€é¡¹æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶çš„æ­¥éª¤ï¼Œé¦–å…ˆéœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå…¶ä¸­é‡è¦çš„æ­¥éª¤åŒ…æ‹¬æ•°æ®æ ¼å¼çš„ç»Ÿä¸€å’Œå¿…è¦çš„æ•°æ®å˜æ¢ï¼ŒåŒæ—¶åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ æ¨¡å‹è®¾è®¡é€‰æ‹©æ¨¡å‹ã€‚ æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡è®¾å®šæŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ï¼Œä»¥åŠå¯¹åº”çš„è¶…å‚æ•°ï¼ˆå½“ç„¶å¯ä»¥ä½¿ç”¨sklearnè¿™æ ·çš„æœºå™¨å­¦ä¹ åº“ä¸­æ¨¡å‹è‡ªå¸¦çš„æŸå¤±"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665563909211/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665566323623/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://datawhalechina.github.io/thorough-pytorch/_images/3.4.1.png"><meta property="og:image" content="https://datawhalechina.github.io/thorough-pytorch/_images/3.4.2.png"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665580819001/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665580768639/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://datawhalechina.github.io/thorough-pytorch/_images/3.5.2.png"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582006862/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582222120/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582284050/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582351089/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="og:image" content="https://datawhalechina.github.io/thorough-pytorch/_images/3.6.1.png"><meta property="og:image" content="https://datawhalechina.github.io/thorough-pytorch/_images/3.6.2.png"><meta property="og:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665568130565/D2B5CA33BD970F64A6301FA75AE2EB22"><meta property="article:published_time" content="2022-10-12T06:43:54.000Z"><meta property="article:modified_time" content="2022-10-12T15:33:48.906Z"><meta property="article:author" content="Yang"><meta property="article:tag" content="Pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665563909211/D2B5CA33BD970F64A6301FA75AE2EB22"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2022/10/12/pytorch-%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E5%92%8C%E5%AE%9E%E8%B7%B5/"},"headline":"pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ","image":["https://datawhalechina.github.io/thorough-pytorch/_images/3.4.1.png","https://datawhalechina.github.io/thorough-pytorch/_images/3.4.2.png","https://datawhalechina.github.io/thorough-pytorch/_images/3.5.2.png","https://datawhalechina.github.io/thorough-pytorch/_images/3.6.1.png","https://datawhalechina.github.io/thorough-pytorch/_images/3.6.2.png"],"datePublished":"2022-10-12T06:43:54.000Z","dateModified":"2022-10-12T15:33:48.906Z","author":{"@type":"Person","name":"Yang"},"publisher":{"@type":"Organization","name":"ğŸ's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"æœ¬ç« ä»‹ç»pytorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„å„ä¸ªç»„ä»¶å’Œå®è·µï¼Œå±‚å±‚æ­å»ºç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶        æ•°æ®é¢„å¤„ç†å®Œæˆä¸€é¡¹æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶çš„æ­¥éª¤ï¼Œé¦–å…ˆéœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå…¶ä¸­é‡è¦çš„æ­¥éª¤åŒ…æ‹¬æ•°æ®æ ¼å¼çš„ç»Ÿä¸€å’Œå¿…è¦çš„æ•°æ®å˜æ¢ï¼ŒåŒæ—¶åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ æ¨¡å‹è®¾è®¡é€‰æ‹©æ¨¡å‹ã€‚ æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡è®¾å®šæŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ï¼Œä»¥åŠå¯¹åº”çš„è¶…å‚æ•°ï¼ˆå½“ç„¶å¯ä»¥ä½¿ç”¨sklearnè¿™æ ·çš„æœºå™¨å­¦ä¹ åº“ä¸­æ¨¡å‹è‡ªå¸¦çš„æŸå¤±"}</script><link rel="canonical" href="http://example.com/2022/10/12/pytorch-%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E5%92%8C%E5%AE%9E%E8%B7%B5/"><link rel="icon" href="/img/logo.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="ğŸ&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">ä¸»é¡µ</a><a class="navbar-item" href="/archives">å½’æ¡£</a><a class="navbar-item" href="/categories">åˆ†ç±»</a><a class="navbar-item" href="/tags">æ ‡ç­¾</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Yang-Emily/Yang-Emily.github.io"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="ç›®å½•" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="æœç´¢" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-12T06:43:54.000Z" title="2022/10/12 ä¸‹åˆ2:43:54">2022-10-12</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-12T15:33:48.906Z" title="2022/10/12 ä¸‹åˆ11:33:48">2022-10-12</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">1 å°æ—¶è¯»å®Œ (å¤§çº¦11579ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile">pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ</h1><div class="content"><p>æœ¬ç« ä»‹ç»pytorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„å„ä¸ªç»„ä»¶å’Œå®è·µï¼Œå±‚å±‚æ­å»ºç¥ç»ç½‘ç»œæ¨¡å‹ã€‚</p>
<h1 id="ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶"><a href="#ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶" class="headerlink" title="ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶"></a>ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶</h1><center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665563909211/D2B5CA33BD970F64A6301FA75AE2EB22" width="250">  
</center>

<ul>
<li>æ•°æ®é¢„å¤„ç†<br>å®Œæˆä¸€é¡¹æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶çš„æ­¥éª¤ï¼Œé¦–å…ˆéœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå…¶ä¸­é‡è¦çš„æ­¥éª¤åŒ…æ‹¬æ•°æ®æ ¼å¼çš„ç»Ÿä¸€å’Œå¿…è¦çš„æ•°æ®å˜æ¢ï¼ŒåŒæ—¶åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚</li>
<li>æ¨¡å‹è®¾è®¡<br>é€‰æ‹©æ¨¡å‹ã€‚</li>
<li>æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡<br>è®¾å®šæŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ï¼Œä»¥åŠå¯¹åº”çš„è¶…å‚æ•°ï¼ˆå½“ç„¶å¯ä»¥ä½¿ç”¨sklearnè¿™æ ·çš„æœºå™¨å­¦ä¹ åº“ä¸­æ¨¡å‹è‡ªå¸¦çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼‰ã€‚</li>
<li>å‰å‘ä¼ æ’­<br>ç”¨æ¨¡å‹å»æ‹Ÿåˆè®­ç»ƒé›†æ•°æ®ï¼Œ</li>
<li>åå‘ä¼ æ’­</li>
<li>æ›´æ–°å‚æ•°</li>
<li>æ¨¡å‹è¡¨ç°<br>åœ¨éªŒè¯é›†&#x2F;æµ‹è¯•é›†ä¸Šè®¡ç®—æ¨¡å‹è¡¨ç°ã€‚</li>
</ul>
<h1 id="æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§"><a href="#æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§" class="headerlink" title="æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§"></a>æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§</h1><ul>
<li>æ ·æœ¬é‡å¤§ï¼Œéœ€è¦åˆ†æ‰¹åŠ è½½<br>ç”±äºæ·±åº¦å­¦ä¹ æ‰€éœ€çš„æ ·æœ¬é‡å¾ˆå¤§ï¼Œä¸€æ¬¡åŠ è½½å…¨éƒ¨æ•°æ®è¿è¡Œå¯èƒ½ä¼šè¶…å‡ºå†…å­˜å®¹é‡è€Œæ— æ³•å®ç°ï¼›åŒæ—¶è¿˜æœ‰æ‰¹ï¼ˆbatchï¼‰è®­ç»ƒç­‰æé«˜æ¨¡å‹è¡¨ç°çš„ç­–ç•¥ï¼Œéœ€è¦æ¯æ¬¡è®­ç»ƒè¯»å–å›ºå®šæ•°é‡çš„æ ·æœ¬é€å…¥æ¨¡å‹ä¸­è®­ç»ƒã€‚</li>
<li>é€å±‚ã€æ¨¡å—åŒ–æ­å»ºç½‘ç»œï¼ˆå·ç§¯å±‚ã€å…¨è¿æ¥å±‚ã€LSTMç­‰ï¼‰<br>æ·±åº¦ç¥ç»ç½‘ç»œå¾€å¾€éœ€è¦â€œé€å±‚â€æ­å»ºï¼Œæˆ–è€…é¢„å…ˆå®šä¹‰å¥½å¯ä»¥å®ç°ç‰¹å®šåŠŸèƒ½çš„æ¨¡å—ï¼Œå†æŠŠè¿™äº›æ¨¡å—ç»„è£…èµ·æ¥ã€‚</li>
<li>å¤šæ ·åŒ–çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨è®¾è®¡<br>ç”±äºæ¨¡å‹è®¾å®šçš„çµæ´»æ€§ï¼Œå› æ­¤æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨è¦èƒ½å¤Ÿä¿è¯åå‘ä¼ æ’­èƒ½å¤Ÿåœ¨ç”¨æˆ·è‡ªè¡Œå®šä¹‰çš„æ¨¡å‹ç»“æ„ä¸Šå®ç°</li>
<li>GPUçš„ä½¿ç”¨<br>éœ€è¦æŠŠæ¨¡å‹å’Œæ•°æ®â€œæ”¾åˆ°â€GPUä¸Šå»åšè¿ç®—ï¼ŒåŒæ—¶è¿˜éœ€è¦ä¿è¯æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨èƒ½å¤Ÿåœ¨GPUä¸Šå·¥ä½œã€‚å¦‚æœä½¿ç”¨å¤šå¼ GPUè¿›è¡Œè®­ç»ƒï¼Œè¿˜éœ€è¦è€ƒè™‘æ¨¡å‹å’Œæ•°æ®åˆ†é…ã€æ•´åˆçš„é—®é¢˜ã€‚</li>
<li>å„ä¸ªæ¨¡å—ä¹‹é—´çš„é…åˆ<br>æ·±åº¦å­¦ä¹ ä¸­è®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹æœ€å¤§çš„ç‰¹ç‚¹åœ¨äºè¯»å…¥æ•°æ®æ˜¯æŒ‰æ‰¹çš„ï¼Œæ¯æ¬¡è¯»å…¥ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œæ”¾å…¥GPUä¸­è®­ç»ƒï¼Œç„¶åå°†æŸå¤±å‡½æ•°åå‘ä¼ æ’­å›ç½‘ç»œæœ€å‰é¢çš„å±‚ï¼ŒåŒæ—¶ä½¿ç”¨ä¼˜åŒ–å™¨è°ƒæ•´ç½‘ç»œå‚æ•°ã€‚è¿™é‡Œä¼šæ¶‰åŠåˆ°å„ä¸ªæ¨¡å—é…åˆçš„é—®é¢˜ã€‚è®­ç»ƒ&#x2F;éªŒè¯åè¿˜éœ€è¦æ ¹æ®è®¾å®šå¥½çš„æŒ‡æ ‡è®¡ç®—æ¨¡å‹è¡¨ç°ã€‚</li>
</ul>
<h1 id="pytorchæ·±åº¦å­¦ä¹ æ¨¡å—"><a href="#pytorchæ·±åº¦å­¦ä¹ æ¨¡å—" class="headerlink" title="pytorchæ·±åº¦å­¦ä¹ æ¨¡å—"></a>pytorchæ·±åº¦å­¦ä¹ æ¨¡å—</h1><p>å°†PyTorchå®Œæˆæ·±åº¦å­¦ä¹ çš„æ­¥éª¤æ‹†è§£ä¸ºå‡ ä¸ªä¸»è¦æ¨¡å—ï¼Œå®é™…ä½¿ç”¨æ ¹æ®è‡ªèº«éœ€æ±‚ä¿®æ”¹å¯¹åº”æ¨¡å—å³å¯ï¼Œæ·±åº¦å­¦ä¹ -&gt;æ­ç§¯æœ¨ã€‚</p>
<h2 id="ä¸€ã€-åŸºæœ¬é…ç½®"><a href="#ä¸€ã€-åŸºæœ¬é…ç½®" class="headerlink" title="ä¸€ã€ åŸºæœ¬é…ç½®"></a>ä¸€ã€ åŸºæœ¬é…ç½®</h2><p>é¦–å…ˆå¯¼å…¥å¿…è¦çš„åŒ…</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optimizer</span><br></pre></td></tr></table></figure>
<p>é…ç½®è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é…ç½®GPUï¼Œè¿™é‡Œæœ‰ä¸¤ç§æ–¹å¼</span></span><br><span class="line"><span class="comment">## æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨os.environï¼Œåç»­ç”¨.cuda()</span></span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line"><span class="comment"># æ–¹æ¡ˆäºŒï¼šä½¿ç”¨â€œdeviceâ€ï¼Œåç»­å¯¹è¦ä½¿ç”¨GPUçš„å˜é‡ç”¨.to(device)å³å¯</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:1&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## é…ç½®å…¶ä»–è¶…å‚æ•°ï¼Œå¦‚batch_size, num_workers, learning rate, ä»¥åŠæ€»çš„epochs</span></span><br><span class="line">batch_size = <span class="number">256</span> <span class="comment"># æ¯æ¬¡è®­ç»ƒè¯»å…¥çš„æ•°æ®é‡</span></span><br><span class="line">num_workers = <span class="number">4</span>   <span class="comment"># æœ‰å¤šå°‘çº¿ç¨‹æ¥è¯»å…¥æ•°æ®ï¼Œå¯¹äºWindowsç”¨æˆ·ï¼Œè¿™é‡Œåº”è®¾ç½®ä¸º0ï¼Œå¦åˆ™ä¼šå‡ºç°å¤šçº¿ç¨‹é”™è¯¯</span></span><br><span class="line">lr = <span class="number">1e-4</span> <span class="comment"># å‚æ•°æ›´æ–°çš„æ­¥é•¿</span></span><br><span class="line">epochs = <span class="number">20</span> <span class="comment"># è®­ç»ƒå¤šå°‘è½®</span></span><br></pre></td></tr></table></figure>
<h2 id="äºŒã€-æ•°æ®è¯»å…¥"><a href="#äºŒã€-æ•°æ®è¯»å…¥" class="headerlink" title="äºŒã€ æ•°æ®è¯»å…¥"></a>äºŒã€ æ•°æ®è¯»å…¥</h2><p>æœ‰ä¸¤ç§æ–¹å¼ï¼š</p>
<ul>
<li>ä¸‹è½½å¹¶ä½¿ç”¨PyTorchæä¾›çš„å†…ç½®æ•°æ®é›†<br>åªé€‚ç”¨äºå¸¸è§çš„æ•°æ®é›†ï¼Œå¦‚MNISTï¼ŒCIFAR10ç­‰ï¼ŒPyTorchå®˜æ–¹æä¾›äº†æ•°æ®ä¸‹è½½ã€‚è¿™ç§æ–¹å¼å¾€å¾€é€‚ç”¨äºå¿«é€Ÿæµ‹è¯•æ–¹æ³•ï¼ˆæ¯”å¦‚æµ‹è¯•ä¸‹æŸä¸ªideaåœ¨MNISTæ•°æ®é›†ä¸Šæ˜¯å¦æœ‰æ•ˆï¼‰<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é¦–å…ˆè®¾ç½®æ•°æ®å˜æ¢</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">28</span> </span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),   <span class="comment"># è¿™ä¸€æ­¥å–å†³äºåç»­çš„æ•°æ®è¯»å–æ–¹å¼ï¼Œå¦‚æœä½¿ç”¨å†…ç½®æ•°æ®é›†åˆ™ä¸éœ€è¦</span></span><br><span class="line">    transforms.Resize(image_size),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## è¯»å–æ–¹å¼ä¸€ï¼šä½¿ç”¨torchvisionè‡ªå¸¦æ•°æ®é›†ï¼Œä¸‹è½½å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">train_data = datasets.FashionMNIST(root=<span class="string">&#x27;./&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=data_transform)</span><br><span class="line">test_data = datasets.FashionMNIST(root=<span class="string">&#x27;./&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=data_transform)</span><br></pre></td></tr></table></figure></li>
<li>ä»ç½‘ç«™ä¸‹è½½ä»¥csvæ ¼å¼å­˜å‚¨çš„æ•°æ®ï¼Œè¯»å…¥å¹¶è½¬æˆé¢„æœŸçš„æ ¼å¼<br>éœ€è¦è‡ªå·±æ„å»ºDatasetï¼Œè¿™å¯¹äºPyTorchåº”ç”¨äºè‡ªå·±çš„å·¥ä½œä¸­ååˆ†é‡è¦,åŒæ—¶ï¼Œè¿˜éœ€è¦å¯¹æ•°æ®è¿›è¡Œå¿…è¦çš„å˜æ¢ï¼Œæ¯”å¦‚è¯´éœ€è¦å°†å›¾ç‰‡ç»Ÿä¸€ä¸ºä¸€è‡´çš„å¤§å°ï¼Œä»¥ä¾¿åç»­èƒ½å¤Ÿè¾“å…¥ç½‘ç»œè®­ç»ƒï¼›éœ€è¦å°†æ•°æ®æ ¼å¼è½¬ä¸ºTensorç±»ï¼Œç­‰ç­‰ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## è¯»å–æ–¹å¼äºŒï¼šè¯»å…¥csvæ ¼å¼çš„æ•°æ®ï¼Œè‡ªè¡Œæ„å»ºDatasetç±»</span></span><br><span class="line"><span class="comment"># csvæ•°æ®ä¸‹è½½é“¾æ¥ï¼šhttps://www.kaggle.com/zalando-research/fashionmnist</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FMDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, df, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.df = df</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.images = df.iloc[:,<span class="number">1</span>:].values.astype(np.uint8)</span><br><span class="line">        self.labels = df.iloc[:, <span class="number">0</span>].values</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        image = self.images[idx].reshape(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>) <span class="comment"># 1æ˜¯å•ä¸€é€šé“</span></span><br><span class="line">        label = <span class="built_in">int</span>(self.labels[idx])</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image = torch.tensor(image/<span class="number">255.</span>, dtype=torch.<span class="built_in">float</span>) <span class="comment"># image/255 æŠŠæ•°å€¼å½’ä¸€åŒ–</span></span><br><span class="line">        label = torch.tensor(label, dtype=torch.long)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">&quot;./fashion-mnist_train.csv&quot;</span>)</span><br><span class="line">test_df = pd.read_csv(<span class="string">&quot;./fashion-mnist_test.csv&quot;</span>)</span><br><span class="line">train_data = FMDataset(train_df, data_transform)</span><br><span class="line">test_data = FMDataset(test_df, data_transform)</span><br></pre></td></tr></table></figure>
PyTorchæ•°æ®è¯»å…¥æ˜¯é€šè¿‡Dataset+DataLoaderçš„æ–¹å¼å®Œæˆçš„ï¼ŒDatasetå®šä¹‰å¥½æ•°æ®çš„æ ¼å¼å’Œæ•°æ®å˜æ¢å½¢å¼ï¼ŒDataLoaderç”¨iterativeçš„æ–¹å¼ä¸æ–­è¯»å…¥æ‰¹æ¬¡æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„Datasetç±»æ¥å®ç°çµæ´»çš„æ•°æ®è¯»å–ï¼Œå®šä¹‰çš„ç±»éœ€è¦ç»§æ‰¿PyTorchè‡ªèº«çš„Datasetç±»ã€‚ä¸»è¦åŒ…å«ä¸‰ä¸ªå‡½æ•°ï¼š</li>
<li>_<em>init</em>_: ç”¨äºå‘ç±»ä¸­ä¼ å…¥å¤–éƒ¨å‚æ•°ï¼ŒåŒæ—¶å®šä¹‰æ ·æœ¬é›†</li>
<li>_<em>getitem</em>_: ç”¨äºé€ä¸ªè¯»å–æ ·æœ¬é›†åˆä¸­çš„å…ƒç´ ï¼Œå¯ä»¥è¿›è¡Œä¸€å®šçš„å˜æ¢ï¼Œå¹¶å°†è¿”å›è®­ç»ƒ&#x2F;éªŒè¯æ‰€éœ€çš„æ•°æ®</li>
<li>_<em>len</em>_: ç”¨äºè¿”å›æ•°æ®é›†çš„æ ·æœ¬æ•°<br>åœ¨æ„å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†å®Œæˆåï¼Œéœ€è¦å®šä¹‰DataLoaderç±»ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶åŠ è½½æ•°æ®:<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers, drop_last=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure>
è¯»å…¥åï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€äº›æ•°æ®å¯è§†åŒ–æ“ä½œï¼Œä¸»è¦æ˜¯éªŒè¯æˆ‘ä»¬è¯»å…¥çš„æ•°æ®æ˜¯å¦æ­£ç¡®:<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image, label = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="built_in">print</span>(image.shape, label.shape)</span><br><span class="line">plt.imshow(image[<span class="number">0</span>][<span class="number">0</span>], cmap=<span class="string">&quot;gray&quot;</span>)</span><br></pre></td></tr></table></figure>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665566323623/D2B5CA33BD970F64A6301FA75AE2EB22" width="250">  
</center></li>
</ul>
<h2 id="ä¸‰ã€-æ¨¡å‹æ„å»º"><a href="#ä¸‰ã€-æ¨¡å‹æ„å»º" class="headerlink" title="ä¸‰ã€ æ¨¡å‹æ„å»º"></a>ä¸‰ã€ æ¨¡å‹æ„å»º</h2><p>æˆ‘ä»¬è¿™é‡Œçš„ä»»åŠ¡æ˜¯å¯¹10ä¸ªç±»åˆ«çš„â€œæ—¶è£…â€å›¾åƒè¿›è¡Œåˆ†ç±»ï¼ŒFashionMNISTæ•°æ®é›†ä¸­åŒ…å«å·²ç»é¢„å…ˆåˆ’åˆ†å¥½çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­è®­ç»ƒé›†å…±60,000å¼ å›¾åƒï¼Œæµ‹è¯•é›†å…±10,000å¼ å›¾åƒã€‚æ¯å¼ å›¾åƒå‡ä¸ºå•é€šé“é»‘ç™½å›¾åƒï¼Œå¤§å°ä¸º32*32pixelï¼Œåˆ†å±10ä¸ªç±»åˆ«ã€‚ç”±äºä»»åŠ¡è¾ƒä¸ºç®€å•ï¼Œè¿™é‡Œæˆ‘ä»¬<strong>æ‰‹æ­ä¸€ä¸ªCNN</strong>ï¼Œè€Œä¸è€ƒè™‘å½“ä¸‹å„ç§æ¨¡å‹çš„å¤æ‚ç»“æ„ï¼Œæ¨¡å‹æ„å»ºå®Œæˆåï¼Œå°†æ¨¡å‹æ”¾åˆ°GPUä¸Šç”¨äºè®­ç»ƒã€‚<br>Module ç±»æ˜¯nnæ¨¡å—ï§©æä¾›çš„ä¸€ä¸ªæ¨¡å‹æ„é€ ç±»ï¼Œæ˜¯æ‰€æœ‰ç¥ç»â½¹ç½‘ç»œæ¨¡å—çš„åŸºç±»ï¼Œæˆ‘ä»¬å¯ä»¥ç»§æ‰¿å®ƒæ¥å®šä¹‰æˆ‘ä»¬æƒ³è¦çš„æ¨¡å‹ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__() </span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="comment"># x = nn.functional.normalize(x)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">model = model.cuda()</span><br><span class="line"><span class="comment"># model = nn.DataParallel(model).cuda()   # å¤šå¡è®­ç»ƒæ—¶çš„å†™æ³•ï¼Œä¹‹åçš„è¯¾ç¨‹ä¸­ä¼šè¿›ä¸€æ­¥è®²è§£</span></span><br></pre></td></tr></table></figure>
<pre><code>torch.nn.Conv2d(
  in_channels, 
  out_channels, 
  kernel_size, 
  stride=1, 
  padding=0, 
  dilation=1, 
  groups=1, 
  bias=True, 
  padding_mode=&#39;zeros&#39;, 
  device=None, 
  dtype=None)

torch.nn.MaxPool2d(
  kernel_size, 
  stride=None, 
  padding=0, 
  dilation=1, 
  return_indices=False, 
  ceil_mode=False)
</code></pre>
<p>$d_{out} &#x3D;(d_{in}âˆ’dilationâˆ—(kernelsizeâˆ’1)âˆ’1+2âˆ—padding)&#x2F;stride+1)$<br><strong>ä¸‹é¢å†ä¸¾ä¸€ä¸ªå…¶ä»–æ¨¡å‹MLPï¼š</strong><br>ç»§æ‰¿Moduleç±»æ„é€ å¤šå±‚æ„ŸçŸ¥æœº,è¿™ï§©å®šä¹‰çš„MLPç±»é‡è½½ï¦ºModuleç±»çš„initå‡½æ•°å’Œforwardå‡½æ•°ã€‚å®ƒä»¬åˆ†åˆ«ç”¨äºåˆ›å»ºæ¨¡å‹å‚æ•°å’Œå®šä¹‰å‰å‘è®¡ç®—ã€‚å‰å‘è®¡ç®—ä¹Ÿå³æ­£å‘ä¼ æ’­ã€‚ç³»ç»Ÿå°†é€šè¿‡â¾ƒåŠ¨æ±‚æ¢¯åº¦â½½è‡ªåŠ¨â½£æˆåå‘ä¼ æ’­æ‰€éœ€çš„ backward å‡½æ•°ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="comment"># å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨MLPçˆ¶ç±»Blockçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°</span></span><br><span class="line">    <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line">    self.hidden = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">    self.act = nn.ReLU()</span><br><span class="line">    self.output = nn.Linear(<span class="number">256</span>,<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">   <span class="comment"># å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    o = self.act(self.hidden(x))</span><br><span class="line">    <span class="keyword">return</span> self.output(o)   </span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¯ä»¥å®ä¾‹åŒ– MLP ç±»å¾—åˆ°æ¨¡å‹å˜ï¥¾ net ã€‚ä¸‹â¾¯çš„ä»£ç åˆå§‹åŒ– net å¹¶ä¼ å…¥è¾“â¼Šæ•°æ® X åšä¸€æ¬¡å‰å‘è®¡ç®—ã€‚å…¶ä¸­ï¼Œ net(X) ä¼šè°ƒç”¨ MLP ç»§æ‰¿â¾ƒè‡ª Module ç±»çš„ call å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°å°†è°ƒâ½¤ç”¨ MLP ç±»å®šä¹‰çš„forward å‡½æ•°æ¥å®Œæˆå‰å‘è®¡ç®—ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(<span class="number">2</span>,<span class="number">784</span>)</span><br><span class="line">net = MLP()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„ï¼Œè¿™ï§©å¹¶æ²¡æœ‰å°† Module ç±»å‘½åä¸º Layer (å±‚)æˆ–è€… Model (æ¨¡å‹)ä¹‹ç±»çš„åå­—ï¼Œè¿™æ˜¯å› ä¸ºè¯¥ç±»æ˜¯ä¸€ä¸ªå¯ä¾›â¾ƒç”±ç»„å»ºçš„éƒ¨ä»¶ã€‚å®ƒçš„å­ç±»æ—¢å¯ä»¥æ˜¯â¼€ä¸ªå±‚(å¦‚PyTorchæä¾›çš„ Linear ç±»)ï¼Œâ¼œå¯ä»¥æ˜¯ä¸€ä¸ªæ¨¡å‹(å¦‚è¿™ï§©å®šä¹‰çš„ MLP ç±»)ï¼Œæˆ–è€…æ˜¯æ¨¡å‹çš„â¼€ä¸ªéƒ¨åˆ†ã€‚<br><strong>ä¸‹é¢ä»‹ç»ä¸€äº›ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„å±‚ï¼š</strong><br>æ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªé­…ï¦Šåœ¨äºç¥ç»ç½‘ç»œä¸­å„å¼å„æ ·çš„å±‚ï¼Œä¾‹å¦‚å…¨è¿æ¥å±‚ã€å·ç§¯å±‚ã€æ± åŒ–å±‚ä¸å¾ªç¯å±‚ç­‰ç­‰ã€‚è™½ç„¶PyTorchæä¾›äº†â¼¤ï¥¾å¸¸ç”¨çš„å±‚ï¼Œä½†æœ‰æ—¶å€™æˆ‘ä»¬ä¾ç„¶å¸Œæœ›â¾ƒå®šä¹‰å±‚ã€‚</p>
<ol>
<li>ä¸å«æ¨¡å‹å‚æ•°çš„å±‚<br>ä¸‹â¾¯æ„é€ çš„ <strong>MyLayer</strong> ç±»é€šè¿‡ç»§æ‰¿ Module ç±»è‡ªå®šä¹‰ï¦ºä¸€ä¸ªå°†è¾“å…¥å‡æ‰å‡å€¼åè¾“å‡ºçš„å±‚ï¼Œå¹¶å°†å±‚çš„è®¡ç®—å®šä¹‰åœ¨ï¦º forward å‡½æ•°ï§©ã€‚è¿™ä¸ªå±‚ï§©ï¥§å«æ¨¡å‹å‚æ•°ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyLayer, self).__init__(**kwargs)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x - x.mean()  </span><br><span class="line"><span class="comment"># æµ‹è¯•ï¼Œå®ä¾‹åŒ–è¯¥å±‚ï¼Œç„¶ååšå‰å‘è®¡ç®—        </span></span><br><span class="line">layer = MyLayer()</span><br><span class="line">layer(torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>))</span><br></pre></td></tr></table></figure></li>
<li>å«æ¨¡å‹å‚æ•°çš„å±‚<br>è‡ªå®šä¹‰å«æ¨¡å‹å‚æ•°çš„è‡ªå®šä¹‰å±‚ï¼Œå…¶ä¸­çš„æ¨¡å‹å‚æ•°å¯ä»¥é€šè¿‡è®­ç»ƒå­¦å‡ºã€‚<strong>Parameter</strong> ç±»å…¶å®æ˜¯ Tensor çš„å­ç±»ï¼Œå¦‚æœä¸€ä¸ª Tensor æ˜¯ Parameter ï¼Œé‚£ä¹ˆå®ƒä¼šâ¾ƒåŠ¨è¢«æ·»åŠ åˆ°æ¨¡å‹çš„å‚æ•°ï¦œè¡¨ï§©ã€‚æ‰€ä»¥åœ¨â¾ƒå®šä¹‰å«æ¨¡å‹å‚æ•°çš„å±‚æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å°†å‚æ•°å®šä¹‰æˆ Parameter ï¼Œé™¤äº†ç›´æ¥å®šä¹‰æˆ Parameter ç±»å¤–ï¼Œè¿˜å¯ä»¥ä½¿â½¤ <strong>ParameterList</strong> å’Œ <strong>ParameterDict</strong> åˆ†åˆ«å®šä¹‰å‚æ•°çš„ï¦œè¡¨å’Œå­—å…¸ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyListDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyListDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">        self.params.append(nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.params)):</span><br><span class="line">            x = torch.mm(x, self.params[i]) <span class="comment"># torch.mmçŸ©é˜µç›¸ä¹˜ï¼Œä¸¤ä¸ªäºŒç»´å¼ é‡ç›¸ä¹˜</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">net = MyListDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDictDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyDictDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">                <span class="string">&#x27;linear1&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">                <span class="string">&#x27;linear2&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">        &#125;)</span><br><span class="line">        self.params.update(&#123;<span class="string">&#x27;linear3&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">2</span>))&#125;) <span class="comment"># æ–°å¢</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice=<span class="string">&#x27;linear1&#x27;</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(x, self.params[choice])</span><br><span class="line"></span><br><span class="line">net = MyDictDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>
ä¸‹é¢ç»™å‡ºå¸¸è§çš„ç¥ç»ç½‘ç»œçš„ä¸€äº›å±‚ï¼Œæ¯”å¦‚å·ç§¯å±‚ã€æ± åŒ–å±‚ï¼Œä»¥åŠè¾ƒä¸ºåŸºç¡€çš„AlexNetï¼ŒLeNetç­‰ã€‚</li>
<li>äºŒç»´å·ç§¯å±‚<br>äºŒç»´å·ç§¯å±‚å°†è¾“å…¥å’Œ<strong>å·ç§¯æ ¸</strong>åšäº’ç›¸å…³è¿ç®—ï¼Œå¹¶åŠ ä¸Šä¸€ä¸ª<strong>æ ‡ï¥¾åå·®</strong>æ¥å¾—åˆ°è¾“å‡ºã€‚å·ç§¯å±‚çš„æ¨¡å‹å‚æ•°åŒ…æ‹¬ï¦ºå·ç§¯æ ¸å’Œæ ‡ï¥¾åå·®ã€‚åœ¨è®­ç»ƒæ¨¡å‹çš„æ—¶å€™ï¼Œé€šå¸¸æˆ‘ä»¬å…ˆå¯¹å·ç§¯æ ¸éšæœºåˆå§‹åŒ–ï¼Œç„¶åï¥§æ–­è¿­ä»£å·ç§¯æ ¸å’Œåå·®ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># å·ç§¯è¿ç®—ï¼ˆäºŒç»´äº’ç›¸å…³ï¼‰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span>(<span class="params">X, K</span>):</span> </span><br><span class="line">    h, w = K.shape</span><br><span class="line">    X, K = X.<span class="built_in">float</span>(), K.<span class="built_in">float</span>()</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i: i + h, j: j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># äºŒç»´å·ç§¯å±‚</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Conv2D, self).__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(kernel_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure>
ä¸‹é¢çš„ï¦µå­é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªâ¾¼å’Œå®½ä¸º3çš„äºŒç»´å·ç§¯å±‚ï¼Œç„¶åè®¾è¾“â¼Šé«˜å’Œå®½ä¸¤ä¾§çš„å¡«å……æ•°åˆ†åˆ«ä¸º1ã€‚ç»™å®šä¸€ä¸ªé«˜å’Œå®½ä¸º8çš„è¾“å…¥ï¼Œæˆ‘ä»¬å‘ç°è¾“å‡ºçš„é«˜å’Œå®½ä¹Ÿæ˜¯8ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å·ç§¯å±‚ã€‚å®ƒå¯¹è¾“å…¥å’Œè¾“å‡ºåšç›¸åº”çš„å‡ç»´å’Œé™ç»´</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span></span><br><span class="line">    <span class="comment"># (1, 1)ä»£è¡¨æ‰¹é‡å¤§å°å’Œé€šé“æ•°</span></span><br><span class="line">    X = X.view((<span class="number">1</span>, <span class="number">1</span>) + X.shape) <span class="comment"># åŠ ä¸Šä¸¤ä¸ªç»´åº¦</span></span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="keyword">return</span> Y.view(Y.shape[<span class="number">2</span>:]) <span class="comment"># æ’é™¤ä¸å…³å¿ƒçš„å‰ä¸¤ç»´:æ‰¹é‡å’Œé€šé“</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ³¨æ„è¿™é‡Œæ˜¯ä¸¤ä¾§åˆ†åˆ«å¡«å……1â¾æˆ–åˆ—ï¼Œæ‰€ä»¥åœ¨ä¸¤ä¾§ä¸€å…±å¡«å……2â¾æˆ–åˆ—</span></span><br><span class="line">conv2d = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
å½“å·ç§¯æ ¸çš„é«˜å’Œå®½ï¥§åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®é«˜å’Œå®½ä¸Šï¥§åŒçš„å¡«å……æ•°ä½¿è¾“å‡ºå’Œè¾“å…¥å…·æœ‰ç›¸åŒçš„é«˜å’Œå®½ã€‚å¡«å……å¯ä»¥å¢åŠ è¾“å‡ºçš„é«˜å’Œå®½ã€‚è¿™å¸¸ç”¨æ¥ä½¿è¾“å‡ºä¸è¾“å…¥å…·æœ‰ç›¸åŒçš„é«˜å’Œå®½ã€‚æ­¥å¹…å¯ä»¥å‡å°è¾“å‡ºçš„é«˜å’Œå®½ï¼Œï¦µå¦‚è¾“å‡ºçš„é«˜å’Œå®½ä»…ä¸ºè¾“å…¥çš„é«˜å’Œå®½çš„ ( ä¸ºå¤§äº1çš„æ•´æ•°)ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨é«˜ä¸º5ã€å®½ä¸º3çš„å·ç§¯æ ¸ã€‚åœ¨â¾¼å’Œå®½ä¸¤ä¾§çš„å¡«å……æ•°åˆ†åˆ«ä¸º2å’Œ1ï¼Œ-5+2*2=-3+2*1</span></span><br><span class="line">conv2d = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">3</span>), padding=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure></li>
<li>æ± åŒ–å±‚<br>æ± åŒ–å±‚æ¯æ¬¡å¯¹è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå›ºå®šå½¢çŠ¶çª—å£(â¼œç§°æ± åŒ–çª—å£)ä¸­çš„å…ƒç´ è®¡ç®—è¾“å‡ºã€‚ï¥§åŒäºå·ç§¯å±‚ï§©è®¡ç®—è¾“â¼Šå’Œæ ¸çš„äº’ç›¸å…³æ€§ï¼Œæ± åŒ–å±‚ç›´æ¥è®¡ç®—æ± åŒ–çª—å£å†…å…ƒç´ çš„æœ€å¤§å€¼æˆ–è€…å¹³å‡å€¼ã€‚è¯¥è¿ç®—ä¹Ÿåˆ†åˆ«å«åšæœ€å¤§æ± åŒ–æˆ–å¹³å‡æ± åŒ–ã€‚åœ¨äºŒç»´æœ€â¼¤æ± åŒ–ä¸­ï¼Œæ± åŒ–çª—å£ä»è¾“å…¥æ•°ç»„çš„æœ€å·¦ä¸Šæ–¹å¼€å§‹ï¼ŒæŒ‰ä»å·¦å¾€å³ã€ä»ä¸Šå¾€ä¸‹çš„é¡ºåºï¼Œä¾æ¬¡åœ¨è¾“â¼Šæ•°ç»„ä¸Šæ»‘åŠ¨ã€‚å½“æ± åŒ–çª—å£æ»‘åŠ¨åˆ°æŸâ¼€ä½ç½®æ—¶ï¼Œçª—å£ä¸­çš„è¾“å…¥å­æ•°ç»„çš„æœ€å¤§å€¼å³è¾“å‡ºæ•°ç»„ä¸­ç›¸åº”ä½ç½®çš„å…ƒç´ ã€‚ä¸‹é¢æŠŠæ± åŒ–å±‚çš„å‰å‘è®¡ç®—å®ç°åœ¨pool2då‡½æ•°é‡Œã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨torch.nnåŒ…æ¥æ„å»ºç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬å·²ç»ä»‹ç»äº†autogradåŒ…ï¼ŒnnåŒ…åˆ™ä¾èµ–äºautogradåŒ…æ¥å®šä¹‰æ¨¡å‹å¹¶å¯¹å®ƒä»¬æ±‚å¯¼ã€‚ä¸€ä¸ªnn.ModuleåŒ…å«å„ä¸ªå±‚å’Œä¸€ä¸ªforward(input)æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è¿”å›outputã€‚</li>
<li>LeNetæ¨¡å‹ç¤ºä¾‹<center> 
<img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.4.1.png" width="480">  
</center>
è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œ (feed-forward networkï¼‰ï¼ˆLeNetï¼‰ã€‚å®ƒæ¥å—ä¸€ä¸ªè¾“å…¥ï¼Œç„¶åå°†å®ƒé€å…¥ä¸‹ä¸€å±‚ï¼Œä¸€å±‚æ¥ä¸€å±‚çš„ä¼ é€’ï¼Œæœ€åç»™å‡ºè¾“å‡ºã€‚ä¸€ä¸ªç¥ç»ç½‘ç»œçš„å…¸å‹è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š
å®šä¹‰åŒ…å«ä¸€äº›å¯å­¦ä¹ å‚æ•°(æˆ–è€…å«æƒé‡ï¼‰çš„ç¥ç»ç½‘ç»œ
åœ¨è¾“å…¥æ•°æ®é›†ä¸Šè¿­ä»£
é€šè¿‡ç½‘ç»œå¤„ç†è¾“å…¥
è®¡ç®— loss (è¾“å‡ºå’Œæ­£ç¡®ç­”æ¡ˆçš„è·ç¦»ï¼‰
å°†æ¢¯åº¦åå‘ä¼ æ’­ç»™ç½‘ç»œçš„å‚æ•°
æ›´æ–°ç½‘ç»œçš„æƒé‡ï¼Œä¸€èˆ¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„è§„åˆ™ï¼šweight = weight - learning_rate * gradient
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># è¾“å…¥å›¾åƒchannelï¼š1ï¼›è¾“å‡ºchannelï¼š6ï¼›5x5å·ç§¯æ ¸</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 2x2 Max pooling</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># å¦‚æœæ˜¯æ–¹é˜µ,åˆ™å¯ä»¥åªä½¿ç”¨ä¸€ä¸ªæ•°å­—è¿›è¡Œå®šä¹‰</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># é™¤å»æ‰¹å¤„ç†ç»´åº¦çš„å…¶ä»–æ‰€æœ‰ç»´åº¦</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<pre><code> Net(
   (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
   (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
   (fc1): Linear(in_features=400, out_features=120, bias=True)
   (fc2): Linear(in_features=120, out_features=84, bias=True)
   (fc3): Linear(in_features=84, out_features=10, bias=True)
 )
</code></pre>
</li>
</ol>
<p>æˆ‘ä»¬åªéœ€è¦å®šä¹‰ forward å‡½æ•°ï¼Œbackwardå‡½æ•°ä¼šåœ¨ä½¿ç”¨autogradæ—¶è‡ªåŠ¨å®šä¹‰ï¼Œbackwardå‡½æ•°ç”¨æ¥è®¡ç®—å¯¼æ•°ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ forward å‡½æ•°ä¸­ä½¿ç”¨ä»»ä½•é’ˆå¯¹å¼ é‡çš„æ“ä½œå’Œè®¡ç®—ã€‚ä¸€ä¸ªæ¨¡å‹çš„å¯å­¦ä¹ å‚æ•°å¯ä»¥é€šè¿‡net.parameters()è¿”å›ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(params))</span><br><span class="line"><span class="built_in">print</span>(params[<span class="number">0</span>].size())  <span class="comment"># conv1çš„æƒé‡</span></span><br></pre></td></tr></table></figure>
<p>å°è¯•éšæœºè¾“å…¥</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="comment"># æ¸…é›¶æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ç¼“å­˜ï¼Œç„¶åè¿›è¡Œéšæœºæ¢¯åº¦çš„åå‘ä¼ æ’­ï¼š</span></span><br><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>torch.nnåªæ”¯æŒå°æ‰¹é‡å¤„ç† (mini-batchesï¼‰ã€‚æ•´ä¸ª torch.nn åŒ…åªæ”¯æŒå°æ‰¹é‡æ ·æœ¬çš„è¾“å…¥ï¼Œä¸æ”¯æŒå•ä¸ªæ ·æœ¬çš„è¾“å…¥ã€‚æ¯”å¦‚ï¼Œnn.Conv2d æ¥å—ä¸€ä¸ª4ç»´çš„å¼ é‡ï¼Œå³nSamples x nChannels x Height x Width å¦‚æœæ˜¯ä¸€ä¸ªå•ç‹¬çš„æ ·æœ¬ï¼Œåªéœ€è¦ä½¿ç”¨input.unsqueeze(0) æ¥æ·»åŠ ä¸€ä¸ªâ€œå‡çš„â€æ‰¹å¤§å°ç»´åº¦ã€‚<br>torch.Tensor - ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼Œæ”¯æŒè¯¸å¦‚backward()ç­‰çš„è‡ªåŠ¨æ±‚å¯¼æ“ä½œï¼ŒåŒæ—¶ä¹Ÿä¿å­˜äº†å¼ é‡çš„æ¢¯åº¦ã€‚<br>nn.Module - ç¥ç»ç½‘ç»œæ¨¡å—ã€‚æ˜¯ä¸€ç§æ–¹ä¾¿å°è£…å‚æ•°çš„æ–¹å¼ï¼Œå…·æœ‰å°†å‚æ•°ç§»åŠ¨åˆ°GPUã€å¯¼å‡ºã€åŠ è½½ç­‰åŠŸèƒ½ã€‚<br>nn.Parameter - å¼ é‡çš„ä¸€ç§ï¼Œå½“å®ƒä½œä¸ºä¸€ä¸ªå±æ€§åˆ†é…ç»™ä¸€ä¸ªModuleæ—¶ï¼Œå®ƒä¼šè¢«è‡ªåŠ¨æ³¨å†Œä¸ºä¸€ä¸ªå‚æ•°ã€‚<br>autograd.Function - å®ç°äº†è‡ªåŠ¨æ±‚å¯¼å‰å‘å’Œåå‘ä¼ æ’­çš„å®šä¹‰ï¼Œæ¯ä¸ªTensorè‡³å°‘åˆ›å»ºä¸€ä¸ªFunctionèŠ‚ç‚¹ï¼Œè¯¥èŠ‚ç‚¹è¿æ¥åˆ°åˆ›å»ºTensorçš„å‡½æ•°å¹¶å¯¹å…¶å†å²è¿›è¡Œç¼–ç ã€‚</p>
<ol>
<li>AlexNetæ¨¡å‹ç¤ºä¾‹<center> 
<img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.4.2.png" width="480">  
</center></li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, <span class="number">11</span>, <span class="number">4</span>), <span class="comment"># in_channels, out_channels, kernel_size, stride, padding</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>), <span class="comment"># kernel_size, stride</span></span><br><span class="line">            <span class="comment"># å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°</span></span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">            <span class="comment"># è¿ç»­3ä¸ªå·ç§¯å±‚ï¼Œä¸”ä½¿ç”¨æ›´å°çš„å·ç§¯çª—å£ã€‚é™¤äº†æœ€åçš„å·ç§¯å±‚å¤–ï¼Œè¿›ä¸€æ­¥å¢å¤§äº†è¾“å‡ºé€šé“æ•°ã€‚</span></span><br><span class="line">            <span class="comment"># å‰ä¸¤ä¸ªå·ç§¯å±‚åä¸ä½¿ç”¨æ± åŒ–å±‚æ¥å‡å°è¾“å…¥çš„é«˜å’Œå®½</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">         <span class="comment"># è¿™é‡Œå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°æ¯”LeNetä¸­çš„å¤§æ•°å€ã€‚ä½¿ç”¨ä¸¢å¼ƒå±‚æ¥ç¼“è§£è¿‡æ‹Ÿåˆ</span></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            <span class="comment"># è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img)</span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">net = AlexNet()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>
<pre><code>AlexNet(
  (conv): Sequential(
    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU()
    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU()
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=6400, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
</code></pre>
<h2 id="å››ã€-æ¨¡å‹åˆå§‹åŒ–"><a href="#å››ã€-æ¨¡å‹åˆå§‹åŒ–" class="headerlink" title="å››ã€ æ¨¡å‹åˆå§‹åŒ–"></a>å››ã€ æ¨¡å‹åˆå§‹åŒ–</h2><ol>
<li>torch.nn.initä½¿ç”¨<br>é€šå¸¸ä½¿ç”¨isinstanceæ¥è¿›è¡Œåˆ¤æ–­æ¨¡å—<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">conv = nn.Conv2d(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">linear = nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">isinstance</span>(conv,nn.Conv2d)</span><br><span class="line"><span class="built_in">isinstance</span>(linear,nn.Conv2d)</span><br></pre></td></tr></table></figure>
æŸ¥çœ‹ä¸åŒåˆå§‹åŒ–å‚æ•°<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŸ¥çœ‹éšæœºåˆå§‹åŒ–çš„convå‚æ•°</span></span><br><span class="line">conv.weight.data</span><br><span class="line"><span class="comment"># æŸ¥çœ‹linearçš„å‚æ•°</span></span><br><span class="line">linear.weight.data</span><br></pre></td></tr></table></figure>
å¯¹ä¸åŒç±»å‹å±‚è¿›è¡Œåˆå§‹åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¹convè¿›è¡Œkaimingåˆå§‹åŒ–</span></span><br><span class="line">torch.nn.init.kaiming_normal_(conv.weight.data)</span><br><span class="line">conv.weight.data</span><br><span class="line"><span class="comment"># å¯¹linearè¿›è¡Œå¸¸æ•°åˆå§‹åŒ–</span></span><br><span class="line">torch.nn.init.constant_(linear.weight.data,<span class="number">0.3</span>)</span><br><span class="line">linear.weight.data</span><br></pre></td></tr></table></figure></li>
<li>åˆå§‹åŒ–å‡½æ•°çš„å°è£…<br>äººä»¬å¸¸å¸¸å°†å„ç§åˆå§‹åŒ–æ–¹æ³•å®šä¹‰ä¸ºä¸€ä¸ªinitialize_weights()çš„å‡½æ•°å¹¶åœ¨æ¨¡å‹åˆå§‹åè¿›è¡Œä½¿ç”¨ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">	<span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">		<span class="comment"># åˆ¤æ–­æ˜¯å¦å±äºConv2d</span></span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">			torch.nn.init.xavier_normal_(m.weight.data)</span><br><span class="line">			<span class="comment"># åˆ¤æ–­æ˜¯å¦æœ‰åç½®</span></span><br><span class="line">			<span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">				torch.nn.init.constant_(m.bias.data,<span class="number">0.3</span>)</span><br><span class="line">		<span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">			torch.nn.init.normal_(m.weight.data, <span class="number">0.1</span>)</span><br><span class="line">			<span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">				torch.nn.init.zeros_(m.bias.data)</span><br><span class="line">		<span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">			m.weight.data.fill_(<span class="number">1</span>) 		 </span><br><span class="line">			m.bias.data.zeros_()	</span><br></pre></td></tr></table></figure>
è¿™æ®µä»£ç æµç¨‹æ˜¯éå†å½“å‰æ¨¡å‹çš„æ¯ä¸€å±‚ï¼Œç„¶ååˆ¤æ–­å„å±‚å±äºä»€ä¹ˆç±»å‹ï¼Œç„¶åæ ¹æ®ä¸åŒç±»å‹å±‚ï¼Œè®¾å®šä¸åŒçš„æƒå€¼åˆå§‹åŒ–æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä¾‹ç¨‹è¿›è¡Œä¸€ä¸ªç®€çŸ­çš„æ¼”ç¤ºï¼š<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ¨¡å‹çš„å®šä¹‰</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="comment"># å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨MLPçˆ¶ç±»Blockçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°</span></span><br><span class="line">    <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line">    self.hidden = nn.Conv2d(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    self.act = nn.ReLU()</span><br><span class="line">    self.output = nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">   <span class="comment"># å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    o = self.act(self.hidden(x))</span><br><span class="line">    <span class="keyword">return</span> self.output(o)</span><br><span class="line"></span><br><span class="line">mlp = MLP()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(mlp.parameters()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------åˆå§‹åŒ–-------&quot;</span>)</span><br><span class="line"></span><br><span class="line">initialize_weights(mlp)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(mlp.parameters()))</span><br></pre></td></tr></table></figure>

<pre><code> [Parameter containing:
 tensor([[[[ 0.2103, -0.1679,  0.1757],
           [-0.0647, -0.0136, -0.0410],
           [ 0.1371, -0.1738, -0.0850]]]], requires_grad=True), Parameter containing:
 tensor([0.2507], requires_grad=True), Parameter containing:
 tensor([[ 0.2790, -0.1247,  0.2762,  0.1149, -0.2121, -0.3022, -0.1859,  0.2983,
         -0.0757, -0.2868]], requires_grad=True), Parameter containing:
 tensor([-0.0905], requires_grad=True)]
 &quot;-------åˆå§‹åŒ–-------&quot;
 [Parameter containing:
 tensor([[[[-0.3196, -0.0204, -0.5784],
           [ 0.2660,  0.2242, -0.4198],
           [-0.0952,  0.6033, -0.8108]]]], requires_grad=True),
 Parameter containing:
 tensor([0.3000], requires_grad=True),
 Parameter containing:
 tensor([[ 0.7542,  0.5796,  2.2963, -0.1814, -0.9627,  1.9044,  0.4763,  1.2077,
           0.8583,  1.9494]], requires_grad=True),
 Parameter containing:
 tensor([0.], requires_grad=True)]
</code></pre>
</li>
</ol>
<h2 id="äº”ã€-æŸå¤±å‡½æ•°"><a href="#äº”ã€-æŸå¤±å‡½æ•°" class="headerlink" title="äº”ã€ æŸå¤±å‡½æ•°"></a>äº”ã€ æŸå¤±å‡½æ•°</h2><p>è¿™é‡Œä½¿ç”¨torch.nnæ¨¡å—è‡ªå¸¦çš„CrossEntropyæŸå¤±ï¼ŒPyTorchä¼šè‡ªåŠ¨æŠŠæ•´æ•°å‹çš„labelè½¬ä¸ºone-hotå‹ï¼Œç”¨äºè®¡ç®—CE lossï¼Œè¿™é‡Œéœ€è¦ç¡®ä¿labelæ˜¯ä»0å¼€å§‹çš„ï¼ŒåŒæ—¶æ¨¡å‹ä¸åŠ softmaxå±‚ï¼ˆä½¿ç”¨logitsè®¡ç®—ï¼‰,è¿™ä¹Ÿè¯´æ˜äº†PyTorchè®­ç»ƒä¸­å„ä¸ªéƒ¨åˆ†ä¸æ˜¯ç‹¬ç«‹çš„ï¼Œéœ€è¦é€šç›˜è€ƒè™‘ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h3 id="1-äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"><a href="#1-äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°" class="headerlink" title="1. äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"></a>1. äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BCELoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½</strong>ï¼šè®¡ç®—äºŒåˆ†ç±»ä»»åŠ¡æ—¶çš„äº¤å‰ç†µï¼ˆCross Entropyï¼‰å‡½æ•°ã€‚åœ¨äºŒåˆ†ç±»ä¸­ï¼Œlabelæ˜¯{0,1}ã€‚å¯¹äºè¿›å…¥äº¤å‰ç†µå‡½æ•°çš„inputä¸ºæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œinputä¸ºsigmoidæ¿€æ´»å±‚çš„è¾“å‡ºï¼Œæˆ–è€…softmaxçš„è¾“å‡ºã€‚<br><strong>ä¸»è¦å‚æ•°</strong>ï¼š<br><code>weight</code>:æ¯ä¸ªç±»åˆ«çš„lossè®¾ç½®æƒå€¼<br><code>size_average</code>:æ•°æ®ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚<br><code>reduce</code>:æ•°æ®ç±»å‹ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œlossçš„è¿”å›æ˜¯æ ‡é‡ã€‚<br>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665580819001/D2B5CA33BD970F64A6301FA75AE2EB22" width="290">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Sigmoid()</span><br><span class="line">loss = nn.BCELoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.empty(<span class="number">3</span>).random_(<span class="number">2</span>)</span><br><span class="line">output = loss(m(<span class="built_in">input</span>), target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;BCELossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>BCELossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.5732, grad_fn=&lt;BinaryCrossEntropyBackward&gt;)
</code></pre>
<h3 id="2-äº¤å‰ç†µæŸå¤±å‡½æ•°"><a href="#2-äº¤å‰ç†µæŸå¤±å‡½æ•°" class="headerlink" title="2. äº¤å‰ç†µæŸå¤±å‡½æ•°"></a>2. äº¤å‰ç†µæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½</strong>ï¼šè®¡ç®—äº¤å‰ç†µå‡½æ•°<br><strong>ä¸»è¦å‚æ•°</strong>ï¼š<br><code>weight</code>:æ¯ä¸ªç±»åˆ«çš„lossè®¾ç½®æƒå€¼ã€‚<br><code>size_average</code>:æ•°æ®ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚<br><code>ignore_index</code>:å¿½ç•¥æŸä¸ªç±»çš„æŸå¤±å‡½æ•°ã€‚<br><code>reduce</code>:æ•°æ®ç±»å‹ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œlossçš„è¿”å›æ˜¯æ ‡é‡ã€‚<br>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š<br>$<br>\operatorname{loss}(x, \text { class })&#x3D;-\log \left(\frac{\exp (x[\text { class }])}{\sum_{j} \exp (x[j])}\right)&#x3D;-x[\text { class }]+\log \left(\sum_{j} \exp (x[j])\right)<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.empty(<span class="number">3</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<pre><code>tensor(2.0115, grad_fn=&lt;NllLossBackward&gt;)
</code></pre>
<h3 id="3-L1æŸå¤±å‡½æ•°"><a href="#3-L1æŸå¤±å‡½æ•°" class="headerlink" title="3. L1æŸå¤±å‡½æ•°"></a>3. L1æŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.L1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—è¾“å‡º<code>y</code>å’ŒçœŸå®æ ‡ç­¾<code>target</code>ä¹‹é—´çš„å·®å€¼çš„ç»å¯¹å€¼ã€‚<code>reduction</code>å‚æ•°å†³å®šäº†è®¡ç®—æ¨¡å¼ã€‚æœ‰ä¸‰ç§è®¡ç®—æ¨¡å¼å¯é€‰ï¼šnoneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚meanï¼šåŠ æƒå¹³å‡ï¼Œè¿”å›æ ‡é‡ã€‚å¦‚æœé€‰æ‹©<code>none</code>ï¼Œé‚£ä¹ˆè¿”å›çš„ç»“æœæ˜¯å’Œè¾“å…¥å…ƒç´ ç›¸åŒå°ºå¯¸çš„ã€‚é»˜è®¤è®¡ç®—æ–¹å¼æ˜¯æ±‚å¹³å‡ã€‚<br><strong>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</strong><br>$<br>L_{n} &#x3D; |x_{n}-y_{n}|<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.L1Loss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;L1æŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>L1æŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(1.5729, grad_fn=&lt;L1LossBackward&gt;)
</code></pre>
<h3 id="4-MSEæŸå¤±å‡½æ•°"><a href="#4-MSEæŸå¤±å‡½æ•°" class="headerlink" title="4. MSEæŸå¤±å‡½æ•°"></a>4. MSEæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MSELoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—è¾“å‡º<code>y</code>å’ŒçœŸå®æ ‡ç­¾<code>target</code>ä¹‹å·®çš„å¹³æ–¹ã€‚</p>
<p>å’Œ<code>L1Loss</code>ä¸€æ ·ï¼Œ<code>MSELoss</code>æŸå¤±å‡½æ•°ä¸­ï¼Œ<code>reduction</code>å‚æ•°å†³å®šäº†è®¡ç®—æ¨¡å¼ã€‚æœ‰ä¸‰ç§è®¡ç®—æ¨¡å¼å¯é€‰ï¼šnoneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚é»˜è®¤è®¡ç®—æ–¹å¼æ˜¯æ±‚å¹³å‡ã€‚</p>
<p><strong>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</strong></p>
<p>$<br>l_{n}&#x3D;\left(x_{n}-y_{n}\right)^{2}<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MSEæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MSEæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(1.6968, grad_fn=&lt;MseLossBackward&gt;)
</code></pre>
<h3 id="5-å¹³æ»‘L1-Smooth-L1-æŸå¤±å‡½æ•°"><a href="#5-å¹³æ»‘L1-Smooth-L1-æŸå¤±å‡½æ•°" class="headerlink" title="5. å¹³æ»‘L1 (Smooth L1)æŸå¤±å‡½æ•°"></a>5. å¹³æ»‘L1 (Smooth L1)æŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.SmoothL1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, beta=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> L1çš„å¹³æ»‘è¾“å‡ºï¼Œå…¶åŠŸèƒ½æ˜¯å‡è½»ç¦»ç¾¤ç‚¹å¸¦æ¥çš„å½±å“</p>
<p><code>reduction</code>å‚æ•°å†³å®šäº†è®¡ç®—æ¨¡å¼ã€‚æœ‰ä¸‰ç§è®¡ç®—æ¨¡å¼å¯é€‰ï¼šnoneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚é»˜è®¤è®¡ç®—æ–¹å¼æ˜¯æ±‚å¹³å‡ã€‚</p>
<p><strong>æé†’ï¼š</strong> ä¹‹åçš„æŸå¤±å‡½æ•°ä¸­ï¼Œå…³äº<code>reduction</code> è¿™ä¸ªå‚æ•°ä¾æ—§ä¼šå­˜åœ¨ã€‚æ‰€ä»¥ï¼Œä¹‹åå°±ä¸å†å•ç‹¬è¯´æ˜ã€‚</p>
<p><strong>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\frac{1}{n} \sum_{i&#x3D;1}^{n} z_{i}<br>$<br>å…¶ä¸­ï¼Œ</p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665580768639/D2B5CA33BD970F64A6301FA75AE2EB22" width="290">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.SmoothL1Loss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;SmoothL1LossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>SmoothL1LossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7808, grad_fn=&lt;SmoothL1LossBackward&gt;)
</code></pre>
<p><strong>å¹³æ»‘L1ä¸L1çš„å¯¹æ¯”</strong></p>
<p>è¿™é‡Œæˆ‘ä»¬é€šè¿‡å¯è§†åŒ–ä¸¤ç§æŸå¤±å‡½æ•°æ›²çº¿æ¥å¯¹æ¯”å¹³æ»‘L1å’ŒL1ä¸¤ç§æŸå¤±å‡½æ•°çš„åŒºåˆ«ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.linspace(-<span class="number">10</span>, <span class="number">10</span>, steps=<span class="number">5000</span>)</span><br><span class="line">target = torch.zeros_like(inputs)</span><br><span class="line"></span><br><span class="line">loss_f_smooth = nn.SmoothL1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_smooth = loss_f_smooth(inputs, target)</span><br><span class="line">loss_f_l1 = nn.L1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_l1 = loss_f_l1(inputs,target)</span><br><span class="line"></span><br><span class="line">plt.plot(inputs.numpy(), loss_smooth.numpy(), label=<span class="string">&#x27;Smooth L1 Loss&#x27;</span>)</span><br><span class="line">plt.plot(inputs.numpy(), loss_l1, label=<span class="string">&#x27;L1 loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x_i - y_i&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss value&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.5.2.png"><br>å¯ä»¥çœ‹å‡ºï¼Œå¯¹äº<code>smoothL1</code>æ¥è¯´ï¼Œåœ¨ 0 è¿™ä¸ªå°–ç«¯å¤„ï¼Œè¿‡æ¸¡æ›´ä¸ºå¹³æ»‘ã€‚</p>
<h3 id="6-ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±"><a href="#6-ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±" class="headerlink" title="6. ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±"></a>6. ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.PoissonNLLLoss(log_input=<span class="literal">True</span>, full=<span class="literal">False</span>, size_average=<span class="literal">None</span>, eps=<span class="number">1e-08</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±å‡½æ•°<br><strong>ä¸»è¦å‚æ•°ï¼š</strong><br><code>log_input</code>ï¼šè¾“å…¥æ˜¯å¦ä¸ºå¯¹æ•°å½¢å¼ï¼Œå†³å®šè®¡ç®—å…¬å¼ã€‚<br><code>full</code>ï¼šè®¡ç®—æ‰€æœ‰ lossï¼Œé»˜è®¤ä¸º Falseã€‚<br><code>eps</code>ï¼šä¿®æ­£é¡¹ï¼Œé¿å… input ä¸º 0 æ—¶ï¼Œlog(input) ä¸º nan çš„æƒ…å†µã€‚<br><strong>æ•°å­¦å…¬å¼ï¼š</strong></p>
<ul>
<li>å½“å‚æ•°<code>log_input=True</code>ï¼š<br>$<br>\operatorname{loss}\left(x_{n}, y_{n}\right)&#x3D;e^{x_{n}}-x_{n} \cdot y_{n}<br>$</li>
<li>å½“å‚æ•°<code>log_input=False</code>ï¼š<br>  $<br>  \operatorname{loss}\left(x_{n}, y_{n}\right)&#x3D;x_{n}-y_{n} \cdot \log \left(x_{n}+\text { eps }\right)<br>  $</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.PoissonNLLLoss()</span><br><span class="line">log_input = torch.randn(<span class="number">5</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">output = loss(log_input, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;PoissonNLLLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>PoissonNLLLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7358, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h3 id="7-KLæ•£åº¦"><a href="#7-KLæ•£åº¦" class="headerlink" title="7. KLæ•£åº¦"></a>7. KLæ•£åº¦</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.KLDivLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, log_target=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—KLæ•£åº¦ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—ç›¸å¯¹ç†µã€‚ç”¨äºè¿ç»­åˆ†å¸ƒçš„è·ç¦»åº¦é‡ï¼Œå¹¶ä¸”å¯¹ç¦»æ•£é‡‡ç”¨çš„è¿ç»­è¾“å‡ºç©ºé—´åˆ†å¸ƒè¿›è¡Œå›å½’é€šå¸¸å¾ˆæœ‰ç”¨ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º <code>none</code>&#x2F;<code>sum</code>&#x2F;<code>mean</code>&#x2F;<code>batchmean</code>ã€‚</p>
<pre><code>noneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚
sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚
meanï¼šåŠ æƒå¹³å‡ï¼Œè¿”å›æ ‡é‡ã€‚
batchmeanï¼šbatchsize ç»´åº¦æ±‚å¹³å‡å€¼ã€‚
</code></pre>
<p><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582006862/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">0.9</span>, <span class="number">0.05</span>, <span class="number">0.05</span>], [<span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.2</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">loss = nn.KLDivLoss()</span><br><span class="line">output = loss(inputs,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;KLDivLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>KLDivLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(-0.3335)
</code></pre>
<h3 id="8-MarginRankingLoss"><a href="#8-MarginRankingLoss" class="headerlink" title="8. MarginRankingLoss"></a>8. MarginRankingLoss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MarginRankingLoss(margin=<span class="number">0.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç”¨äºæ’åºä»»åŠ¡ã€‚è¯¥æ–¹æ³•ç”¨äºè®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„å·®å¼‚ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>margin</code>ï¼šè¾¹ç•Œå€¼ï¼Œ$x_{1}$ ä¸$x_{2}$ ä¹‹é—´çš„å·®å¼‚å€¼ã€‚<br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x 1, x 2, y)&#x3D;\max (0,-y *(x 1-x 2)+\operatorname{margin})<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MarginRankingLoss()</span><br><span class="line">input1 = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">input2 = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>).sign()</span><br><span class="line">output = loss(input1, input2, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MarginRankingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MarginRankingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7740, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h3 id="9-å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°"><a href="#9-å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°" class="headerlink" title="9. å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°"></a>9. å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiLabelMarginLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> å¯¹äºå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜è®¡ç®—æŸå¤±å‡½æ•°ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\sum_{i j} \frac{\max (0,1-x[y[j]]-x[i])}{x \cdot \operatorname{size}(0)}<br>$<br>$<br>\begin{array}{l}<br>\text { å…¶ä¸­, } i&#x3D;0, \ldots, x \cdot \operatorname{size}(0), j&#x3D;0, \ldots, y \cdot \operatorname{size}(0), \text { å¯¹äºæ‰€æœ‰çš„ } i \text { å’Œ } j \text {, éƒ½æœ‰ } y[j] \geq 0 \text { å¹¶ä¸” }\<br>i \neq y[j]<br>\end{array}<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MultiLabelMarginLoss()</span><br><span class="line">x = torch.FloatTensor([[<span class="number">0.9</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.8</span>]])</span><br><span class="line"><span class="comment"># for target y, only consider labels 3 and 0, not after label -1</span></span><br><span class="line">y = torch.LongTensor([[<span class="number">3</span>, <span class="number">0</span>, -<span class="number">1</span>, <span class="number">1</span>]])<span class="comment"># çœŸå®çš„åˆ†ç±»æ˜¯ï¼Œç¬¬3ç±»å’Œç¬¬0ç±»</span></span><br><span class="line">output = loss(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MultiLabelMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MultiLabelMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.4500)
</code></pre>
<h3 id="10-äºŒåˆ†ç±»æŸå¤±å‡½æ•°"><a href="#10-äºŒåˆ†ç±»æŸå¤±å‡½æ•°" class="headerlink" title="10. äºŒåˆ†ç±»æŸå¤±å‡½æ•°"></a>10. äºŒåˆ†ç±»æŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.SoftMarginLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)torch.nn.(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—äºŒåˆ†ç±»çš„ logistic æŸå¤±ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\sum_{i} \frac{\log (1+\exp (-y[i] \cdot x[i]))}{x \cdot \operatorname{nelement}()}<br>$<br>$<br><br>\text { å…¶ä¸­, } x . \text { nelement() ä¸ºè¾“å…¥ } x \text { ä¸­çš„æ ·æœ¬ä¸ªæ•°ã€‚æ³¨æ„è¿™é‡Œ } y \text { ä¹Ÿæœ‰ } 1 \text { å’Œ }-1 \text { ä¸¤ç§æ¨¡å¼ã€‚ }<br><br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.7</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>]])  <span class="comment"># ä¸¤ä¸ªæ ·æœ¬ï¼Œä¸¤ä¸ªç¥ç»å…ƒ</span></span><br><span class="line">target = torch.tensor([[-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)  <span class="comment"># è¯¥ loss ä¸ºé€ä¸ªç¥ç»å…ƒè®¡ç®—ï¼Œéœ€è¦ä¸ºæ¯ä¸ªç¥ç»å…ƒå•ç‹¬è®¾ç½®æ ‡ç­¾</span></span><br><span class="line"></span><br><span class="line">loss_f = nn.SoftMarginLoss()</span><br><span class="line">output = loss_f(inputs, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;SoftMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>SoftMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.6764)
</code></pre>
<h3 id="11-å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±"><a href="#11-å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±" class="headerlink" title="11. å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±"></a>11. å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiMarginLoss(p=<span class="number">1</span>, margin=<span class="number">1.0</span>, weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>pï¼š</code>å¯é€‰ 1 æˆ– 2ã€‚<br><code>weight</code>ï¼šå„ç±»åˆ«çš„ loss è®¾ç½®æƒå€¼ã€‚<br><code>margin</code>ï¼šè¾¹ç•Œå€¼<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\frac{\sum_{i} \max (0, \operatorname{margin}-x[y]+x[i])^{p}}{x \cdot \operatorname{size}(0)}<br>$<br>$<br>\begin{array}{l}<br>\text { å…¶ä¸­, } x \in{0, \ldots, x \cdot \operatorname{size}(0)-1}, y \in{0, \ldots, y \cdot \operatorname{size}(0)-1} \text {, å¹¶ä¸”å¯¹äºæ‰€æœ‰çš„ } i \text { å’Œ } j \text {, }\<br>\text { éƒ½æœ‰ } 0 \leq y[j] \leq x \cdot \operatorname{size}(0)-1, \text { ä»¥åŠ } i \neq y[j] \text { ã€‚ }<br>\end{array}<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.7</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>]]) </span><br><span class="line">target = torch.tensor([<span class="number">0</span>, <span class="number">1</span>], dtype=torch.long) </span><br><span class="line"></span><br><span class="line">loss_f = nn.MultiMarginLoss()</span><br><span class="line">output = loss_f(inputs, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MultiMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MultiMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.6000)
</code></pre>
<h3 id="12-ä¸‰å…ƒç»„æŸå¤±"><a href="#12-ä¸‰å…ƒç»„æŸå¤±" class="headerlink" title="12. ä¸‰å…ƒç»„æŸå¤±"></a>12. ä¸‰å…ƒç»„æŸå¤±</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.TripletMarginLoss(margin=<span class="number">1.0</span>, p=<span class="number">2.0</span>, eps=<span class="number">1e-06</span>, swap=<span class="literal">False</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—ä¸‰å…ƒç»„æŸå¤±ã€‚<br><strong>ä¸‰å…ƒç»„:</strong> è¿™æ˜¯ä¸€ç§æ•°æ®çš„å­˜å‚¨æˆ–è€…ä½¿ç”¨æ ¼å¼ã€‚&lt;å®ä½“1ï¼Œå…³ç³»ï¼Œå®ä½“2&gt;ã€‚åœ¨é¡¹ç›®ä¸­ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºä¸º&lt; <code>anchor</code>, <code>positive examples</code> , <code>negative examples</code>&gt;<br>åœ¨è¿™ä¸ªæŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›å»<code>anchor</code>çš„è·ç¦»æ›´æ¥è¿‘<code>positive examples</code>ï¼Œè€Œè¿œç¦»<code>negative examples </code><br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>pï¼š</code>å¯é€‰ 1 æˆ– 2ã€‚<br><code>margin</code>ï¼šè¾¹ç•Œå€¼<br><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582222120/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">triplet_loss = nn.TripletMarginLoss(margin=<span class="number">1.0</span>, p=<span class="number">2</span>)</span><br><span class="line">anchor = torch.randn(<span class="number">100</span>, <span class="number">128</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">positive = torch.randn(<span class="number">100</span>, <span class="number">128</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">negative = torch.randn(<span class="number">100</span>, <span class="number">128</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">output = triplet_loss(anchor, positive, negative)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;TripletMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>TripletMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(1.1667, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h3 id="13-HingEmbeddingLoss"><a href="#13-HingEmbeddingLoss" class="headerlink" title="13. HingEmbeddingLoss"></a>13. HingEmbeddingLoss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.HingeEmbeddingLoss(margin=<span class="number">1.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> å¯¹è¾“å‡ºçš„embeddingç»“æœåšHingæŸå¤±è®¡ç®—<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>margin</code>ï¼šè¾¹ç•Œå€¼<br><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582284050/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<p><strong>æ³¨æ„äº‹é¡¹ï¼š</strong> è¾“å…¥xåº”ä¸ºä¸¤ä¸ªè¾“å…¥ä¹‹å·®çš„ç»å¯¹å€¼ã€‚<br>å¯ä»¥è¿™æ ·ç†è§£ï¼Œè®©ä¸ªè¾“å‡ºçš„æ˜¯æ­£ä¾‹yn&#x3D;1,é‚£ä¹ˆlosså°±æ˜¯xï¼Œå¦‚æœè¾“å‡ºçš„æ˜¯è´Ÿä¾‹y&#x3D;-1ï¼Œé‚£ä¹ˆè¾“å‡ºçš„losså°±æ˜¯è¦åšä¸€ä¸ªæ¯”è¾ƒã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss_f = nn.HingeEmbeddingLoss()</span><br><span class="line">inputs = torch.tensor([[<span class="number">1.</span>, <span class="number">0.8</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">output = loss_f(inputs,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;HingEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>HingEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7667)
</code></pre>
<h3 id="14-ä½™å¼¦ç›¸ä¼¼åº¦"><a href="#14-ä½™å¼¦ç›¸ä¼¼åº¦" class="headerlink" title="14. ä½™å¼¦ç›¸ä¼¼åº¦"></a>14. ä½™å¼¦ç›¸ä¼¼åº¦</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CosineEmbeddingLoss(margin=<span class="number">0.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> å¯¹ä¸¤ä¸ªå‘é‡åšä½™å¼¦ç›¸ä¼¼åº¦<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>margin</code>ï¼šå¯å–å€¼[-1,1] ï¼Œæ¨èä¸º[0,0.5] ã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582351089/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<p>è¿™ä¸ªæŸå¤±å‡½æ•°åº”è¯¥æ˜¯æœ€å¹¿ä¸ºäººçŸ¥çš„ã€‚å¯¹äºä¸¤ä¸ªå‘é‡ï¼Œåšä½™å¼¦ç›¸ä¼¼åº¦ã€‚å°†ä½™å¼¦ç›¸ä¼¼åº¦ä½œä¸ºä¸€ä¸ªè·ç¦»çš„è®¡ç®—æ–¹å¼ï¼Œå¦‚æœä¸¤ä¸ªå‘é‡çš„è·ç¦»è¿‘ï¼Œåˆ™æŸå¤±å‡½æ•°å€¼å°ï¼Œåä¹‹äº¦ç„¶ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss_f = nn.CosineEmbeddingLoss()</span><br><span class="line">inputs_1 = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.7</span>], [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.7</span>]])</span><br><span class="line">inputs_2 = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>], [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, -<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">output = loss_f(inputs_1,inputs_2,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;CosineEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>CosineEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.5000)
</code></pre>
<h3 id="15-CTCæŸå¤±å‡½æ•°"><a href="#15-CTCæŸå¤±å‡½æ•°" class="headerlink" title="15.CTCæŸå¤±å‡½æ•°"></a>15.CTCæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CTCLoss(blank=<span class="number">0</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, zero_infinity=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> ç”¨äºè§£å†³æ—¶åºç±»æ•°æ®çš„åˆ†ç±»<br>è®¡ç®—è¿ç»­æ—¶é—´åºåˆ—å’Œç›®æ ‡åºåˆ—ä¹‹é—´çš„æŸå¤±ã€‚CTCLosså¯¹è¾“å…¥å’Œç›®æ ‡çš„å¯èƒ½æ’åˆ—çš„æ¦‚ç‡è¿›è¡Œæ±‚å’Œï¼Œäº§ç”Ÿä¸€ä¸ªæŸå¤±å€¼ï¼Œè¿™ä¸ªæŸå¤±å€¼å¯¹æ¯ä¸ªè¾“å…¥èŠ‚ç‚¹æ¥è¯´æ˜¯å¯åˆ†çš„ã€‚è¾“å…¥ä¸ç›®æ ‡çš„å¯¹é½æ–¹å¼è¢«å‡å®šä¸º â€œå¤šå¯¹ä¸€â€ï¼Œè¿™å°±é™åˆ¶äº†ç›®æ ‡åºåˆ—çš„é•¿åº¦ï¼Œä½¿å…¶å¿…é¡»æ˜¯â‰¤è¾“å…¥é•¿åº¦ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>blank</code>ï¼šblank labelã€‚<br><code>zero_infinity</code>ï¼šæ— ç©·å¤§çš„å€¼æˆ–æ¢¯åº¦å€¼ä¸º </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Target are to be padded</span></span><br><span class="line">T = <span class="number">50</span>      <span class="comment"># Input sequence length</span></span><br><span class="line">C = <span class="number">20</span>      <span class="comment"># Number of classes (including blank)</span></span><br><span class="line">N = <span class="number">16</span>      <span class="comment"># Batch size</span></span><br><span class="line">S = <span class="number">30</span>      <span class="comment"># Target sequence length of longest target in batch (padding length)</span></span><br><span class="line">S_min = <span class="number">10</span>  <span class="comment"># Minimum target length, for demonstration purposes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of input vectors, for *size = (T,N,C)</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(T, N, C).log_softmax(<span class="number">2</span>).detach().requires_grad_()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of targets (0 = blank, 1:C = classes)</span></span><br><span class="line">target = torch.randint(low=<span class="number">1</span>, high=C, size=(N, S), dtype=torch.long)</span><br><span class="line"></span><br><span class="line">input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)</span><br><span class="line">target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)</span><br><span class="line">ctc_loss = nn.CTCLoss()</span><br><span class="line">loss = ctc_loss(<span class="built_in">input</span>, target, input_lengths, target_lengths)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Target are to be un-padded</span></span><br><span class="line">T = <span class="number">50</span>      <span class="comment"># Input sequence length</span></span><br><span class="line">C = <span class="number">20</span>      <span class="comment"># Number of classes (including blank)</span></span><br><span class="line">N = <span class="number">16</span>      <span class="comment"># Batch size</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of input vectors, for *size = (T,N,C)</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(T, N, C).log_softmax(<span class="number">2</span>).detach().requires_grad_()</span><br><span class="line">input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of targets (0 = blank, 1:C = classes)</span></span><br><span class="line">target_lengths = torch.randint(low=<span class="number">1</span>, high=T, size=(N,), dtype=torch.long)</span><br><span class="line">target = torch.randint(low=<span class="number">1</span>, high=C, size=(<span class="built_in">sum</span>(target_lengths),), dtype=torch.long)</span><br><span class="line">ctc_loss = nn.CTCLoss()</span><br><span class="line">loss = ctc_loss(<span class="built_in">input</span>, target, input_lengths, target_lengths)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;CTCLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,loss)</span><br></pre></td></tr></table></figure>

<pre><code>CTCLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(16.0885, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h2 id="å…­ã€-ä¼˜åŒ–å™¨"><a href="#å…­ã€-ä¼˜åŒ–å™¨" class="headerlink" title="å…­ã€ ä¼˜åŒ–å™¨"></a>å…­ã€ ä¼˜åŒ–å™¨</h2><p>è¿™é‡Œä½¿ç”¨Adamä¼˜åŒ–å™¨</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<p>Pytorchå¾ˆäººæ€§åŒ–çš„ç»™æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªä¼˜åŒ–å™¨çš„åº“torch.optimï¼Œåœ¨è¿™é‡Œé¢æä¾›äº†åç§ä¼˜åŒ–å™¨ã€‚</p>
<ul>
<li>torch.optim.ASGD</li>
<li>torch.optim.Adadelta</li>
<li>torch.optim.Adagrad</li>
<li>torch.optim.Adam</li>
<li>torch.optim.AdamW</li>
<li>torch.optim.Adamax</li>
<li>torch.optim.LBFGS</li>
<li>torch.optim.RMSprop</li>
<li>torch.optim.Rprop</li>
<li>torch.optim.SGD</li>
<li>torch.optim.SparseAdam</li>
</ul>
<p>è€Œä»¥ä¸Šè¿™äº›ä¼˜åŒ–ç®—æ³•å‡ç»§æ‰¿äº<code>Optimizer</code>ï¼Œä¸‹é¢æˆ‘ä»¬å…ˆæ¥çœ‹ä¸‹æ‰€æœ‰ä¼˜åŒ–å™¨çš„åŸºç±»<code>Optimizer</code>ã€‚å®šä¹‰å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, params, defaults</span>):</span>        </span><br><span class="line">        self.defaults = defaults</span><br><span class="line">        self.state = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">        self.param_groups = []</span><br></pre></td></tr></table></figure>

<p><strong><code>Optimizer</code>æœ‰ä¸‰ä¸ªå±æ€§ï¼š</strong></p>
<ul>
<li><code>defaults</code>ï¼šå­˜å‚¨çš„æ˜¯ä¼˜åŒ–å™¨çš„è¶…å‚æ•°ï¼Œä¾‹å­å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>state</code>ï¼šå‚æ•°çš„ç¼“å­˜ï¼Œä¾‹å­å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">defaultdict(&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">dict</span>&#x27;&gt;, &#123;<span class="title">tensor</span>(<span class="params">[[ <span class="number">0.3864</span>, -<span class="number">0.0131</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">        [-<span class="number">0.1911</span>, -<span class="number">0.4511</span>]], requires_grad=<span class="literal">True</span></span>):</span> &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>param_groups</code>ï¼šç®¡ç†çš„å‚æ•°ç»„ï¼Œæ˜¯ä¸€ä¸ªlistï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé¡ºåºæ˜¯paramsï¼Œlrï¼Œmomentumï¼Œdampeningï¼Œweight_decayï¼Œnesterovï¼Œä¾‹å­å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">0.1022</span>, -<span class="number">1.6890</span>],[-<span class="number">1.5116</span>, -<span class="number">1.7846</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;]</span><br></pre></td></tr></table></figure>

<p><strong><code>Optimizer</code>è¿˜æœ‰ä»¥ä¸‹çš„æ–¹æ³•ï¼š</strong></p>
<ul>
<li><code>zero_grad()</code>ï¼šæ¸…ç©ºæ‰€ç®¡ç†å‚æ•°çš„æ¢¯åº¦ï¼ŒPyTorchçš„ç‰¹æ€§æ˜¯å¼ é‡çš„æ¢¯åº¦ä¸è‡ªåŠ¨æ¸…é›¶ï¼Œå› æ­¤æ¯æ¬¡åå‘ä¼ æ’­åéƒ½éœ€è¦æ¸…ç©ºæ¢¯åº¦ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_grad</span>(<span class="params">self, set_to_none: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> self.param_groups:</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> group[<span class="string">&#x27;params&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> p.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  <span class="comment">#æ¢¯åº¦ä¸ä¸ºç©º</span></span><br><span class="line">                <span class="keyword">if</span> set_to_none: </span><br><span class="line">                    p.grad = <span class="literal">None</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> p.grad.grad_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        p.grad.detach_()</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        p.grad.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">                    p.grad.zero_()<span class="comment"># æ¢¯åº¦è®¾ç½®ä¸º0</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>step()</code>ï¼šæ‰§è¡Œä¸€æ­¥æ¢¯åº¦æ›´æ–°ï¼Œå‚æ•°æ›´æ–°</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, closure</span>):</span> </span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>

<ul>
<li><code>add_param_group()</code>ï¼šæ·»åŠ å‚æ•°ç»„</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_param_group</span>(<span class="params">self, param_group</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(param_group, <span class="built_in">dict</span>), <span class="string">&quot;param group must be a dict&quot;</span></span><br><span class="line"><span class="comment"># æ£€æŸ¥ç±»å‹æ˜¯å¦ä¸ºtensor</span></span><br><span class="line">    params = param_group[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(params, torch.Tensor):</span><br><span class="line">        param_group[<span class="string">&#x27;params&#x27;</span>] = [params]</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(params, <span class="built_in">set</span>):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">&#x27;optimizer parameters need to be organized in ordered collections, but &#x27;</span></span><br><span class="line">                        <span class="string">&#x27;the ordering of tensors in sets will change between runs. Please use a list instead.&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        param_group[<span class="string">&#x27;params&#x27;</span>] = <span class="built_in">list</span>(params)</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> param_group[<span class="string">&#x27;params&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(param, torch.Tensor):</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&quot;optimizer can only optimize Tensors, &quot;</span></span><br><span class="line">                            <span class="string">&quot;but one of the params is &quot;</span> + torch.typename(param))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> param.is_leaf:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;can&#x27;t optimize a non-leaf Tensor&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name, default <span class="keyword">in</span> self.defaults.items():</span><br><span class="line">        <span class="keyword">if</span> default <span class="keyword">is</span> required <span class="keyword">and</span> name <span class="keyword">not</span> <span class="keyword">in</span> param_group:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;parameter group didn&#x27;t specify a value of required optimization parameter &quot;</span> +</span><br><span class="line">                             name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            param_group.setdefault(name, default)</span><br><span class="line"></span><br><span class="line">    params = param_group[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(params) != <span class="built_in">len</span>(<span class="built_in">set</span>(params)):</span><br><span class="line">        warnings.warn(<span class="string">&quot;optimizer contains a parameter group with duplicate parameters; &quot;</span></span><br><span class="line">                      <span class="string">&quot;in future, this will cause an error; &quot;</span></span><br><span class="line">                      <span class="string">&quot;see github.com/pytorch/pytorch/issues/40967 for more information&quot;</span>, stacklevel=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># ä¸Šé¢å¥½åƒéƒ½åœ¨è¿›è¡Œä¸€äº›ç±»çš„æ£€æµ‹ï¼ŒæŠ¥Warningå’ŒError</span></span><br><span class="line">    param_set = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> self.param_groups:</span><br><span class="line">        param_set.update(<span class="built_in">set</span>(group[<span class="string">&#x27;params&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> param_set.isdisjoint(<span class="built_in">set</span>(param_group[<span class="string">&#x27;params&#x27;</span>])):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;some parameters appear in more than one parameter group&quot;</span>)</span><br><span class="line"><span class="comment"># æ·»åŠ å‚æ•°</span></span><br><span class="line">    self.param_groups.append(param_group)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>load_state_dict()</code> ï¼šåŠ è½½çŠ¶æ€å‚æ•°å­—å…¸ï¼Œå¯ä»¥ç”¨æ¥è¿›è¡Œæ¨¡å‹çš„æ–­ç‚¹ç»­è®­ç»ƒï¼Œç»§ç»­ä¸Šæ¬¡çš„å‚æ•°è¿›è¡Œè®­ç»ƒ</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_state_dict</span>(<span class="params">self, state_dict</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Loads the optimizer state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        state_dict (dict): optimizer state. Should be an object returned</span></span><br><span class="line"><span class="string">            from a call to :meth:`state_dict`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># deepcopy, to be consistent with module API</span></span><br><span class="line">    state_dict = deepcopy(state_dict)</span><br><span class="line">    <span class="comment"># Validate the state_dict</span></span><br><span class="line">    groups = self.param_groups</span><br><span class="line">    saved_groups = state_dict[<span class="string">&#x27;param_groups&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(groups) != <span class="built_in">len</span>(saved_groups):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;loaded state dict has a different number of &quot;</span></span><br><span class="line">                         <span class="string">&quot;parameter groups&quot;</span>)</span><br><span class="line">    param_lens = (<span class="built_in">len</span>(g[<span class="string">&#x27;params&#x27;</span>]) <span class="keyword">for</span> g <span class="keyword">in</span> groups)</span><br><span class="line">    saved_lens = (<span class="built_in">len</span>(g[<span class="string">&#x27;params&#x27;</span>]) <span class="keyword">for</span> g <span class="keyword">in</span> saved_groups)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">any</span>(p_len != s_len <span class="keyword">for</span> p_len, s_len <span class="keyword">in</span> <span class="built_in">zip</span>(param_lens, saved_lens)):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;loaded state dict contains a parameter group &quot;</span></span><br><span class="line">                         <span class="string">&quot;that doesn&#x27;t match the size of optimizer&#x27;s group&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update the state</span></span><br><span class="line">    id_map = &#123;old_id: p <span class="keyword">for</span> old_id, p <span class="keyword">in</span></span><br><span class="line">              <span class="built_in">zip</span>(chain.from_iterable((g[<span class="string">&#x27;params&#x27;</span>] <span class="keyword">for</span> g <span class="keyword">in</span> saved_groups)),</span><br><span class="line">                  chain.from_iterable((g[<span class="string">&#x27;params&#x27;</span>] <span class="keyword">for</span> g <span class="keyword">in</span> groups)))&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cast</span>(<span class="params">param, value</span>):</span></span><br><span class="line">        <span class="string">r&quot;&quot;&quot;Make a deep copy of value, casting all tensors to device of param.&quot;&quot;&quot;</span></span><br><span class="line">   		.....</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Copy state assigned to params (and cast tensors to appropriate types).</span></span><br><span class="line">    <span class="comment"># State that is not assigned to params is copied as is (needed for</span></span><br><span class="line">    <span class="comment"># backward compatibility).</span></span><br><span class="line">    state = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> state_dict[<span class="string">&#x27;state&#x27;</span>].items():</span><br><span class="line">        <span class="keyword">if</span> k <span class="keyword">in</span> id_map:</span><br><span class="line">            param = id_map[k]</span><br><span class="line">            state[param] = cast(param, v)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            state[k] = v</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update parameter groups, setting their &#x27;params&#x27; value</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_group</span>(<span class="params">group, new_group</span>):</span></span><br><span class="line">       ...</span><br><span class="line">    param_groups = [</span><br><span class="line">        update_group(g, ng) <span class="keyword">for</span> g, ng <span class="keyword">in</span> <span class="built_in">zip</span>(groups, saved_groups)]</span><br><span class="line">    self.__setstate__(&#123;<span class="string">&#x27;state&#x27;</span>: state, <span class="string">&#x27;param_groups&#x27;</span>: param_groups&#125;)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>state_dict()</code>ï¼šè·å–ä¼˜åŒ–å™¨å½“å‰çŠ¶æ€ä¿¡æ¯å­—å…¸</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Returns the state of the optimizer as a :class:`dict`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It contains two entries:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    * state - a dict holding current optimization state. Its content</span></span><br><span class="line"><span class="string">        differs between optimizer classes.</span></span><br><span class="line"><span class="string">    * param_groups - a dict containing all parameter groups</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Save order indices instead of Tensors</span></span><br><span class="line">    param_mappings = &#123;&#125;</span><br><span class="line">    start_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pack_group</span>(<span class="params">group</span>):</span></span><br><span class="line">		......</span><br><span class="line">    param_groups = [pack_group(g) <span class="keyword">for</span> g <span class="keyword">in</span> self.param_groups]</span><br><span class="line">    <span class="comment"># Remap state to use order indices as keys</span></span><br><span class="line">    packed_state = &#123;(param_mappings[<span class="built_in">id</span>(k)] <span class="keyword">if</span> <span class="built_in">isinstance</span>(k, torch.Tensor) <span class="keyword">else</span> k): v</span><br><span class="line">                    <span class="keyword">for</span> k, v <span class="keyword">in</span> self.state.items()&#125;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;state&#x27;</span>: packed_state,</span><br><span class="line">        <span class="string">&#x27;param_groups&#x27;</span>: param_groups,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="å®é™…æ“ä½œ"><a href="#å®é™…æ“ä½œ" class="headerlink" title="å®é™…æ“ä½œ"></a>å®é™…æ“ä½œ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®æƒé‡ï¼Œæœä»æ­£æ€åˆ†å¸ƒ  --&gt; 2 x 2</span></span><br><span class="line">weight = torch.randn((<span class="number">2</span>, <span class="number">2</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># è®¾ç½®æ¢¯åº¦ä¸ºå…¨1çŸ©é˜µ  --&gt; 2 x 2</span></span><br><span class="line">weight.grad = torch.ones((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># è¾“å‡ºç°æœ‰çš„weightå’Œdata</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The data of weight before step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.data))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The grad of weight before step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.grad))</span><br><span class="line"><span class="comment"># å®ä¾‹åŒ–ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = torch.optim.SGD([weight], lr=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># è¿›è¡Œä¸€æ­¥æ“ä½œ</span></span><br><span class="line">optimizer.step()</span><br><span class="line"><span class="comment"># æŸ¥çœ‹è¿›è¡Œä¸€æ­¥åçš„å€¼ï¼Œæ¢¯åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The data of weight after step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.data))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The grad of weight after step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.grad))</span><br><span class="line"><span class="comment"># æƒé‡æ¸…é›¶</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"><span class="comment"># æ£€éªŒæƒé‡æ˜¯å¦ä¸º0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The grad of weight after optimizer.zero_grad():\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.grad))</span><br><span class="line"><span class="comment"># è¾“å‡ºå‚æ•°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;optimizer.params_group is \n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups))</span><br><span class="line"><span class="comment"># æŸ¥çœ‹å‚æ•°ä½ç½®ï¼Œoptimizerå’Œweightçš„ä½ç½®ä¸€æ ·ï¼Œæˆ‘è§‰å¾—è¿™é‡Œå¯ä»¥å‚è€ƒPythonæ˜¯åŸºäºå€¼ç®¡ç†</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weight in optimizer:&#123;&#125;\nweight in weight:&#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(<span class="built_in">id</span>(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;params&#x27;</span>][<span class="number">0</span>]), <span class="built_in">id</span>(weight)))</span><br><span class="line"><span class="comment"># æ·»åŠ å‚æ•°ï¼šweight2</span></span><br><span class="line">weight2 = torch.randn((<span class="number">3</span>, <span class="number">3</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">optimizer.add_param_group(&#123;<span class="string">&quot;params&quot;</span>: weight2, <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line"><span class="comment"># æŸ¥çœ‹ç°æœ‰çš„å‚æ•°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;optimizer.param_groups is\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups))</span><br><span class="line"><span class="comment"># æŸ¥çœ‹å½“å‰çŠ¶æ€ä¿¡æ¯</span></span><br><span class="line">opt_state_dict = optimizer.state_dict()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;state_dict before step:\n&quot;</span>, opt_state_dict)</span><br><span class="line"><span class="comment"># è¿›è¡Œ5æ¬¡stepæ“ä½œ</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    optimizer.step()</span><br><span class="line"><span class="comment"># è¾“å‡ºç°æœ‰çŠ¶æ€ä¿¡æ¯</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;state_dict after step:\n&quot;</span>, optimizer.state_dict())</span><br><span class="line"><span class="comment"># ä¿å­˜å‚æ•°ä¿¡æ¯</span></span><br><span class="line">torch.save(optimizer.state_dict(),os.path.join(<span class="string">r&quot;D:\pythonProject\Attention_Unet&quot;</span>, <span class="string">&quot;optimizer_state_dict.pkl&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------done-----------&quot;</span>)</span><br><span class="line"><span class="comment"># åŠ è½½å‚æ•°ä¿¡æ¯</span></span><br><span class="line">state_dict = torch.load(<span class="string">r&quot;D:\pythonProject\Attention_Unet\optimizer_state_dict.pkl&quot;</span>) <span class="comment"># éœ€è¦ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„è·¯å¾„</span></span><br><span class="line">optimizer.load_state_dict(state_dict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;load state_dict successfully\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(state_dict))</span><br><span class="line"><span class="comment"># è¾“å‡ºæœ€åå±æ€§ä¿¡æ¯</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.defaults))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.state))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups))</span><br></pre></td></tr></table></figure>

<h2 id="è¾“å‡ºç»“æœ"><a href="#è¾“å‡ºç»“æœ" class="headerlink" title="è¾“å‡ºç»“æœ"></a>è¾“å‡ºç»“æœ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°å‰çš„æ•°æ®ï¼Œæ¢¯åº¦</span></span><br><span class="line">The data of weight before step:</span><br><span class="line">tensor([[-<span class="number">0.3077</span>, -<span class="number">0.1808</span>],</span><br><span class="line">        [-<span class="number">0.7462</span>, -<span class="number">1.5556</span>]])</span><br><span class="line">The grad of weight before step:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°åçš„æ•°æ®ï¼Œæ¢¯åº¦</span></span><br><span class="line">The data of weight after step:</span><br><span class="line">tensor([[-<span class="number">0.4077</span>, -<span class="number">0.2808</span>],</span><br><span class="line">        [-<span class="number">0.8462</span>, -<span class="number">1.6556</span>]])</span><br><span class="line">The grad of weight after step:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="comment"># è¿›è¡Œæ¢¯åº¦æ¸…é›¶çš„æ¢¯åº¦</span></span><br><span class="line">The grad of weight after optimizer.zero_grad():</span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"><span class="comment"># è¾“å‡ºä¿¡æ¯</span></span><br><span class="line">optimizer.params_group <span class="keyword">is</span> </span><br><span class="line">[&#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">0.4077</span>, -<span class="number">0.2808</span>],</span><br><span class="line">        [-<span class="number">0.8462</span>, -<span class="number">1.6556</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯æ˜äº†ä¼˜åŒ–å™¨çš„å’Œweightçš„å‚¨å­˜æ˜¯åœ¨ä¸€ä¸ªåœ°æ–¹ï¼ŒPythonåŸºäºå€¼ç®¡ç†</span></span><br><span class="line">weight <span class="keyword">in</span> optimizer:<span class="number">1841923407424</span></span><br><span class="line">weight <span class="keyword">in</span> weight:<span class="number">1841923407424</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># è¾“å‡ºå‚æ•°</span></span><br><span class="line">optimizer.param_groups <span class="keyword">is</span></span><br><span class="line">[&#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">0.4077</span>, -<span class="number">0.2808</span>],</span><br><span class="line">        [-<span class="number">0.8462</span>, -<span class="number">1.6556</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;, &#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[ <span class="number">0.4539</span>, -<span class="number">2.1901</span>, -<span class="number">0.6662</span>],</span><br><span class="line">        [ <span class="number">0.6630</span>, -<span class="number">1.5178</span>, -<span class="number">0.8708</span>],</span><br><span class="line">        [-<span class="number">2.0222</span>,  <span class="number">1.4573</span>,  <span class="number">0.8657</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°å‰çš„å‚æ•°æŸ¥çœ‹ï¼Œç”¨state_dict</span></span><br><span class="line">state_dict before step:</span><br><span class="line"> &#123;<span class="string">&#x27;state&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])&#125;&#125;, <span class="string">&#x27;param_groups&#x27;</span>: [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">0</span>]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">1</span>]&#125;]&#125;</span><br><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°åçš„å‚æ•°æŸ¥çœ‹ï¼Œç”¨state_dict</span></span><br><span class="line">state_dict after step:</span><br><span class="line"> &#123;<span class="string">&#x27;state&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;, <span class="string">&#x27;param_groups&#x27;</span>: [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">0</span>]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">1</span>]&#125;]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># å­˜å‚¨ä¿¡æ¯å®Œæ¯•</span></span><br><span class="line">----------done-----------</span><br><span class="line"><span class="comment"># åŠ è½½å‚æ•°ä¿¡æ¯æˆåŠŸ</span></span><br><span class="line">load state_dict successfully</span><br><span class="line"><span class="comment"># åŠ è½½å‚æ•°ä¿¡æ¯</span></span><br><span class="line">&#123;<span class="string">&#x27;state&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;, <span class="string">&#x27;param_groups&#x27;</span>: [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">0</span>]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">1</span>]&#125;]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># defaultsçš„å±æ€§è¾“å‡º</span></span><br><span class="line">&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># stateå±æ€§è¾“å‡º</span></span><br><span class="line">defaultdict(&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">dict</span>&#x27;&gt;, &#123;<span class="title">tensor</span>(<span class="params">[[-<span class="number">1.3031</span>, -<span class="number">1.1761</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">        [-<span class="number">1.7415</span>, -<span class="number">2.5510</span>]], requires_grad=<span class="literal">True</span></span>):</span> &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># param_groupså±æ€§è¾“å‡º</span></span><br><span class="line">[&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">1.3031</span>, -<span class="number">1.1761</span>],</span><br><span class="line">        [-<span class="number">1.7415</span>, -<span class="number">2.5510</span>]], requires_grad=<span class="literal">True</span>)]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [tensor([[ <span class="number">0.4539</span>, -<span class="number">2.1901</span>, -<span class="number">0.6662</span>],</span><br><span class="line">        [ <span class="number">0.6630</span>, -<span class="number">1.5178</span>, -<span class="number">0.8708</span>],</span><br><span class="line">        [-<span class="number">2.0222</span>,  <span class="number">1.4573</span>,  <span class="number">0.8657</span>]], requires_grad=<span class="literal">True</span>)]&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>æ³¨æ„ï¼š</strong></p>
<ol>
<li><p>æ¯ä¸ªä¼˜åŒ–å™¨éƒ½æ˜¯ä¸€ä¸ªç±»ï¼Œæˆ‘ä»¬ä¸€å®šè¦è¿›è¡Œå®ä¾‹åŒ–æ‰èƒ½ä½¿ç”¨ï¼Œæ¯”å¦‚ä¸‹æ–¹å®ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Moddule</span>):</span></span><br><span class="line">    Â·Â·Â·</span><br><span class="line">net = Net()</span><br><span class="line">optim = torch.optim.SGD(net.parameters(),lr=lr)</span><br><span class="line">optim.step()</span><br></pre></td></tr></table></figure>
</li>
<li><p>optimizeråœ¨ä¸€ä¸ªç¥ç»ç½‘ç»œçš„epochä¸­éœ€è¦å®ç°ä¸‹é¢ä¸¤ä¸ªæ­¥éª¤ï¼š</p>
<ol>
<li>æ¢¯åº¦ç½®é›¶</li>
<li>æ¢¯åº¦æ›´æ–°<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">1e-5</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH):</span><br><span class="line">	...</span><br><span class="line">	optimizer.zero_grad()  <span class="comment">#æ¢¯åº¦ç½®é›¶</span></span><br><span class="line">	loss = ...             <span class="comment">#è®¡ç®—loss</span></span><br><span class="line">	loss.backward()        <span class="comment">#BPåå‘ä¼ æ’­</span></span><br><span class="line">	optimizer.step()       <span class="comment">#æ¢¯åº¦æ›´æ–°</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>ç»™ç½‘ç»œä¸åŒçš„å±‚èµ‹äºˆä¸åŒçš„ä¼˜åŒ–å™¨å‚æ•°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"></span><br><span class="line">net = resnet18()</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([</span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>:net.fc.parameters()&#125;,<span class="comment">#fcçš„lrä½¿ç”¨é»˜è®¤çš„1e-5</span></span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>:net.layer4[<span class="number">0</span>].conv1.parameters(),<span class="string">&#x27;lr&#x27;</span>:<span class="number">1e-2</span>&#125;],lr=<span class="number">1e-5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯ä»¥ä½¿ç”¨param_groupsæŸ¥çœ‹å±æ€§</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><p>ä¸ºäº†æ›´å¥½çš„äº†è§£ä¼˜åŒ–å™¨ï¼Œå¯¹PyTorchä¸­çš„ä¼˜åŒ–å™¨è¿›è¡Œäº†ä¸€ä¸ªå°æµ‹è¯•</p>
<p><strong>æ•°æ®ç”Ÿæˆ</strong>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line"><span class="comment"># å‡ç»´æ“ä½œ</span></span><br><span class="line">x = torch.unsqueeze(a, dim=<span class="number">1</span>)</span><br><span class="line">y = x.<span class="built_in">pow</span>(<span class="number">2</span>) + <span class="number">0.1</span> * torch.normal(torch.zeros(x.size()))</span><br></pre></td></tr></table></figure>

<p><strong>æ•°æ®åˆ†å¸ƒæ›²çº¿</strong>ï¼š<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.6.1.png"></p>
<p><strong>ç½‘ç»œç»“æ„</strong>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line">        self.predict = nn.Linear(<span class="number">20</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.hidden(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.predict(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ä¸‹é¢è¿™éƒ¨åˆ†æ˜¯æµ‹è¯•å›¾ï¼Œçºµåæ ‡ä»£è¡¨Lossï¼Œæ¨ªåæ ‡ä»£è¡¨çš„æ˜¯Stepï¼š<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.6.2.png"><br>åœ¨ä¸Šé¢çš„å›¾ç‰‡ä¸Šï¼Œæ›²çº¿ä¸‹é™çš„è¶‹åŠ¿å’Œå¯¹åº”çš„stepsä»£è¡¨äº†åœ¨è¿™è½®æ•°æ®ï¼Œæ¨¡å‹ä¸‹çš„æ”¶æ•›é€Ÿåº¦</p>
<p><strong>æ³¨æ„:</strong></p>
<p>ä¼˜åŒ–å™¨çš„é€‰æ‹©æ˜¯éœ€è¦æ ¹æ®æ¨¡å‹è¿›è¡Œæ”¹å˜çš„ï¼Œä¸å­˜åœ¨ç»å¯¹çš„å¥½åä¹‹åˆ†ï¼Œæˆ‘ä»¬éœ€è¦å¤šè¿›è¡Œä¸€äº›æµ‹è¯•ã€‚<br>åç»­ä¼šæ·»åŠ SparseAdamï¼ŒLBFGSè¿™ä¸¤ä¸ªä¼˜åŒ–å™¨çš„å¯è§†åŒ–ç»“æœ</p>
<h2 id="ä¸ƒã€-è®­ç»ƒä¸è¯„ä¼°"><a href="#ä¸ƒã€-è®­ç»ƒä¸è¯„ä¼°" class="headerlink" title="ä¸ƒã€ è®­ç»ƒä¸è¯„ä¼°"></a>ä¸ƒã€ è®­ç»ƒä¸è¯„ä¼°</h2><p>å…³æ³¨ä¸¤è€…çš„ä¸»è¦åŒºåˆ«ï¼š<br>æ¨¡å‹çŠ¶æ€è®¾ç½®<br>æ˜¯å¦éœ€è¦åˆå§‹åŒ–ä¼˜åŒ–å™¨<br>æ˜¯å¦éœ€è¦å°†lossä¼ å›åˆ°ç½‘ç»œ<br>æ˜¯å¦éœ€è¦æ¯æ­¥æ›´æ–°optimizer<br>æ­¤å¤–ï¼Œå¯¹äºæµ‹è¯•æˆ–éªŒè¯è¿‡ç¨‹ï¼Œå¯ä»¥è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        data, label = data.cuda(), label.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data) <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line">        loss.backward() <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">        optimizer.step() <span class="comment"># ä¼˜åŒ–å™¨æ›´æ–°æƒé‡</span></span><br><span class="line">        train_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    train_loss = train_loss/<span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss))</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val</span>(<span class="params">epoch</span>):</span>       </span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># æµ‹è¯•å’Œè®­ç»ƒä¸ä¸€æ ·</span></span><br><span class="line">    val_loss = <span class="number">0</span></span><br><span class="line">    gt_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment"># ä¸è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, label = data.cuda(), label.cuda()</span><br><span class="line">            output = model(data)</span><br><span class="line">            preds = torch.argmax(output, <span class="number">1</span>) <span class="comment"># å¾—åˆ°é¢„æµ‹çš„ç»“æœæ˜¯å“ªä¸€ç±»</span></span><br><span class="line">            gt_labels.append(label.cpu().data.numpy()) <span class="comment"># æ‹¼æ¥èµ·æ¥</span></span><br><span class="line">            pred_labels.append(preds.cpu().data.numpy())</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            val_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    val_loss = val_loss/<span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)</span><br><span class="line">    acc = np.<span class="built_in">sum</span>(gt_labels==pred_labels)/<span class="built_in">len</span>(pred_labels) <span class="comment"># preå’Œlabelç›¸ç­‰çš„æ¬¡æ•°é™¤ä¸Šæ€»æ•°</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tValidation Loss: &#123;:.6f&#125;, Accuracy: &#123;:6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, val_loss, acc))</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs+<span class="number">1</span>):</span><br><span class="line">    train(epoch)</span><br><span class="line">    val(epoch)</span><br></pre></td></tr></table></figure>
<p><img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665568130565/D2B5CA33BD970F64A6301FA75AE2EB22"></p>
<h2 id="å…«ã€-å¯è§†åŒ–"><a href="#å…«ã€-å¯è§†åŒ–" class="headerlink" title="å…«ã€ å¯è§†åŒ–"></a>å…«ã€ å¯è§†åŒ–</h2><p>è§åç»­ä¸“é¢˜</p>
<h2 id="ä¹ã€-ä¿å­˜æ¨¡å‹"><a href="#ä¹ã€-ä¿å­˜æ¨¡å‹" class="headerlink" title="ä¹ã€ ä¿å­˜æ¨¡å‹"></a>ä¹ã€ ä¿å­˜æ¨¡å‹</h2><p>è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨torch.saveä¿å­˜æ¨¡å‹å‚æ•°æˆ–è€…æ•´ä¸ªæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜æ¨¡å‹:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">save_path = <span class="string">&quot;./FahionModel.pkl&quot;</span></span><br><span class="line">torch.save(model, save_path)</span><br></pre></td></tr></table></figure>
<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%B8%89%E7%AB%A0/3.4%20%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA.html">æ·±å…¥æµ…å‡ºPyTorch</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ</p><p><a href="http://example.com/2022/10/12/pytorch-å„ä¸ªç»„ä»¶å’Œå®è·µ/">http://example.com/2022/10/12/pytorch-å„ä¸ªç»„ä»¶å’Œå®è·µ/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>ä½œè€…</h6><p>Yang</p></div></div><div class="level-item is-narrow"><div><h6>å‘å¸ƒäº</h6><p>2022-10-12</p></div></div><div class="level-item is-narrow"><div><h6>æ›´æ–°äº</h6><p>2022-10-12</p></div></div><div class="level-item is-narrow"><div><h6>è®¸å¯åè®®</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Pytorch/">Pytorch</a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><div class="social-share"></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Ÿæ‰“èµä¸€ä¸‹ä½œè€…å§</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>æ”¯ä»˜å®</span><span class="qrcode"><img src="/img/alipay.png" alt="æ”¯ä»˜å®"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>å¾®ä¿¡</span><span class="qrcode"><img src="/img/wechat.png" alt="å¾®ä¿¡"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/10/16/pytorch-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">pytorch - æ¨¡å‹å®šä¹‰</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/10/10/pytorch-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="level-item">pytorch - åŸºç¡€çŸ¥è¯†</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">è¯„è®º</h3><div class="content" id="valine-thread"></div><script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.16/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "5g2Ywva8lFU3cYbP8uFyl0s7-gzGzoHsz",
            appKey: "6X4LgAqvfozBP061RrUMebFP",
            
            avatar: "mm",
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: false,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="ğŸ"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">ğŸ</p><p class="is-size-6 is-block">DubistmeinAugenstern</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>WuHan,China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ–‡ç« </p><a href="/archives"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">åˆ†ç±»</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ ‡ç­¾</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Yang-Emily" target="_blank" rel="noopener">å…³æ³¨æˆ‘</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Yang-Emily"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/wuyangemily/"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Youtube" href="https://www.youtube.com/channel/UCSnojGpH9om-xzl-og2_AZQ/featured"><i class="fab fa-youtube"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="twitter" href="https://twitter.com/YangWu00506105"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1047772929&amp;site=qq&amp;menu=yes"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">ç›®å½•</h3><ul class="menu-list"><li><a class="level is-mobile" href="#ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶"><span class="level-left"><span class="level-item">1</span><span class="level-item">ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶</span></span></a></li><li><a class="level is-mobile" href="#æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§"><span class="level-left"><span class="level-item">2</span><span class="level-item">æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§</span></span></a></li><li><a class="level is-mobile" href="#pytorchæ·±åº¦å­¦ä¹ æ¨¡å—"><span class="level-left"><span class="level-item">3</span><span class="level-item">pytorchæ·±åº¦å­¦ä¹ æ¨¡å—</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#ä¸€ã€-åŸºæœ¬é…ç½®"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">ä¸€ã€ åŸºæœ¬é…ç½®</span></span></a></li><li><a class="level is-mobile" href="#äºŒã€-æ•°æ®è¯»å…¥"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">äºŒã€ æ•°æ®è¯»å…¥</span></span></a></li><li><a class="level is-mobile" href="#ä¸‰ã€-æ¨¡å‹æ„å»º"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">ä¸‰ã€ æ¨¡å‹æ„å»º</span></span></a></li><li><a class="level is-mobile" href="#å››ã€-æ¨¡å‹åˆå§‹åŒ–"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">å››ã€ æ¨¡å‹åˆå§‹åŒ–</span></span></a></li><li><a class="level is-mobile" href="#äº”ã€-æŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5</span><span class="level-item">äº”ã€ æŸå¤±å‡½æ•°</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#1-äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.1</span><span class="level-item">1. äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#2-äº¤å‰ç†µæŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.2</span><span class="level-item">2. äº¤å‰ç†µæŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#3-L1æŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.3</span><span class="level-item">3. L1æŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#4-MSEæŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.4</span><span class="level-item">4. MSEæŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#5-å¹³æ»‘L1-Smooth-L1-æŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.5</span><span class="level-item">5. å¹³æ»‘L1 (Smooth L1)æŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#6-ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±"><span class="level-left"><span class="level-item">3.5.6</span><span class="level-item">6. ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±</span></span></a></li><li><a class="level is-mobile" href="#7-KLæ•£åº¦"><span class="level-left"><span class="level-item">3.5.7</span><span class="level-item">7. KLæ•£åº¦</span></span></a></li><li><a class="level is-mobile" href="#8-MarginRankingLoss"><span class="level-left"><span class="level-item">3.5.8</span><span class="level-item">8. MarginRankingLoss</span></span></a></li><li><a class="level is-mobile" href="#9-å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.9</span><span class="level-item">9. å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#10-äºŒåˆ†ç±»æŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.10</span><span class="level-item">10. äºŒåˆ†ç±»æŸå¤±å‡½æ•°</span></span></a></li><li><a class="level is-mobile" href="#11-å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±"><span class="level-left"><span class="level-item">3.5.11</span><span class="level-item">11. å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±</span></span></a></li><li><a class="level is-mobile" href="#12-ä¸‰å…ƒç»„æŸå¤±"><span class="level-left"><span class="level-item">3.5.12</span><span class="level-item">12. ä¸‰å…ƒç»„æŸå¤±</span></span></a></li><li><a class="level is-mobile" href="#13-HingEmbeddingLoss"><span class="level-left"><span class="level-item">3.5.13</span><span class="level-item">13. HingEmbeddingLoss</span></span></a></li><li><a class="level is-mobile" href="#14-ä½™å¼¦ç›¸ä¼¼åº¦"><span class="level-left"><span class="level-item">3.5.14</span><span class="level-item">14. ä½™å¼¦ç›¸ä¼¼åº¦</span></span></a></li><li><a class="level is-mobile" href="#15-CTCæŸå¤±å‡½æ•°"><span class="level-left"><span class="level-item">3.5.15</span><span class="level-item">15.CTCæŸå¤±å‡½æ•°</span></span></a></li></ul></li><li><a class="level is-mobile" href="#å…­ã€-ä¼˜åŒ–å™¨"><span class="level-left"><span class="level-item">3.6</span><span class="level-item">å…­ã€ ä¼˜åŒ–å™¨</span></span></a></li><li><a class="level is-mobile" href="#å®é™…æ“ä½œ"><span class="level-left"><span class="level-item">3.7</span><span class="level-item">å®é™…æ“ä½œ</span></span></a></li><li><a class="level is-mobile" href="#è¾“å‡ºç»“æœ"><span class="level-left"><span class="level-item">3.8</span><span class="level-item">è¾“å‡ºç»“æœ</span></span></a></li><li><a class="level is-mobile" href="#å®éªŒ"><span class="level-left"><span class="level-item">3.9</span><span class="level-item">å®éªŒ</span></span></a></li><li><a class="level is-mobile" href="#ä¸ƒã€-è®­ç»ƒä¸è¯„ä¼°"><span class="level-left"><span class="level-item">3.10</span><span class="level-item">ä¸ƒã€ è®­ç»ƒä¸è¯„ä¼°</span></span></a></li><li><a class="level is-mobile" href="#å…«ã€-å¯è§†åŒ–"><span class="level-left"><span class="level-item">3.11</span><span class="level-item">å…«ã€ å¯è§†åŒ–</span></span></a></li><li><a class="level is-mobile" href="#ä¹ã€-ä¿å­˜æ¨¡å‹"><span class="level-left"><span class="level-item">3.12</span><span class="level-item">ä¹ã€ ä¿å­˜æ¨¡å‹</span></span></a></li></ul></li><li><a class="level is-mobile" href="#å‚è€ƒèµ„æ–™"><span class="level-left"><span class="level-item">4</span><span class="level-item">å‚è€ƒèµ„æ–™</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">é“¾æ¥</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://leetcode-cn.com/u/wuyangemily/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Leetcode</span></span><span class="level-right"><span class="level-item tag">leetcode-cn.com</span></span></a></li><li><a class="level is-mobile" href="https://blog.csdn.net/qq_44729001" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">blog.csdn.net</span></span></a></li><li><a class="level is-mobile" href="https://www.kaggle.com/wuyangemily" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Kaggle</span></span><span class="level-right"><span class="level-item tag">www.kaggle.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">åˆ†ç±»</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E5%AD%A6/"><span class="level-start"><span class="level-item">æ•°å­¦</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">æœºå™¨å­¦ä¹ </span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9D%82/"><span class="level-start"><span class="level-item">æ‚</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">æ·±åº¦å­¦ä¹ </span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">æ·±åº¦å¼ºåŒ–å­¦ä¹ </span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">è‡ªç„¶è¯­è¨€å¤„ç†</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">è®ºæ–‡é˜…è¯»</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">æœ€æ–°æ–‡ç« </h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-23T06:43:54.000Z">2022-10-23</time></p><p class="title"><a href="/2022/10/23/pytorch-%E7%94%9F%E6%80%81%E9%83%A8%E7%BD%B2/">pytorch - ç”Ÿæ€å’Œéƒ¨ç½²</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-22T06:43:54.000Z">2022-10-22</time></p><p class="title"><a href="/2022/10/22/pytorch-%E5%8F%AF%E8%A7%86%E5%8C%96/">pytorch - å¯è§†åŒ–</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-20T06:43:54.000Z">2022-10-20</time></p><p class="title"><a href="/2022/10/20/pytorch-%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">pytorch - è®­ç»ƒæŠ€å·§</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-16T06:43:54.000Z">2022-10-16</time></p><p class="title"><a href="/2022/10/16/pytorch-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89/">pytorch - æ¨¡å‹å®šä¹‰</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-12T06:43:54.000Z">2022-10-12</time></p><p class="title"><a href="/2022/10/12/pytorch-%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E5%92%8C%E5%AE%9E%E8%B7%B5/">pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">å½’æ¡£</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">åæœˆ 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">ä¹æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">å…«æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">å…­æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">ä¸‰æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">åæœˆ 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/08/"><span class="level-start"><span class="level-item">å…«æœˆ 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">ä¸€æœˆ 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">æ ‡ç­¾</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DRL/"><span class="tag">DRL</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Draft/"><span class="tag">Draft</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Intelligence-Code/"><span class="tag">Intelligence Code</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">6</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="ğŸ&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Yang</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Yang-Emily/Yang-Emily.github.io"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="å›åˆ°é¡¶ç«¯" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "æ­¤ç½‘ç«™ä½¿ç”¨Cookieæ¥æ”¹å–„æ‚¨çš„ä½“éªŒã€‚",
          dismiss: "çŸ¥é“äº†ï¼",
          allow: "å…è®¸ä½¿ç”¨Cookie",
          deny: "æ‹’ç»",
          link: "äº†è§£æ›´å¤š",
          policy: "Cookieæ”¿ç­–",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ...","untitled":"(æ— æ ‡é¢˜)","posts":"æ–‡ç« ","pages":"é¡µé¢","categories":"åˆ†ç±»","tags":"æ ‡ç­¾"});
        });</script></body></html>