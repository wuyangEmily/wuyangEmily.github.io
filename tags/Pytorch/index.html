<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>æ ‡ç­¾: Pytorch - ğŸ&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="ğŸ&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="ğŸ&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="ğŸ&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="ğŸ&#039;s Blog"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Yang"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"ğŸ's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Yang"},"publisher":{"@type":"Organization","name":"ğŸ's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/logo.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="ğŸ&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">ä¸»é¡µ</a><a class="navbar-item" href="/archives">å½’æ¡£</a><a class="navbar-item" href="/categories">åˆ†ç±»</a><a class="navbar-item" href="/tags">æ ‡ç­¾</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Yang-Emily/Yang-Emily.github.io"><i class="fab fa-github"></i></a><a class="navbar-item search" title="æœç´¢" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">æ ‡ç­¾</a></li><li class="is-active"><a href="#" aria-current="page">Pytorch</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-23T06:43:54.000Z" title="2022/10/23 ä¸‹åˆ2:43:54">2022-10-23</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-23T08:10:43.559Z" title="2022/10/23 ä¸‹åˆ4:10:43">2022-10-23</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">18 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦2763ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/23/pytorch-%E7%94%9F%E6%80%81%E9%83%A8%E7%BD%B2/">pytorch - ç”Ÿæ€å’Œéƒ¨ç½²</a></h1><div class="content"><h1 id="1-ç”Ÿæ€"><a href="#1-ç”Ÿæ€" class="headerlink" title="1 ç”Ÿæ€"></a>1 ç”Ÿæ€</h1><p>PyTorchç”Ÿæ€åœ¨å›¾åƒã€è§†é¢‘ã€æ–‡æœ¬ç­‰é¢†åŸŸä¸­çš„å‘å±•ã€‚</p>
<h2 id="1-1-torchvision"><a href="#1-1-torchvision" class="headerlink" title="1.1 torchvision"></a>1.1 torchvision</h2><p>torchvisionåŒ…å«äº†åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¸¸å¸¸ç”¨åˆ°çš„æ•°æ®é›†ï¼Œæ¨¡å‹å’Œå›¾åƒå¤„ç†çš„æ–¹å¼ã€‚</p>
<ol>
<li>torchvision.datasets *<br>torchvision.datasetsä¸»è¦åŒ…å«äº†ä¸€äº›æˆ‘ä»¬åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¸¸è§çš„æ•°æ®é›†</li>
<li>torchvision.models *<br><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html">å„ç§é¢„è®­ç»ƒå¥½çš„æ¨¡å‹</a></li>
<li>torchvision.tramsforms *<br><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">å›¾åƒå¤„ç†çš„æ–¹æ³•</a></li>
<li>torchvision.io<br>åœ¨torchvision.ioæä¾›äº†è§†é¢‘ã€å›¾ç‰‡å’Œæ–‡ä»¶çš„ IO æ“ä½œçš„åŠŸèƒ½ï¼Œå®ƒä»¬åŒ…æ‹¬è¯»å–ã€å†™å…¥ã€ç¼–è§£ç å¤„ç†æ“ä½œã€‚éšç€torchvisionçš„å‘å±•ï¼Œioä¹Ÿå¢åŠ äº†æ›´å¤šåº•å±‚çš„é«˜æ•ˆç‡çš„APIã€‚</li>
<li>torchvision.ops<br><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/ops.html">torchvision.ops</a> ä¸ºæˆ‘ä»¬æä¾›äº†è®¸å¤šè®¡ç®—æœºè§†è§‰çš„ç‰¹å®šæ“ä½œï¼ŒåŒ…æ‹¬ä½†ä¸ä»…é™äºNMSï¼ŒRoIAlignï¼ˆMASK R-CNNä¸­åº”ç”¨çš„ä¸€ç§æ–¹æ³•ï¼‰ï¼ŒRoIPoolï¼ˆFast R-CNNä¸­ç”¨åˆ°çš„ä¸€ç§æ–¹æ³•ï¼‰ã€‚åœ¨åˆé€‚çš„æ—¶é—´ä½¿ç”¨å¯ä»¥å¤§å¤§é™ä½æˆ‘ä»¬çš„å·¥ä½œé‡ï¼Œé¿å…é‡å¤çš„é€ è½®å­ã€‚</li>
<li>torchvision.utils<br><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/utils.html">torchvision.utils</a> ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€äº›å¯è§†åŒ–çš„æ–¹æ³•ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬å°†è‹¥å¹²å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€èµ·ã€å¯è§†åŒ–æ£€æµ‹å’Œåˆ†å‰²çš„æ•ˆæœã€‚</li>
</ol>
<h2 id="1-2-PyTorchVideo"><a href="#1-2-PyTorchVideo" class="headerlink" title="1.2 PyTorchVideo"></a>1.2 PyTorchVideo</h2><p><a target="_blank" rel="noopener" href="https://pytorchvideo.readthedocs.io/en/latest/index.html">PyTorchVideo</a> æ˜¯ä¸€ä¸ªä¸“æ³¨äºè§†é¢‘ç†è§£å·¥ä½œçš„æ·±åº¦å­¦ä¹ åº“ã€‚<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/list.png"></p>
<h2 id="1-3-torchtext"><a href="#1-3-torchtext" class="headerlink" title="1.3 torchtext"></a>1.3 torchtext</h2><p>ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„å·¥å…·åŒ…torchtextã€‚æ–¹ä¾¿çš„å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œä¾‹å¦‚æˆªæ–­è¡¥é•¿ã€æ„å»ºè¯è¡¨ç­‰ã€‚</p>
<ol>
<li>æ„å»ºæ•°æ®é›†<ul>
<li>FieldåŠå…¶ä½¿ç”¨<br> Fieldæ˜¯torchtextä¸­å®šä¹‰æ•°æ®ç±»å‹ä»¥åŠè½¬æ¢ä¸ºå¼ é‡çš„æŒ‡ä»¤ã€‚torchtext è®¤ä¸ºä¸€ä¸ªæ ·æœ¬æ˜¯ç”±å¤šä¸ªå­—æ®µï¼ˆæ–‡æœ¬å­—æ®µï¼Œæ ‡ç­¾å­—æ®µï¼‰ç»„æˆï¼Œä¸åŒçš„å­—æ®µå¯èƒ½ä¼šæœ‰ä¸åŒçš„å¤„ç†æ–¹å¼ï¼Œæ‰€ä»¥æ‰ä¼šæœ‰ Field æŠ½è±¡ã€‚å®šä¹‰Fieldå¯¹è±¡æ˜¯ä¸ºäº†æ˜ç¡®å¦‚ä½•å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®ï¼Œä½†å…·ä½“çš„å¤„ç†åˆ™æ˜¯åœ¨Datasetä¸­å®Œæˆçš„ã€‚ <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenize = <span class="keyword">lambda</span> x: x.split()</span><br><span class="line">TEXT = data.Field(sequential=<span class="literal">True</span>, tokenize=tokenize, lower=<span class="literal">True</span>, fix_length=<span class="number">200</span>)</span><br><span class="line">LABEL = data.Field(sequential=<span class="literal">False</span>, use_vocab=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
 sequentialè®¾ç½®æ•°æ®æ˜¯å¦æ˜¯é¡ºåºè¡¨ç¤ºçš„ï¼›<br> â€‹tokenizeç”¨äºè®¾ç½®å°†å­—ç¬¦ä¸²æ ‡è®°ä¸ºé¡ºåºå®ä¾‹çš„å‡½æ•°;<br> â€‹lowerè®¾ç½®æ˜¯å¦å°†å­—ç¬¦ä¸²å…¨éƒ¨è½¬ä¸ºå°å†™ï¼›<br> â€‹fix_lengthè®¾ç½®æ­¤å­—æ®µæ‰€æœ‰å®ä¾‹éƒ½å°†å¡«å……åˆ°ä¸€ä¸ªå›ºå®šçš„é•¿åº¦ï¼Œæ–¹ä¾¿åç»­å¤„ç†ï¼›<br> â€‹use_vocabè®¾ç½®æ˜¯å¦å¼•å…¥Vocab objectï¼Œå¦‚æœä¸ºFalseï¼Œåˆ™éœ€è¦ä¿è¯ä¹‹åè¾“å…¥fieldä¸­çš„dataéƒ½æ˜¯numericalçš„;<br> æ„å»ºFieldå®Œæˆåå°±å¯ä»¥è¿›ä¸€æ­¥æ„å»ºdatasetäº† <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span>(<span class="params">csv_data, text_field, label_field, test=<span class="literal">False</span></span>):</span></span><br><span class="line">    fields = [(<span class="string">&quot;id&quot;</span>, <span class="literal">None</span>), <span class="comment"># we won&#x27;t be needing the id, so we pass in None as the field</span></span><br><span class="line">                (<span class="string">&quot;comment_text&quot;</span>, text_field), (<span class="string">&quot;toxic&quot;</span>, label_field)]       </span><br><span class="line">    examples = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> test:</span><br><span class="line">        <span class="comment"># å¦‚æœä¸ºæµ‹è¯•é›†ï¼Œåˆ™ä¸åŠ è½½label</span></span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> tqdm(csv_data[<span class="string">&#x27;comment_text&#x27;</span>]):</span><br><span class="line">            examples.append(data.Example.fromlist([<span class="literal">None</span>, text, <span class="literal">None</span>], fields))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> text, label <span class="keyword">in</span> tqdm(<span class="built_in">zip</span>(csv_data[<span class="string">&#x27;comment_text&#x27;</span>], csv_data[<span class="string">&#x27;toxic&#x27;</span>])):</span><br><span class="line">            examples.append(data.Example.fromlist([<span class="literal">None</span>, text, label], fields))</span><br><span class="line">    <span class="keyword">return</span> examples, fields</span><br></pre></td></tr></table></figure>
 è¿™é‡Œä½¿ç”¨æ•°æ®csv_dataä¸­æœ‰â€comment_textâ€å’Œâ€toxicâ€ä¸¤åˆ—ï¼Œåˆ†åˆ«å¯¹åº”textå’Œlabel <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">&#x27;train_toxic_comments.csv&#x27;</span>)</span><br><span class="line">valid_data = pd.read_csv(<span class="string">&#x27;valid_toxic_comments.csv&#x27;</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">&quot;test_toxic_comments.csv&quot;</span>)</span><br><span class="line">TEXT = data.Field(sequential=<span class="literal">True</span>, tokenize=tokenize, lower=<span class="literal">True</span>)</span><br><span class="line">LABEL = data.Field(sequential=<span class="literal">False</span>, use_vocab=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¾—åˆ°æ„å»ºDatasetæ‰€éœ€çš„exampleså’Œfields</span></span><br><span class="line">train_examples, train_fields = get_dataset(train_data, TEXT, LABEL)</span><br><span class="line">valid_examples, valid_fields = get_dataset(valid_data, TEXT, LABEL)</span><br><span class="line">test_examples, test_fields = get_dataset(test_data, TEXT, <span class="literal">None</span>, test=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># æ„å»ºDatasetæ•°æ®é›†</span></span><br><span class="line">train = data.Dataset(train_examples, train_fields)</span><br><span class="line">valid = data.Dataset(valid_examples, valid_fields)</span><br><span class="line">test = data.Dataset(test_examples, test_fields)</span><br></pre></td></tr></table></figure>
 å¯ä»¥çœ‹åˆ°ï¼Œå®šä¹‰Fieldå¯¹è±¡å®Œæˆåï¼Œé€šè¿‡get_datasetå‡½æ•°å¯ä»¥è¯»å…¥æ•°æ®çš„æ–‡æœ¬å’Œæ ‡ç­¾ï¼Œå°†äºŒè€…ï¼ˆexamplesï¼‰è¿åŒfieldä¸€èµ·é€åˆ°torchtext.data.Datasetç±»ä¸­ï¼Œå³å¯å®Œæˆæ•°æ®é›†çš„æ„å»ºã€‚ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ä»¥çœ‹ä¸‹è¯»å…¥çš„æ•°æ®æƒ…å†µ <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ£€æŸ¥keysæ˜¯å¦æ­£ç¡®</span></span><br><span class="line"><span class="built_in">print</span>(train[<span class="number">0</span>].__dict__.keys())</span><br><span class="line"><span class="built_in">print</span>(test[<span class="number">0</span>].__dict__.keys())</span><br><span class="line"><span class="comment"># æŠ½æŸ¥å†…å®¹æ˜¯å¦æ­£ç¡®</span></span><br><span class="line"><span class="built_in">print</span>(train[<span class="number">0</span>].comment_text)</span><br></pre></td></tr></table></figure></li>
<li>è¯æ±‡è¡¨ï¼ˆvocabï¼‰<br> Word Embedding çš„åŸºæœ¬æ€æƒ³æ˜¯æ”¶é›†ä¸€ä¸ªæ¯”è¾ƒå¤§çš„è¯­æ–™åº“ï¼ˆå°½é‡ä¸æ‰€åšçš„ä»»åŠ¡ç›¸å…³ï¼‰ï¼Œåœ¨è¯­æ–™åº“ä¸­ä½¿ç”¨word2vecä¹‹ç±»çš„æ–¹æ³•æ„å»ºè¯è¯­åˆ°å‘é‡ï¼ˆæˆ–æ•°å­—ï¼‰çš„æ˜ å°„å…³ç³»ï¼Œä¹‹åå°†è¿™ä¸€æ˜ å°„å…³ç³»åº”ç”¨äºå½“å‰çš„ä»»åŠ¡ï¼Œå°†å¥å­ä¸­çš„è¯è¯­è½¬ä¸ºå‘é‡è¡¨ç¤ºã€‚åœ¨torchtextä¸­å¯ä»¥ä½¿ç”¨Fieldè‡ªå¸¦çš„build_vocabå‡½æ•°å®Œæˆè¯æ±‡è¡¨æ„å»ºã€‚ <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TEXT.build_vocab(train)</span><br></pre></td></tr></table></figure></li>
<li>æ•°æ®è¿­ä»£å™¨<br> ç›¸å½“äºdataloader <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext.data <span class="keyword">import</span> Iterator, BucketIterator</span><br><span class="line"><span class="comment"># è‹¥åªé’ˆå¯¹è®­ç»ƒé›†æ„é€ è¿­ä»£å™¨</span></span><br><span class="line"><span class="comment"># train_iter = data.BucketIterator(dataset=train, batch_size=8, shuffle=True, sort_within_batch=False, repeat=False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åŒæ—¶å¯¹è®­ç»ƒé›†å’ŒéªŒè¯é›†è¿›è¡Œè¿­ä»£å™¨çš„æ„å»º</span></span><br><span class="line">train_iter, val_iter = BucketIterator.splits(</span><br><span class="line">        (train, valid), <span class="comment"># æ„å»ºæ•°æ®é›†æ‰€éœ€çš„æ•°æ®é›†</span></span><br><span class="line">        batch_sizes=(<span class="number">8</span>, <span class="number">8</span>),</span><br><span class="line">        device=-<span class="number">1</span>, <span class="comment"># å¦‚æœä½¿ç”¨gpuï¼Œæ­¤å¤„å°†-1æ›´æ¢ä¸ºGPUçš„ç¼–å·</span></span><br><span class="line">        sort_key=<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x.comment_text), <span class="comment"># the BucketIterator needs to be told what function it should use to group the data.</span></span><br><span class="line">        sort_within_batch=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_iter = Iterator(test, batch_size=<span class="number">8</span>, device=-<span class="number">1</span>, sort=<span class="literal">False</span>, sort_within_batch=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></li>
<li>ä½¿ç”¨è‡ªå¸¦æ•°æ®é›†<br> <a target="_blank" rel="noopener" href="https://pytorch.org/text/stable/datasets.html">è‹¥å¹²å¸¸ç”¨çš„æ•°æ®é›†</a></li>
</ul>
</li>
<li>è¯„æµ‹æŒ‡æ ‡ï¼ˆmetricï¼‰<br>NLPä¸­éƒ¨åˆ†ä»»åŠ¡çš„è¯„æµ‹ä¸æ˜¯é€šè¿‡å‡†ç¡®ç‡ç­‰æŒ‡æ ‡å®Œæˆçš„ï¼Œæ¯”å¦‚æœºå™¨ç¿»è¯‘ä»»åŠ¡å¸¸ç”¨BLEU (bilingual evaluation understudy) scoreæ¥è¯„ä»·é¢„æµ‹æ–‡æœ¬å’Œæ ‡ç­¾æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚torchtextä¸­å¯ä»¥ç›´æ¥è°ƒç”¨torchtext.data.metrics.bleu_scoreæ¥å¿«é€Ÿå®ç°BLEU<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext.data.metrics <span class="keyword">import</span> bleu_score</span><br><span class="line">candidate_corpus = [[<span class="string">&#x27;My&#x27;</span>, <span class="string">&#x27;full&#x27;</span>, <span class="string">&#x27;pytorch&#x27;</span>, <span class="string">&#x27;test&#x27;</span>], [<span class="string">&#x27;Another&#x27;</span>, <span class="string">&#x27;Sentence&#x27;</span>]]</span><br><span class="line">references_corpus = [[[<span class="string">&#x27;My&#x27;</span>, <span class="string">&#x27;full&#x27;</span>, <span class="string">&#x27;pytorch&#x27;</span>, <span class="string">&#x27;test&#x27;</span>], [<span class="string">&#x27;Completely&#x27;</span>, <span class="string">&#x27;Different&#x27;</span>]], [[<span class="string">&#x27;No&#x27;</span>, <span class="string">&#x27;Match&#x27;</span>]]]</span><br><span class="line">bleu_score(candidate_corpus, references_corpus)</span><br></pre></td></tr></table></figure></li>
<li>å…¶ä»–<br>ç”±äºNLPå¸¸ç”¨çš„ç½‘ç»œç»“æ„æ¯”è¾ƒå›ºå®šï¼Œtorchtextå¹¶ä¸åƒtorchvisioné‚£æ ·æä¾›ä¸€ç³»åˆ—å¸¸ç”¨çš„ç½‘ç»œç»“æ„ã€‚æ¨¡å‹ä¸»è¦é€šè¿‡torch.nnä¸­çš„æ¨¡å—æ¥å®ç°ï¼Œæ¯”å¦‚torch.nn.LSTMã€torch.nn.RNNç­‰ã€‚</li>
</ol>
<h1 id="2-æ¨¡å‹éƒ¨ç½²"><a href="#2-æ¨¡å‹éƒ¨ç½²" class="headerlink" title="2 æ¨¡å‹éƒ¨ç½²"></a>2 æ¨¡å‹éƒ¨ç½²</h1><p>å°†PyTorchè®­ç»ƒå¥½çš„æ¨¡å‹è½¬æ¢ä¸ºONNX æ ¼å¼ï¼Œç„¶åä½¿ç”¨ONNX Runtimeè¿è¡Œå®ƒè¿›è¡Œæ¨ç†ã€‚å°†å¾—åˆ°çš„æƒé‡è¿›è¡Œå˜æ¢æ‰èƒ½ä½¿æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æˆåŠŸéƒ¨ç½²åœ¨ä¸Šè¿°è®¾å¤‡ä¸Šã€‚<br><img src="https://niuzhikang.oss-cn-chengdu.aliyuncs.com/figures/202208052139305.jpg"></p>
<h2 id="2-1-ä½¿ç”¨ONNXè¿›è¡Œéƒ¨ç½²å¹¶æ¨ç†"><a href="#2-1-ä½¿ç”¨ONNXè¿›è¡Œéƒ¨ç½²å¹¶æ¨ç†" class="headerlink" title="2.1 ä½¿ç”¨ONNXè¿›è¡Œéƒ¨ç½²å¹¶æ¨ç†"></a>2.1 ä½¿ç”¨ONNXè¿›è¡Œéƒ¨ç½²å¹¶æ¨ç†</h2><p>ONNX Runtime æ˜¯ç”±å¾®è½¯ç»´æŠ¤çš„ä¸€ä¸ªè·¨å¹³å°æœºå™¨å­¦ä¹ æ¨ç†åŠ é€Ÿå™¨ï¼Œå®ƒç›´æ¥å¯¹æ¥ONNXï¼Œå¯ä»¥ç›´æ¥è¯»å–.onnxæ–‡ä»¶å¹¶å®ç°æ¨ç†ï¼Œä¸éœ€è¦å†æŠŠ .onnx æ ¼å¼çš„æ–‡ä»¶è½¬æ¢æˆå…¶ä»–æ ¼å¼çš„æ–‡ä»¶ã€‚PyTorchå€ŸåŠ©ONNX Runtimeä¹Ÿå®Œæˆäº†éƒ¨ç½²çš„æœ€åä¸€å…¬é‡Œï¼Œæ„å»ºäº† PyTorch â€“&gt; ONNX â€“&gt; ONNX Runtime éƒ¨ç½²æµæ°´çº¿ï¼Œæˆ‘ä»¬åªéœ€è¦å°†æ¨¡å‹è½¬æ¢ä¸º .onnx æ–‡ä»¶ï¼Œå¹¶åœ¨ ONNX Runtime ä¸Šè¿è¡Œæ¨¡å‹å³å¯ã€‚</p>
<h2 id="2-2-ONNXå’ŒONNX-Runtimeç®€ä»‹"><a href="#2-2-ONNXå’ŒONNX-Runtimeç®€ä»‹" class="headerlink" title="2.2 ONNXå’ŒONNX Runtimeç®€ä»‹"></a>2.2 ONNXå’ŒONNX Runtimeç®€ä»‹</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ</span></span><br><span class="line">conda activate env_name <span class="comment"># env_nameæ¢æˆç¯å¢ƒåç§°</span></span><br><span class="line"><span class="comment"># å®‰è£…onnx</span></span><br><span class="line">pip install onnx </span><br><span class="line"><span class="comment"># å®‰è£…onnx runtime</span></span><br><span class="line">pip install onnxruntime <span class="comment"># ä½¿ç”¨CPUè¿›è¡Œæ¨ç†</span></span><br><span class="line"><span class="comment"># pip install onnxruntime-gpu # ä½¿ç”¨GPUè¿›è¡Œæ¨ç†</span></span><br></pre></td></tr></table></figure>

<h2 id="2-3-æ¨¡å‹å¯¼å‡ºä¸ºONNX"><a href="#2-3-æ¨¡å‹å¯¼å‡ºä¸ºONNX" class="headerlink" title="2.3 æ¨¡å‹å¯¼å‡ºä¸ºONNX"></a>2.3 æ¨¡å‹å¯¼å‡ºä¸ºONNX</h2><ol>
<li>æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.onnx </span><br><span class="line"><span class="comment"># è½¬æ¢çš„onnxæ ¼å¼çš„åç§°ï¼Œæ–‡ä»¶åç¼€éœ€ä¸º.onnx</span></span><br><span class="line">onnx_file_name = <span class="string">&quot;xxxxxx.onnx&quot;</span></span><br><span class="line"><span class="comment"># æˆ‘ä»¬éœ€è¦è½¬æ¢çš„æ¨¡å‹ï¼Œå°†torch_modelè®¾ç½®ä¸ºè‡ªå·±çš„æ¨¡å‹</span></span><br><span class="line">model = torch_model</span><br><span class="line"><span class="comment"># åŠ è½½æƒé‡ï¼Œå°†model.pthè½¬æ¢ä¸ºè‡ªå·±çš„æ¨¡å‹æƒé‡</span></span><br><span class="line"><span class="comment"># å¦‚æœæ¨¡å‹çš„æƒé‡æ˜¯ä½¿ç”¨å¤šå¡è®­ç»ƒå‡ºæ¥ï¼Œæˆ‘ä»¬éœ€è¦å»é™¤æƒé‡ä¸­å¤šçš„module. å…·ä½“æ“ä½œå¯ä»¥è§5.4èŠ‚</span></span><br><span class="line">model = model.load_state_dict(torch.load(<span class="string">&quot;model.pth&quot;</span>))</span><br><span class="line"><span class="comment"># å¯¼å‡ºæ¨¡å‹å‰ï¼Œå¿…é¡»è°ƒç”¨model.eval()æˆ–è€…model.train(False)</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># dummy_inputå°±æ˜¯ä¸€ä¸ªè¾“å…¥çš„å®ä¾‹ï¼Œä»…æä¾›è¾“å…¥shapeã€typeç­‰ä¿¡æ¯ </span></span><br><span class="line">batch_size = <span class="number">1</span> <span class="comment"># éšæœºçš„å–å€¼ï¼Œå½“è®¾ç½®dynamic_axesåå½±å“ä¸å¤§</span></span><br><span class="line">dummy_input = torch.randn(batch_size, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, requires_grad=<span class="literal">True</span>) </span><br><span class="line"><span class="comment"># è¿™ç»„è¾“å…¥å¯¹åº”çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line">output = model(dummy_input)</span><br><span class="line"><span class="comment"># å¯¼å‡ºæ¨¡å‹</span></span><br><span class="line">torch.onnx.export(model,        <span class="comment"># æ¨¡å‹çš„åç§°</span></span><br><span class="line">                  dummy_input,   <span class="comment"># ä¸€ç»„å®ä¾‹åŒ–è¾“å…¥</span></span><br><span class="line">                  onnx_file_name,   <span class="comment"># æ–‡ä»¶ä¿å­˜è·¯å¾„/åç§°</span></span><br><span class="line">                  export_params=<span class="literal">True</span>,        <span class="comment">#  å¦‚æœæŒ‡å®šä¸ºTrueæˆ–é»˜è®¤, å‚æ•°ä¹Ÿä¼šè¢«å¯¼å‡º. å¦‚æœä½ è¦å¯¼å‡ºä¸€ä¸ªæ²¡è®­ç»ƒè¿‡çš„å°±è®¾ä¸º False.</span></span><br><span class="line">                  opset_version=<span class="number">10</span>,          <span class="comment"># ONNX ç®—å­é›†çš„ç‰ˆæœ¬ï¼Œå½“å‰å·²æ›´æ–°åˆ°15</span></span><br><span class="line">                  do_constant_folding=<span class="literal">True</span>,  <span class="comment"># æ˜¯å¦æ‰§è¡Œå¸¸é‡æŠ˜å ä¼˜åŒ–</span></span><br><span class="line">                  input_names = [<span class="string">&#x27;input&#x27;</span>],   <span class="comment"># è¾“å…¥æ¨¡å‹çš„å¼ é‡çš„åç§°</span></span><br><span class="line">                  output_names = [<span class="string">&#x27;output&#x27;</span>], <span class="comment"># è¾“å‡ºæ¨¡å‹çš„å¼ é‡çš„åç§°</span></span><br><span class="line">                  <span class="comment"># dynamic_axeså°†batch_sizeçš„ç»´åº¦æŒ‡å®šä¸ºåŠ¨æ€ï¼Œ</span></span><br><span class="line">                  <span class="comment"># åç»­è¿›è¡Œæ¨ç†çš„æ•°æ®å¯ä»¥ä¸å¯¼å‡ºçš„dummy_inputçš„batch_sizeä¸åŒ</span></span><br><span class="line">                  dynamic_axes=&#123;<span class="string">&#x27;input&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;,    </span><br><span class="line">                                <span class="string">&#x27;output&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;&#125;)</span><br></pre></td></tr></table></figure></li>
<li>ONNXæ¨¡å‹çš„æ£€éªŒ<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="comment"># æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¼‚å¸¸å¤„ç†çš„æ–¹æ³•è¿›è¡Œæ£€éªŒ</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># å½“æˆ‘ä»¬çš„æ¨¡å‹ä¸å¯ç”¨æ—¶ï¼Œå°†ä¼šæŠ¥å‡ºå¼‚å¸¸</span></span><br><span class="line">    onnx.checker.check_model(self.onnx_model)</span><br><span class="line"><span class="keyword">except</span> onnx.checker.ValidationError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The model is invalid: %s&quot;</span>%e)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># æ¨¡å‹å¯ç”¨æ—¶ï¼Œå°†ä¸ä¼šæŠ¥å‡ºå¼‚å¸¸ï¼Œå¹¶ä¼šè¾“å‡ºâ€œThe model is valid!â€</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The model is valid!&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li>ONNXå¯è§†åŒ–<br><a target="_blank" rel="noopener" href="https://github.com/lutzroeder/netron">Netron</a></li>
</ol>
<h2 id="2-4-ä½¿ç”¨ONNX-Runtimeè¿›è¡Œæ¨ç†"><a href="#2-4-ä½¿ç”¨ONNX-Runtimeè¿›è¡Œæ¨ç†" class="headerlink" title="2.4 ä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç†"></a>2.4 ä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç†</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¼å…¥onnxruntime</span></span><br><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"><span class="comment"># éœ€è¦è¿›è¡Œæ¨ç†çš„onnxæ¨¡å‹æ–‡ä»¶åç§°</span></span><br><span class="line">onnx_file_name = <span class="string">&quot;xxxxxx.onnx&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># onnxruntime.InferenceSessionç”¨äºè·å–ä¸€ä¸ª ONNX Runtime æ¨ç†å™¨</span></span><br><span class="line">ort_session = onnxruntime.InferenceSession(onnx_file_name)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºå­—å…¸çš„è¾“å…¥æ•°æ®ï¼Œå­—å…¸çš„keyéœ€è¦ä¸æˆ‘ä»¬æ„å»ºonnxæ¨¡å‹æ—¶çš„input_namesç›¸åŒ</span></span><br><span class="line"><span class="comment"># è¾“å…¥çš„input_img ä¹Ÿéœ€è¦æ”¹å˜ä¸ºndarrayæ ¼å¼</span></span><br><span class="line">ort_inputs = &#123;<span class="string">&#x27;input&#x27;</span>: input_img&#125; </span><br><span class="line"><span class="comment"># æˆ‘ä»¬æ›´å»ºè®®ä½¿ç”¨ä¸‹é¢è¿™ç§æ–¹æ³•,å› ä¸ºé¿å…äº†æ‰‹åŠ¨è¾“å…¥key</span></span><br><span class="line"><span class="comment"># ort_inputs = &#123;ort_session.get_inputs()[0].name:input_img&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># runæ˜¯è¿›è¡Œæ¨¡å‹çš„æ¨ç†ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºè¾“å‡ºå¼ é‡åçš„åˆ—è¡¨ï¼Œä¸€èˆ¬æƒ…å†µå¯ä»¥è®¾ç½®ä¸ºNone</span></span><br><span class="line"><span class="comment"># ç¬¬äºŒä¸ªå‚æ•°ä¸ºæ„å»ºçš„è¾“å…¥å€¼çš„å­—å…¸</span></span><br><span class="line"><span class="comment"># ç”±äºè¿”å›çš„ç»“æœè¢«åˆ—è¡¨åµŒå¥—ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è¿›è¡Œ[0]çš„ç´¢å¼•</span></span><br><span class="line">ort_output = ort_session.run(<span class="literal">None</span>,ort_inputs)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># output = &#123;ort_session.get_outputs()[0].name&#125;</span></span><br><span class="line"><span class="comment"># ort_output = ort_session.run([output], ort_inputs)[0]</span></span><br></pre></td></tr></table></figure>
<ul>
<li>PyTorchæ¨¡å‹çš„è¾“å…¥ä¸ºtensorï¼Œè€ŒONNXçš„è¾“å…¥ä¸ºarrayï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¯¹å¼ é‡è¿›è¡Œå˜æ¢æˆ–è€…ç›´æ¥å°†æ•°æ®è¯»å–ä¸ºarrayæ ¼å¼ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ä¸‹é¢çš„æ–¹å¼è¿›è¡Œå¼ é‡åˆ°arrayçš„è½¬åŒ–ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_numpy</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tensor.detach().cpu().numpy() <span class="keyword">if</span> tensor.requires_grad <span class="keyword">else</span> tensor.cpu().numpy()</span><br></pre></td></tr></table></figure></li>
<li>è¾“å…¥çš„arrayçš„shapeåº”è¯¥å’Œæˆ‘ä»¬å¯¼å‡ºæ¨¡å‹çš„dummy_inputçš„shapeç›¸åŒï¼Œå¦‚æœå›¾ç‰‡å¤§å°ä¸ä¸€æ ·ï¼Œæˆ‘ä»¬åº”è¯¥å…ˆè¿›è¡Œresizeæ“ä½œã€‚</li>
<li>runçš„ç»“æœæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œç´¢å¼•æ“ä½œæ‰èƒ½è·å¾—arrayæ ¼å¼çš„ç»“æœã€‚</li>
<li>åœ¨æ„å»ºè¾“å…¥çš„å­—å…¸æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ³¨æ„å­—å…¸çš„keyåº”ä¸å¯¼å‡ºONNXæ ¼å¼è®¾ç½®çš„input_nameç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬æ›´å»ºè®®ä½¿ç”¨ä¸Šè¿°çš„ç¬¬äºŒç§æ–¹æ³•æ„å»ºè¾“å…¥çš„å­—å…¸ã€‚</li>
</ul>
<h2 id="2-5-ä»£ç å®æˆ˜"><a href="#2-5-ä»£ç å®æˆ˜" class="headerlink" title="2.5 ä»£ç å®æˆ˜"></a>2.5 ä»£ç å®æˆ˜</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html">pytorch- EXPORTING A MODEL FROM PYTORCH TO ONNX AND RUNNING IT USING ONNX RUNTIME</a></p>
<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E5%85%AB%E7%AB%A0/index.html">æ·±å…¥æµ…å‡ºPyTorch</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-22T06:43:54.000Z" title="2022/10/22 ä¸‹åˆ2:43:54">2022-10-22</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-21T17:12:18.246Z" title="2022/10/22 ä¸Šåˆ1:12:18">2022-10-22</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">9 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦1366ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/22/pytorch-%E5%8F%AF%E8%A7%86%E5%8C%96/">pytorch - å¯è§†åŒ–</a></h1><div class="content"><h1 id="å¯è§†åŒ–ç½‘ç»œç»“æ„"><a href="#å¯è§†åŒ–ç½‘ç»œç»“æ„" class="headerlink" title="å¯è§†åŒ–ç½‘ç»œç»“æ„"></a>å¯è§†åŒ–ç½‘ç»œç»“æ„</h1><ol>
<li>ä½¿ç”¨printå‡½æ•°æ‰“å°æ¨¡å‹åŸºç¡€ä¿¡æ¯<br>åªèƒ½å¾—å‡ºåŸºç¡€æ„ä»¶çš„ä¿¡æ¯ï¼Œæ—¢ä¸èƒ½æ˜¾ç¤ºå‡ºæ¯ä¸€å±‚çš„shapeï¼Œä¹Ÿä¸èƒ½æ˜¾ç¤ºå¯¹åº”å‚æ•°é‡çš„å¤§å°<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">model = models.resnet18()</span><br></pre></td></tr></table></figure></li>
<li>ä½¿ç”¨torchinfoå¯è§†åŒ–ç½‘ç»œç»“æ„<br>è¾“å‡ºç»“æ„åŒ–çš„æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¨¡å—ä¿¡æ¯ï¼ˆæ¯ä¸€å±‚çš„ç±»å‹ã€è¾“å‡ºshapeå’Œå‚æ•°é‡ï¼‰ã€æ¨¡å‹æ•´ä½“çš„å‚æ•°é‡ã€æ¨¡å‹å¤§å°ã€ä¸€æ¬¡å‰å‘æˆ–è€…åå‘ä¼ æ’­éœ€è¦çš„å†…å­˜å¤§å°ç­‰<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torchinfo <span class="keyword">import</span> summary</span><br><span class="line">resnet18 = models.resnet18() <span class="comment"># å®ä¾‹åŒ–æ¨¡å‹</span></span><br><span class="line">summary(resnet18, (<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)) <span class="comment"># 1ï¼šbatch_size 3:å›¾ç‰‡çš„é€šé“æ•° 224: å›¾ç‰‡çš„é«˜å®½</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="CNNå¯è§†åŒ–"><a href="#CNNå¯è§†åŒ–" class="headerlink" title="CNNå¯è§†åŒ–"></a>CNNå¯è§†åŒ–</h1><ol>
<li>CNNå·ç§¯æ ¸å¯è§†åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> vgg11</span><br><span class="line"></span><br><span class="line">model = vgg11(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">dict</span>(model.features.named_children()))</span><br><span class="line">conv1 = <span class="built_in">dict</span>(model.features.named_children())[<span class="string">&#x27;3&#x27;</span>]</span><br><span class="line">kernel_set = conv1.weight.detach()</span><br><span class="line">num = <span class="built_in">len</span>(conv1.weight.detach())</span><br><span class="line"><span class="built_in">print</span>(kernel_set.shape)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,num):</span><br><span class="line">    i_kernel = kernel_set[i]</span><br><span class="line">    plt.figure(figsize=(<span class="number">20</span>, <span class="number">17</span>))</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(i_kernel)) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> idx, filer <span class="keyword">in</span> <span class="built_in">enumerate</span>(i_kernel):</span><br><span class="line">            plt.subplot(<span class="number">9</span>, <span class="number">9</span>, idx+<span class="number">1</span>) </span><br><span class="line">            plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">            plt.imshow(filer[ :, :].detach(),cmap=<span class="string">&#x27;bwr&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li>CNNç‰¹å¾å›¾å¯è§†åŒ–æ–¹æ³•<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Hook</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.module_name = []</span><br><span class="line">        self.features_in_hook = []</span><br><span class="line">        self.features_out_hook = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self,module, fea_in, fea_out</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;hooker working&quot;</span>, self)</span><br><span class="line">        self.module_name.append(module.__class__)</span><br><span class="line">        self.features_in_hook.append(fea_in)</span><br><span class="line">        self.features_out_hook.append(fea_out)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_feature</span>(<span class="params">model, idx, inputs</span>):</span></span><br><span class="line">    hh = Hook()</span><br><span class="line">    model.features[idx].register_forward_hook(hh)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># forward_model(model,False)</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    _ = model(inputs)</span><br><span class="line">    <span class="built_in">print</span>(hh.module_name)</span><br><span class="line">    <span class="built_in">print</span>((hh.features_in_hook[<span class="number">0</span>][<span class="number">0</span>].shape))</span><br><span class="line">    <span class="built_in">print</span>((hh.features_out_hook[<span class="number">0</span>].shape))</span><br><span class="line">    </span><br><span class="line">    out1 = hh.features_out_hook[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    total_ft  = out1.shape[<span class="number">1</span>]</span><br><span class="line">    first_item = out1[<span class="number">0</span>].cpu().clone()    </span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">20</span>, <span class="number">17</span>))</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ftidx <span class="keyword">in</span> <span class="built_in">range</span>(total_ft):</span><br><span class="line">        <span class="keyword">if</span> ftidx &gt; <span class="number">99</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        ft = first_item[ftidx]</span><br><span class="line">        plt.subplot(<span class="number">10</span>, <span class="number">10</span>, ftidx+<span class="number">1</span>) </span><br><span class="line">        </span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        <span class="comment">#plt.imshow(ft[ :, :].detach(),cmap=&#x27;gray&#x27;)</span></span><br><span class="line">        plt.imshow(ft[ :, :].detach())</span><br></pre></td></tr></table></figure></li>
<li>CNN class activation mapå¯è§†åŒ–æ–¹æ³•<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> vgg11,resnet18,resnet101,resnext101_32x8d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">model = vgg11(pretrained=<span class="literal">True</span>)</span><br><span class="line">img_path = <span class="string">&#x27;./dog.png&#x27;</span></span><br><span class="line"><span class="comment"># resizeæ“ä½œæ˜¯ä¸ºäº†å’Œä¼ å…¥ç¥ç»ç½‘ç»œè®­ç»ƒå›¾ç‰‡å¤§å°ä¸€è‡´</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path).resize((<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"><span class="comment"># éœ€è¦å°†åŸå§‹å›¾ç‰‡è½¬ä¸ºnp.float32æ ¼å¼å¹¶ä¸”åœ¨0-1ä¹‹é—´ </span></span><br><span class="line">rgb_img = np.float32(img)/<span class="number">255</span></span><br><span class="line">plt.imshow(img)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_grad_cam <span class="keyword">import</span> GradCAM,ScoreCAM,GradCAMPlusPlus,AblationCAM,XGradCAM,EigenCAM,FullGrad</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam.utils.model_targets <span class="keyword">import</span> ClassifierOutputTarget</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam.utils.image <span class="keyword">import</span> show_cam_on_image</span><br><span class="line"></span><br><span class="line">target_layers = [model.features[-<span class="number">1</span>]]</span><br><span class="line"><span class="comment"># é€‰å–åˆé€‚çš„ç±»æ¿€æ´»å›¾ï¼Œä½†æ˜¯ScoreCAMå’ŒAblationCAMéœ€è¦batch_size</span></span><br><span class="line">cam = GradCAM(model=model,target_layers=target_layers)</span><br><span class="line">targets = [ClassifierOutputTarget(preds)]   </span><br><span class="line"><span class="comment"># ä¸Šæ–¹predséœ€è¦è®¾å®šï¼Œæ¯”å¦‚ImageNetæœ‰1000ç±»ï¼Œè¿™é‡Œå¯ä»¥è®¾ä¸º200</span></span><br><span class="line">grayscale_cam = cam(input_tensor=img_tensor, targets=targets)</span><br><span class="line">grayscale_cam = grayscale_cam[<span class="number">0</span>, :]</span><br><span class="line">cam_img = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(cam_img))</span><br><span class="line">Image.fromarray(cam_img)</span><br></pre></td></tr></table></figure></li>
<li>ä½¿ç”¨FlashTorchå¿«é€Ÿå®ç°CNNå¯è§†åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download example images</span></span><br><span class="line"><span class="comment"># !mkdir -p images</span></span><br><span class="line"><span class="comment"># !wget -nv \</span></span><br><span class="line"><span class="comment">#    https://github.com/MisaOgura/flashtorch/raw/master/examples/images/great_grey_owl.jpg \</span></span><br><span class="line"><span class="comment">#    https://github.com/MisaOgura/flashtorch/raw/master/examples/images/peacock.jpg   \</span></span><br><span class="line"><span class="comment">#    https://github.com/MisaOgura/flashtorch/raw/master/examples/images/toucan.jpg    \</span></span><br><span class="line"><span class="comment">#    -P /content/images</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> flashtorch.utils <span class="keyword">import</span> apply_transforms, load_image</span><br><span class="line"><span class="keyword">from</span> flashtorch.saliency <span class="keyword">import</span> Backprop</span><br><span class="line"></span><br><span class="line">model = models.alexnet(pretrained=<span class="literal">True</span>)</span><br><span class="line">backprop = Backprop(model)</span><br><span class="line"></span><br><span class="line">image = load_image(<span class="string">&#x27;/content/images/great_grey_owl.jpg&#x27;</span>)</span><br><span class="line">owl = apply_transforms(image)</span><br><span class="line"></span><br><span class="line">target_class = <span class="number">24</span></span><br><span class="line">backprop.visualize(owl, target_class, guided=<span class="literal">True</span>, use_gpu=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> flashtorch.activmax <span class="keyword">import</span> GradientAscent</span><br><span class="line"></span><br><span class="line">model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">g_ascent = GradientAscent(model.features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># specify layer and filter info</span></span><br><span class="line">conv5_1 = model.features[<span class="number">24</span>]</span><br><span class="line">conv5_1_filters = [<span class="number">45</span>, <span class="number">271</span>, <span class="number">363</span>, <span class="number">489</span>]</span><br><span class="line"></span><br><span class="line">g_ascent.visualize(conv5_1, conv5_1_filters, title=<span class="string">&quot;VGG16: conv5_1&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="ä½¿ç”¨TensorBoardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹"><a href="#ä½¿ç”¨TensorBoardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹" class="headerlink" title="ä½¿ç”¨TensorBoardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹"></a>ä½¿ç”¨TensorBoardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹</h1><ol>
<li>TensorBoardå®‰è£…</li>
<li>TensorBoardå¯è§†åŒ–çš„åŸºæœ¬é€»è¾‘</li>
<li>TensorBoardçš„é…ç½®ä¸å¯åŠ¨</li>
<li>TensorBoardæ¨¡å‹ç»“æ„å¯è§†åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">32</span>,kernel_size = <span class="number">3</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size = <span class="number">2</span>,stride = <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">32</span>,out_channels=<span class="number">64</span>,kernel_size = <span class="number">5</span>)</span><br><span class="line">        self.adaptive_pool = nn.AdaptiveMaxPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">64</span>,<span class="number">32</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(<span class="number">32</span>,<span class="number">1</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = self.adaptive_pool(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.linear1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.linear2(x)</span><br><span class="line">        y = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">writer.add_graph(model, input_to_model = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li>
<li>TensorBoardå›¾åƒå¯è§†åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">transform_train = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor()])</span><br><span class="line">transform_test = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor()])</span><br><span class="line"></span><br><span class="line">train_data = datasets.CIFAR10(<span class="string">&quot;.&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform_train)</span><br><span class="line">test_data = datasets.CIFAR10(<span class="string">&quot;.&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform_test)</span><br><span class="line">train_loader = DataLoader(train_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_data, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># ä»…æŸ¥çœ‹ä¸€å¼ å›¾ç‰‡</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./pytorch_tb&#x27;</span>)</span><br><span class="line">writer.add_image(<span class="string">&#x27;images[0]&#x27;</span>, images[<span class="number">0</span>])</span><br><span class="line">writer.close()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># å°†å¤šå¼ å›¾ç‰‡æ‹¼æ¥æˆä¸€å¼ å›¾ç‰‡ï¼Œä¸­é—´ç”¨é»‘è‰²ç½‘æ ¼åˆ†å‰²</span></span><br><span class="line"><span class="comment"># create grid of images</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./pytorch_tb&#x27;</span>)</span><br><span class="line">img_grid = torchvision.utils.make_grid(images)</span><br><span class="line">writer.add_image(<span class="string">&#x27;image_grid&#x27;</span>, img_grid)</span><br><span class="line">writer.close()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># å°†å¤šå¼ å›¾ç‰‡ç›´æ¥å†™å…¥</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./pytorch_tb&#x27;</span>)</span><br><span class="line">writer.add_images(<span class="string">&quot;images&quot;</span>,images,global_step = <span class="number">0</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li>
<li>TensorBoardè¿ç»­å˜é‡å¯è§†åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">writer = SummaryWriter(<span class="string">&#x27;./pytorch_tb&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    x = i</span><br><span class="line">    y = x**<span class="number">2</span></span><br><span class="line">    writer.add_scalar(<span class="string">&quot;x&quot;</span>, x, i) <span class="comment">#æ—¥å¿—ä¸­è®°å½•xåœ¨ç¬¬step i çš„å€¼</span></span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y&quot;</span>, y, i) <span class="comment">#æ—¥å¿—ä¸­è®°å½•yåœ¨ç¬¬step i çš„å€¼</span></span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line">writer1 = SummaryWriter(<span class="string">&#x27;./pytorch_tb/x&#x27;</span>)</span><br><span class="line">writer2 = SummaryWriter(<span class="string">&#x27;./pytorch_tb/y&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    x = i</span><br><span class="line">    y = x*<span class="number">2</span></span><br><span class="line">    writer1.add_scalar(<span class="string">&quot;same&quot;</span>, x, i) <span class="comment">#æ—¥å¿—ä¸­è®°å½•xåœ¨ç¬¬step i çš„å€¼</span></span><br><span class="line">    writer2.add_scalar(<span class="string">&quot;same&quot;</span>, y, i) <span class="comment">#æ—¥å¿—ä¸­è®°å½•yåœ¨ç¬¬step i çš„å€¼</span></span><br><span class="line">writer1.close()</span><br><span class="line">writer2.close()</span><br></pre></td></tr></table></figure></li>
<li>TensorBoardå‚æ•°åˆ†å¸ƒå¯è§†åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºæ­£æ€åˆ†å¸ƒçš„å¼ é‡æ¨¡æ‹Ÿå‚æ•°çŸ©é˜µ</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">norm</span>(<span class="params">mean, std</span>):</span></span><br><span class="line">    t = std * torch.randn((<span class="number">100</span>, <span class="number">20</span>)) + mean</span><br><span class="line">    <span class="keyword">return</span> t</span><br><span class="line"> </span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./pytorch_tb/&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> step, mean <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">range</span>(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">1</span>)):</span><br><span class="line">    w = norm(mean, <span class="number">1</span>)</span><br><span class="line">    writer.add_histogram(<span class="string">&quot;w&quot;</span>, w, step)</span><br><span class="line">    writer.flush()</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li>
<li>æœåŠ¡å™¨ç«¯ä½¿ç”¨TensorBoard</li>
<li>æ€»ç»“<br>TensorBoardçš„åŸºæœ¬é€»è¾‘å°±æ˜¯æ–‡ä»¶çš„è¯»å†™é€»è¾‘ï¼Œå†™å…¥æƒ³è¦å¯è§†åŒ–çš„æ•°æ®ï¼Œç„¶åTensorBoardè‡ªå·±ä¼šè¯»å‡ºæ¥ã€‚<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%B8%83%E7%AB%A0/index.html">æ·±å…¥æµ…å‡ºPyTorch</a></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-20T06:43:54.000Z" title="2022/10/20 ä¸‹åˆ2:43:54">2022-10-20</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-19T16:59:07.090Z" title="2022/10/20 ä¸Šåˆ12:59:07">2022-10-20</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">21 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦3084ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/20/pytorch-%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">pytorch - è®­ç»ƒæŠ€å·§</a></h1><div class="content"><h1 id="è‡ªå®šä¹‰æŸå¤±å‡½æ•°"><a href="#è‡ªå®šä¹‰æŸå¤±å‡½æ•°" class="headerlink" title="è‡ªå®šä¹‰æŸå¤±å‡½æ•°"></a>è‡ªå®šä¹‰æŸå¤±å‡½æ•°</h1><ol>
<li>ä»¥å‡½æ•°å®šä¹‰<br>ç®€å•ç›´æ¥<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_loss</span>(<span class="params">output, target</span>):</span></span><br><span class="line">    loss = torch.mean((output - target)**<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure></li>
<li>ä»¥ç±»å®šä¹‰<br>æ›´åŠ å¸¸ç”¨ï¼Œç»§æ‰¿è‡ªnn.Moduleï¼Œå¯ä»¥å½“æˆç¥ç»ç½‘ç»œçš„ä¸€å±‚ï¼Œä½¿ç”¨tensorå¯ä»¥è‡ªåŠ¨æ±‚å¯¼<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiceLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,weight=<span class="literal">None</span>,size_average=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DiceLoss,self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,inputs,targets,smooth=<span class="number">1</span></span>):</span></span><br><span class="line">        inputs = F.sigmoid(inputs)       </span><br><span class="line">        inputs = inputs.view(-<span class="number">1</span>)</span><br><span class="line">        targets = targets.view(-<span class="number">1</span>)</span><br><span class="line">        intersection = (inputs * targets).<span class="built_in">sum</span>()                   </span><br><span class="line">        dice = (<span class="number">2.</span>*intersection + smooth)/(inputs.<span class="built_in">sum</span>() + targets.<span class="built_in">sum</span>() + smooth)  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - dice</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨æ–¹æ³•    </span></span><br><span class="line">criterion = DiceLoss()</span><br><span class="line">loss = criterion(<span class="built_in">input</span>,targets)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiceBCELoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, size_average=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DiceBCELoss, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, targets, smooth=<span class="number">1</span></span>):</span></span><br><span class="line">        inputs = F.sigmoid(inputs)       </span><br><span class="line">        inputs = inputs.view(-<span class="number">1</span>)</span><br><span class="line">        targets = targets.view(-<span class="number">1</span>)</span><br><span class="line">        intersection = (inputs * targets).<span class="built_in">sum</span>()                     </span><br><span class="line">        dice_loss = <span class="number">1</span> - (<span class="number">2.</span>*intersection + smooth)/(inputs.<span class="built_in">sum</span>() + targets.<span class="built_in">sum</span>() + smooth)  </span><br><span class="line">        BCE = F.binary_cross_entropy(inputs, targets, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">        Dice_BCE = BCE + dice_loss</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> Dice_BCE</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IoULoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, size_average=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(IoULoss, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, targets, smooth=<span class="number">1</span></span>):</span></span><br><span class="line">        inputs = F.sigmoid(inputs)       </span><br><span class="line">        inputs = inputs.view(-<span class="number">1</span>)</span><br><span class="line">        targets = targets.view(-<span class="number">1</span>)</span><br><span class="line">        intersection = (inputs * targets).<span class="built_in">sum</span>()</span><br><span class="line">        total = (inputs + targets).<span class="built_in">sum</span>()</span><br><span class="line">        union = total - intersection </span><br><span class="line">        </span><br><span class="line">        IoU = (intersection + smooth)/(union + smooth)</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - IoU</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ALPHA = <span class="number">0.8</span></span><br><span class="line">GAMMA = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, size_average=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FocalLoss, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=<span class="number">1</span></span>):</span></span><br><span class="line">        inputs = F.sigmoid(inputs)       </span><br><span class="line">        inputs = inputs.view(-<span class="number">1</span>)</span><br><span class="line">        targets = targets.view(-<span class="number">1</span>)</span><br><span class="line">        BCE = F.binary_cross_entropy(inputs, targets, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">        BCE_EXP = torch.exp(-BCE)</span><br><span class="line">        focal_loss = alpha * (<span class="number">1</span>-BCE_EXP)**gamma * BCE</span><br><span class="line">                       </span><br><span class="line">        <span class="keyword">return</span> focal_loss</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡"><a href="#åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡" class="headerlink" title="åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡"></a>åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡</h1><ol>
<li><p>ä½¿ç”¨scheduler<br>PyTorchåœ¨torch.optim.lr_schedulerå°è£…å¥½äº†ä¸€äº›åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡çš„æ–¹æ³•ã€‚</p>
<ul>
<li>lr_scheduler.LambdaLR</li>
<li>lr_scheduler.MultiplicativeLR</li>
<li>lr_scheduler.StepLR</li>
<li>lr_scheduler.MultiStepLR</li>
<li>lr_scheduler.ExponentialLR</li>
<li>lr_scheduler.CosineAnnealingLR</li>
<li>lr_scheduler.ReduceLROnPlateau</li>
<li>lr_scheduler.CyclicLR</li>
<li>lr_scheduler.OneCycleLR</li>
<li>lr_scheduler.CosineAnnealingWarmRestarts</li>
</ul>
<p> å°†scheduler.step()æ”¾åœ¨optimizer.step()åé¢è¿›è¡Œä½¿ç”¨ã€‚<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é€‰æ‹©ä¸€ç§ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = torch.optim.Adam(...) </span><br><span class="line"><span class="comment"># é€‰æ‹©ä¸Šé¢æåˆ°çš„ä¸€ç§æˆ–å¤šç§åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡çš„æ–¹æ³•</span></span><br><span class="line">scheduler1 = torch.optim.lr_scheduler.... </span><br><span class="line">scheduler2 = torch.optim.lr_scheduler....</span><br><span class="line">...</span><br><span class="line">schedulern = torch.optim.lr_scheduler....</span><br><span class="line"><span class="comment"># è¿›è¡Œè®­ç»ƒ</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    train(...)</span><br><span class="line">    validate(...)</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="comment"># éœ€è¦åœ¨ä¼˜åŒ–å™¨å‚æ•°æ›´æ–°ä¹‹åå†åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡</span></span><br><span class="line">    scheduler1.step() </span><br><span class="line">    ...</span><br><span class="line">    schedulern.step()</span><br></pre></td></tr></table></figure></p>
</li>
<li><p>è‡ªå®šä¹‰scheduler</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adjust_learning_rate</span>(<span class="params">optimizer, epoch</span>):</span></span><br><span class="line">    lr = args.lr * (<span class="number">0.1</span> ** (epoch // <span class="number">30</span>)) <span class="comment"># å­¦ä¹ ç‡æ¯30è½®ä¸‹é™ä¸ºåŸæ¥çš„1/10</span></span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = lr</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr = args.lr,momentum = <span class="number">0.9</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    train(...)</span><br><span class="line">    validate(...)</span><br><span class="line">    adjust_learning_rate(optimizer,epoch)        </span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="æ¨¡å‹å¾®è°ƒ-torchvision"><a href="#æ¨¡å‹å¾®è°ƒ-torchvision" class="headerlink" title="æ¨¡å‹å¾®è°ƒ-torchvision"></a>æ¨¡å‹å¾®è°ƒ-torchvision</h1><ol>
<li>æ¨¡å‹å¾®è°ƒ-torchvision<ul>
<li>åœ¨æºæ•°æ®é›†ä¸Šé¢„è®­ç»ƒä¸€ä¸ªæºæ¨¡å‹</li>
<li>åˆ›å»ºä¸€ä¸ªæ–°çš„ç›®æ ‡æ¨¡å‹ï¼Œå¤åˆ¶æºæ¨¡å‹é™¤äº†è¾“å‡ºå±‚å¤–çš„æ‰€æœ‰ç»“æ„ï¼Œå…¶å‚æ•°å­¦ä¹ åˆ°äº†æºæ•°æ®é›†çš„çŸ¥è¯†ï¼Œå‡è®¾å…¶åŒæ ·é€‚ç”¨äºç›®æ ‡æ•°æ®é›†ï¼Œä¸”æºæ¨¡å‹è¾“å‡ºå±‚å’Œæºæ•°æ®é›†æ ‡ç­¾å¯†åˆ‡ç›¸å…³ï¼Œæ‰€ä»¥ç›®æ ‡æ¨¡å‹ä¸é‡‡ç”¨å®ƒã€‚</li>
<li>ä¸ºç›®æ ‡å±‚æ·»åŠ ç›®æ ‡æ•°æ®é›†ç±»åˆ«ä¸ªæ•°çš„è¾“å‡ºå±‚ï¼Œéšæœºåˆå§‹åŒ–æ¨¡å‹å‚æ•°ã€‚</li>
<li>åœ¨ç›®æ ‡æ•°æ®é›†ä¸Šè®­ç»ƒç›®æ ‡æ¨¡å‹ï¼Œä»å¤´è®­ç»ƒè¾“å‡ºå±‚ï¼Œå…¶ä»–å±‚å‚æ•°å¾®è°ƒã€‚<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/finetune.png"></li>
</ul>
</li>
<li>ä½¿ç”¨å·²æœ‰æ¨¡å‹ç»“æ„<ul>
<li>å®ä¾‹åŒ–ç½‘ç»œ <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet18 = models.resnet18()</span><br><span class="line"><span class="comment"># resnet18 = models.resnet18(pretrained=False)  ç­‰ä»·äºä¸ä¸Šé¢çš„è¡¨è¾¾å¼</span></span><br><span class="line">alexnet = models.alexnet()</span><br><span class="line">vgg16 = models.vgg16()</span><br><span class="line">squeezenet = models.squeezenet1_0()</span><br><span class="line">densenet = models.densenet161()</span><br><span class="line">inception = models.inception_v3()</span><br><span class="line">googlenet = models.googlenet()</span><br><span class="line">shufflenet = models.shufflenet_v2_x1_0()</span><br><span class="line">mobilenet_v2 = models.mobilenet_v2()</span><br><span class="line">mobilenet_v3_large = models.mobilenet_v3_large()</span><br><span class="line">mobilenet_v3_small = models.mobilenet_v3_small()</span><br><span class="line">resnext50_32x4d = models.resnext50_32x4d()</span><br><span class="line">wide_resnet50_2 = models.wide_resnet50_2()</span><br><span class="line">mnasnet = models.mnasnet1_0()</span><br></pre></td></tr></table></figure></li>
<li>ä¼ é€’pretrainedå‚æ•° <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet18 = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">alexnet = models.alexnet(pretrained=<span class="literal">True</span>)</span><br><span class="line">squeezenet = models.squeezenet1_0(pretrained=<span class="literal">True</span>)</span><br><span class="line">vgg16 = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">densenet = models.densenet161(pretrained=<span class="literal">True</span>)</span><br><span class="line">inception = models.inception_v3(pretrained=<span class="literal">True</span>)</span><br><span class="line">googlenet = models.googlenet(pretrained=<span class="literal">True</span>)</span><br><span class="line">shufflenet = models.shufflenet_v2_x1_0(pretrained=<span class="literal">True</span>)</span><br><span class="line">mobilenet_v2 = models.mobilenet_v2(pretrained=<span class="literal">True</span>)</span><br><span class="line">mobilenet_v3_large = models.mobilenet_v3_large(pretrained=<span class="literal">True</span>)</span><br><span class="line">mobilenet_v3_small = models.mobilenet_v3_small(pretrained=<span class="literal">True</span>)</span><br><span class="line">resnext50_32x4d = models.resnext50_32x4d(pretrained=<span class="literal">True</span>)</span><br><span class="line">wide_resnet50_2 = models.wide_resnet50_2(pretrained=<span class="literal">True</span>)</span><br><span class="line">mnasnet = models.mnasnet1_0(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
 pytorchæ¨¡å‹æ‰©å±•ä¸º.pt .pthï¼Œæ¨¡å‹æƒé‡ä¸€æ—¦è¢«ä¸‹è½½ä¸‹æ¬¡å°±ä¸éœ€è¦åŠ è½½ï¼Œå¯ä»¥å°†è‡ªå·±çš„æƒé‡ä¸‹è½½ä¸‹æ¥æ”¾åˆ°åŒæ–‡ä»¶å¤¹ä¸‹ï¼Œç„¶åå†å°†å‚æ•°åŠ è½½ç½‘ç»œã€‚å¦‚æœä¸­é€”å¼ºè¡Œåœæ­¢ä¸‹è½½çš„è¯ï¼Œä¸€å®šè¦å»å¯¹åº”è·¯å¾„ä¸‹å°†æƒé‡æ–‡ä»¶åˆ é™¤å¹²å‡€ï¼Œè¦ä¸ç„¶å¯èƒ½ä¼šæŠ¥é”™ã€‚ <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.model = models.resnet50(pretrained=<span class="literal">False</span>)</span><br><span class="line">self.model.load_state_dict(torch.load(<span class="string">&#x27;./model/resnet50-19c8e357.pth&#x27;</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>è®­ç»ƒç‰¹å®šå±‚<br>å¦‚æœæˆ‘ä»¬æ­£åœ¨æå–ç‰¹å¾å¹¶ä¸”åªæƒ³ä¸ºæ–°åˆå§‹åŒ–çš„å±‚è®¡ç®—æ¢¯åº¦ï¼Œå…¶ä»–å‚æ•°ä¸è¿›è¡Œæ”¹å˜ã€‚é‚£æˆ‘ä»¬å°±éœ€è¦é€šè¿‡è®¾ç½®requires_grad &#x3D; Falseæ¥å†»ç»“éƒ¨åˆ†å±‚ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_parameter_requires_grad</span>(<span class="params">model, feature_extracting</span>):</span></span><br><span class="line">    <span class="keyword">if</span> feature_extracting:</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="comment"># å†»ç»“å‚æ•°çš„æ¢¯åº¦</span></span><br><span class="line">feature_extract = <span class="literal">True</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">set_parameter_requires_grad(model, feature_extract)</span><br><span class="line"><span class="comment"># ä¿®æ”¹æ¨¡å‹</span></span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line">model.fc = nn.Linear(in_features=num_ftrs, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
ä¹‹ååœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œmodelä»ä¼šè¿›è¡Œæ¢¯åº¦å›ä¼ ï¼Œä½†æ˜¯å‚æ•°æ›´æ–°åˆ™åªä¼šå‘ç”Ÿåœ¨fcå±‚ã€‚</li>
</ol>
<h1 id="æ¨¡å‹å¾®è°ƒ-timm"><a href="#æ¨¡å‹å¾®è°ƒ-timm" class="headerlink" title="æ¨¡å‹å¾®è°ƒ - timm"></a>æ¨¡å‹å¾®è°ƒ - timm</h1><p>torchvisionçš„æ‰©å……ç‰ˆæœ¬</p>
<ol>
<li>æŸ¥çœ‹é¢„è®­ç»ƒæ¨¡å‹ç§ç±»<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm</span><br><span class="line">avail_pretrained_models = timm.list_models(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">len</span>(avail_pretrained_models)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¨¡ç³ŠæŸ¥è¯¢</span></span><br><span class="line">all_densnet_models = timm.list_models(<span class="string">&quot;*densenet*&quot;</span>)</span><br><span class="line">all_densnet_models</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹æ¨¡å‹å‚æ•°</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>,num_classes=<span class="number">10</span>,pretrained=<span class="literal">True</span>)</span><br><span class="line">model.default_cfg</span><br></pre></td></tr></table></figure></li>
<li>ä½¿ç”¨å’Œä¿®æ”¹é¢„è®­ç»ƒæ¨¡å‹<br>é€šè¿‡timm.create_model()çš„æ–¹æ³•æ¥è¿›è¡Œæ¨¡å‹çš„åˆ›å»ºï¼Œä¼ å…¥å‚æ•°pretrained&#x3D;Trueï¼Œæ¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>,pretrained=<span class="literal">True</span>)</span><br><span class="line">x = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">output = model(x)</span><br><span class="line">output.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹æŸä¸€å±‚æ¨¡å‹å‚æ•°</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>,pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">dict</span>(model.named_children())[<span class="string">&#x27;conv1&#x27;</span>].parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¿®æ”¹æ¨¡å‹</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>,num_classes=<span class="number">10</span>,pretrained=<span class="literal">True</span>)</span><br><span class="line">x = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">output = model(x)</span><br><span class="line">output.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ”¹å˜è¾“å…¥é€šé“æ•°</span></span><br><span class="line">model = timm.create_model(<span class="string">&#x27;resnet34&#x27;</span>,num_classes=<span class="number">10</span>,pretrained=<span class="literal">True</span>,in_chans=<span class="number">1</span>)</span><br><span class="line">x = torch.randn(<span class="number">1</span>,<span class="number">1</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">output = model(x)</span><br></pre></td></tr></table></figure></li>
<li>æ¨¡å‹ä¿å­˜<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(),<span class="string">&#x27;./checkpoint/timm_model.pth&#x27;</span>)</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;./checkpoint/timm_model.pth&#x27;</span>))</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="åŠç²¾åº¦è®­ç»ƒ"><a href="#åŠç²¾åº¦è®­ç»ƒ" class="headerlink" title="åŠç²¾åº¦è®­ç»ƒ"></a>åŠç²¾åº¦è®­ç»ƒ</h1><p>GPUçš„æ€§èƒ½ä¸»è¦åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šç®—åŠ›å’Œæ˜¾å­˜ï¼Œå‰è€…å†³å®šäº†æ˜¾å¡è®¡ç®—çš„é€Ÿåº¦ï¼Œåè€…åˆ™å†³å®šäº†æ˜¾å¡å¯ä»¥åŒæ—¶æ”¾å…¥å¤šå°‘æ•°æ®ç”¨äºè®¡ç®—ã€‚åœ¨å¯ä»¥ä½¿ç”¨çš„æ˜¾å­˜æ•°é‡ä¸€å®šçš„æƒ…å†µä¸‹ï¼Œæ¯æ¬¡è®­ç»ƒèƒ½å¤ŸåŠ è½½çš„æ•°æ®æ›´å¤šï¼ˆä¹Ÿå°±æ˜¯batch sizeæ›´å¤§ï¼‰ï¼Œåˆ™ä¹Ÿå¯ä»¥æé«˜è®­ç»ƒæ•ˆç‡ã€‚å¦å¤–ï¼Œæœ‰æ—¶å€™æ•°æ®æœ¬èº«ä¹Ÿæ¯”è¾ƒå¤§ï¼ˆæ¯”å¦‚3Då›¾åƒã€è§†é¢‘ç­‰ï¼‰ï¼Œæ˜¾å­˜è¾ƒå°çš„æƒ…å†µä¸‹å¯èƒ½ç”šè‡³batch sizeä¸º1çš„æƒ…å†µéƒ½æ— æ³•å®ç°ã€‚å› æ­¤ï¼Œåˆç†ä½¿ç”¨æ˜¾å­˜ä¹Ÿå°±æ˜¾å¾—ååˆ†é‡è¦ã€‚</p>
<p>æˆ‘ä»¬è§‚å¯ŸPyTorché»˜è®¤çš„æµ®ç‚¹æ•°å­˜å‚¨æ–¹å¼ç”¨çš„æ˜¯torch.float32ï¼Œå°æ•°ç‚¹åä½æ•°æ›´å¤šå›ºç„¶èƒ½ä¿è¯æ•°æ®çš„ç²¾ç¡®æ€§ï¼Œä½†ç»å¤§å¤šæ•°åœºæ™¯å…¶å®å¹¶ä¸éœ€è¦è¿™ä¹ˆç²¾ç¡®ï¼Œåªä¿ç•™ä¸€åŠçš„ä¿¡æ¯ä¹Ÿä¸ä¼šå½±å“ç»“æœï¼Œä¹Ÿå°±æ˜¯ä½¿ç”¨torch.float16æ ¼å¼ã€‚ç”±äºæ•°ä½å‡äº†ä¸€åŠï¼Œå› æ­¤è¢«ç§°ä¸ºâ€œåŠç²¾åº¦â€ã€‚æ˜¾ç„¶åŠç²¾åº¦èƒ½å¤Ÿå‡å°‘æ˜¾å­˜å ç”¨ï¼Œä½¿å¾—æ˜¾å¡å¯ä»¥åŒæ—¶åŠ è½½æ›´å¤šæ•°æ®è¿›è¡Œè®¡ç®—ã€‚<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/float16.jpg"></p>
<ol>
<li>åŠç²¾åº¦è®­ç»ƒçš„è®¾ç½®<br>import autocast<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast</span><br></pre></td></tr></table></figure>
åœ¨æ¨¡å‹å®šä¹‰ä¸­ï¼Œä½¿ç”¨pythonçš„è£…é¥°å™¨æ–¹æ³•ï¼Œç”¨autocastè£…é¥°æ¨¡å‹ä¸­çš„forwardå‡½æ•°ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@autocast()   </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåªéœ€åœ¨å°†æ•°æ®è¾“å…¥æ¨¡å‹åŠå…¶ä¹‹åçš„éƒ¨åˆ†æ”¾å…¥â€œwith autocast():â€œå³å¯ï¼š<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> train_loader:</span><br><span class="line">x = x.cuda()</span><br><span class="line"><span class="keyword">with</span> autocast():</span><br><span class="line">       output = model(x)</span><br><span class="line">       ...</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="æ•°æ®å¢å¼º-imgaug"><a href="#æ•°æ®å¢å¼º-imgaug" class="headerlink" title="æ•°æ®å¢å¼º-imgaug"></a>æ•°æ®å¢å¼º-imgaug</h1><ol>
<li>å•å¼ å›¾ç‰‡å¤„ç†<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"><span class="keyword">import</span> imgaug <span class="keyword">as</span> ia</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># å›¾ç‰‡çš„è¯»å–</span></span><br><span class="line">img = imageio.imread(<span class="string">&quot;./Lenna.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨Imageè¿›è¡Œè¯»å–</span></span><br><span class="line"><span class="comment"># img = Image.open(&quot;./Lenna.jpg&quot;)</span></span><br><span class="line"><span class="comment"># image = np.array(img)</span></span><br><span class="line"><span class="comment"># ia.imshow(image)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯è§†åŒ–å›¾ç‰‡</span></span><br><span class="line">ia.imshow(img)</span><br></pre></td></tr></table></figure>
imgaugåŒ…å«äº†è®¸å¤šä»Augmenterç»§æ‰¿çš„æ•°æ®å¢å¼ºçš„æ“ä½œ<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imgaug <span class="keyword">import</span> augmenters <span class="keyword">as</span> iaa</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®éšæœºæ•°ç§å­</span></span><br><span class="line">ia.seed(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®ä¾‹åŒ–æ–¹æ³•</span></span><br><span class="line">rotate = iaa.Affine(rotate=(-<span class="number">4</span>,<span class="number">45</span>))</span><br><span class="line">img_aug = rotate(image=img)</span><br><span class="line">ia.imshow(img_aug)</span><br></pre></td></tr></table></figure>
å¯¹ä¸€å¼ å›¾ç‰‡åšå¤šç§æ•°æ®å¢å¼ºå¤„ç†<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">iaa.Sequential(children=<span class="literal">None</span>, <span class="comment"># Augmenteré›†åˆ</span></span><br><span class="line">               random_order=<span class="literal">False</span>, <span class="comment"># æ˜¯å¦å¯¹æ¯ä¸ªbatchä½¿ç”¨ä¸åŒé¡ºåºçš„Augmenter list</span></span><br><span class="line">               name=<span class="literal">None</span>,</span><br><span class="line">               deterministic=<span class="literal">False</span>,</span><br><span class="line">               random_state=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># æ„å»ºå¤„ç†åºåˆ—</span></span><br><span class="line">aug_seq = iaa.Sequential([</span><br><span class="line">    iaa.Affine(rotate=(-<span class="number">25</span>,<span class="number">25</span>)),</span><br><span class="line">    iaa.AdditiveGaussianNoise(scale=(<span class="number">10</span>,<span class="number">60</span>)),</span><br><span class="line">    iaa.Crop(percent=(<span class="number">0</span>,<span class="number">0.2</span>))</span><br><span class="line">])</span><br><span class="line"><span class="comment"># å¯¹å›¾ç‰‡è¿›è¡Œå¤„ç†ï¼Œimageä¸å¯ä»¥çœç•¥ï¼Œä¹Ÿä¸èƒ½å†™æˆimages</span></span><br><span class="line">image_aug = aug_seq(image=img)</span><br><span class="line">ia.imshow(image_aug)</span><br></pre></td></tr></table></figure></li>
<li>å¯¹æ‰¹æ¬¡å›¾ç‰‡è¿›è¡Œå¤„ç†<br>å¯¹æ‰¹æ¬¡çš„å›¾ç‰‡ä»¥åŒä¸€ç§æ–¹å¼å¤„ç†<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">images = [img,img,img,img,]</span><br><span class="line">images_aug = rotate(images=images)</span><br><span class="line">ia.imshow(np.hstack(images_aug))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹æ‰¹æ¬¡å›¾ç‰‡è¿›è¡Œå¤šç§å¢å¼º</span></span><br><span class="line">aug_seq = iaa.Sequential([</span><br><span class="line">    iaa.Affine(rotate=(-<span class="number">25</span>, <span class="number">25</span>)),</span><br><span class="line">    iaa.AdditiveGaussianNoise(scale=(<span class="number">10</span>, <span class="number">60</span>)),</span><br><span class="line">    iaa.Crop(percent=(<span class="number">0</span>, <span class="number">0.2</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¼ å…¥æ—¶éœ€è¦æŒ‡æ˜æ˜¯imageså‚æ•°</span></span><br><span class="line">images_aug = aug_seq.augment_images(images = images)</span><br><span class="line"><span class="comment">#images_aug = aug_seq(images = images) </span></span><br><span class="line">ia.imshow(np.hstack(images_aug))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹æ‰¹æ¬¡çš„å›¾ç‰‡åˆ†éƒ¨åˆ†å¤„ç†</span></span><br><span class="line">iaa.Sometimes(p=<span class="number">0.5</span>,  <span class="comment"># ä»£è¡¨åˆ’åˆ†æ¯”ä¾‹</span></span><br><span class="line">              then_list=<span class="literal">None</span>,  <span class="comment"># Augmenteré›†åˆã€‚pæ¦‚ç‡çš„å›¾ç‰‡è¿›è¡Œå˜æ¢çš„Augmentersã€‚</span></span><br><span class="line">              else_list=<span class="literal">None</span>,  <span class="comment">#1-pæ¦‚ç‡çš„å›¾ç‰‡ä¼šè¢«è¿›è¡Œå˜æ¢çš„Augmentersã€‚æ³¨æ„å˜æ¢çš„å›¾ç‰‡åº”ç”¨çš„Augmenteråªèƒ½æ˜¯then_listæˆ–è€…else_listä¸­çš„ä¸€ä¸ªã€‚</span></span><br><span class="line">              name=<span class="literal">None</span>,</span><br><span class="line">              deterministic=<span class="literal">False</span>,</span><br><span class="line">              random_state=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹ä¸åŒå¤§å°çš„å›¾ç‰‡è¿›è¡Œå¤„ç†</span></span><br><span class="line"><span class="comment"># æ„å»ºpipline</span></span><br><span class="line">seq = iaa.Sequential([</span><br><span class="line">    iaa.CropAndPad(percent=(-<span class="number">0.2</span>, <span class="number">0.2</span>), pad_mode=<span class="string">&quot;edge&quot;</span>),  <span class="comment"># crop and pad images</span></span><br><span class="line">    iaa.AddToHueAndSaturation((-<span class="number">60</span>, <span class="number">60</span>)),  <span class="comment"># change their color</span></span><br><span class="line">    iaa.ElasticTransformation(alpha=<span class="number">90</span>, sigma=<span class="number">9</span>),  <span class="comment"># water-like effect</span></span><br><span class="line">    iaa.Cutout()  <span class="comment"># replace one squared area within the image by a constant intensity value</span></span><br><span class="line">], random_order=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½ä¸åŒå¤§å°çš„å›¾ç‰‡</span></span><br><span class="line">images_different_sizes = [</span><br><span class="line">    imageio.imread(<span class="string">&quot;https://upload.wikimedia.org/wikipedia/commons/e/ed/BRACHYLAGUS_IDAHOENSIS.jpg&quot;</span>),</span><br><span class="line">    imageio.imread(<span class="string">&quot;https://upload.wikimedia.org/wikipedia/commons/c/c9/Southern_swamp_rabbit_baby.jpg&quot;</span>),</span><br><span class="line">    imageio.imread(<span class="string">&quot;https://upload.wikimedia.org/wikipedia/commons/9/9f/Lower_Keys_marsh_rabbit.jpg&quot;</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹å›¾ç‰‡è¿›è¡Œå¢å¼º</span></span><br><span class="line">images_aug = seq(images=images_different_sizes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯è§†åŒ–ç»“æœ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Image 0 (input shape: %s, output shape: %s)&quot;</span> % (images_different_sizes[<span class="number">0</span>].shape, images_aug[<span class="number">0</span>].shape))</span><br><span class="line">ia.imshow(np.hstack([images_different_sizes[<span class="number">0</span>], images_aug[<span class="number">0</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Image 1 (input shape: %s, output shape: %s)&quot;</span> % (images_different_sizes[<span class="number">1</span>].shape, images_aug[<span class="number">1</span>].shape))</span><br><span class="line">ia.imshow(np.hstack([images_different_sizes[<span class="number">1</span>], images_aug[<span class="number">1</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Image 2 (input shape: %s, output shape: %s)&quot;</span> % (images_different_sizes[<span class="number">2</span>].shape, images_aug[<span class="number">2</span>].shape))</span><br><span class="line">ia.imshow(np.hstack([images_different_sizes[<span class="number">2</span>], images_aug[<span class="number">2</span>]]))</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="ä½¿ç”¨argparseè¿›è¡Œè°ƒå‚"><a href="#ä½¿ç”¨argparseè¿›è¡Œè°ƒå‚" class="headerlink" title="ä½¿ç”¨argparseè¿›è¡Œè°ƒå‚"></a>ä½¿ç”¨argparseè¿›è¡Œè°ƒå‚</h1><p>ç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­å°±å¯ä»¥å‘ç¨‹åºä¸­ä¼ å…¥å‚æ•°ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨python file.pyæ¥è¿è¡Œpythonæ–‡ä»¶ã€‚è€Œargparseçš„ä½œç”¨å°±æ˜¯å°†å‘½ä»¤è¡Œä¼ å…¥çš„å…¶ä»–å‚æ•°è¿›è¡Œè§£æã€ä¿å­˜å’Œä½¿ç”¨ã€‚åœ¨ä½¿ç”¨argparseåï¼Œæˆ‘ä»¬åœ¨å‘½ä»¤è¡Œè¾“å…¥çš„å‚æ•°å°±å¯ä»¥ä»¥è¿™ç§å½¢å¼python file.py â€“lr 1e-4 â€“batch_size 32æ¥å®Œæˆå¯¹å¸¸è§è¶…å‚æ•°çš„è®¾ç½®ã€‚</p>
<h2 id="argparseçš„ä½¿ç”¨"><a href="#argparseçš„ä½¿ç”¨" class="headerlink" title="argparseçš„ä½¿ç”¨"></a>argparseçš„ä½¿ç”¨</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># demo.py</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºArgumentParser()å¯¹è±¡</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ·»åŠ å‚æ•°</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;--output&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, </span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;shows output&quot;</span>)</span><br><span class="line"><span class="comment"># action = `store_true` ä¼šå°†outputå‚æ•°è®°å½•ä¸ºTrue</span></span><br><span class="line"><span class="comment"># type è§„å®šäº†å‚æ•°çš„æ ¼å¼</span></span><br><span class="line"><span class="comment"># default è§„å®šäº†é»˜è®¤å€¼</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">3e-5</span>, <span class="built_in">help</span>=<span class="string">&#x27;select the learning rate, default=1e-3&#x27;</span>) </span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;input batch size&#x27;</span>)  </span><br><span class="line"><span class="comment"># ä½¿ç”¨parse_args()è§£æå‡½æ•°</span></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.output:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;This is some output&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;learning rate:<span class="subst">&#123;args.lr&#125;</span> &quot;</span>)</span><br></pre></td></tr></table></figure>
<p>è¾“å…¥python demo.py â€“lr 3e-4 â€“batch_size 32ï¼Œå¾—åˆ°ï¼š</p>
<pre><code>This is some output
learning rate: 3e-4
</code></pre>
<h2 id="æ›´åŠ é«˜æ•ˆä½¿ç”¨argparseä¿®æ”¹è¶…å‚æ•°"><a href="#æ›´åŠ é«˜æ•ˆä½¿ç”¨argparseä¿®æ”¹è¶…å‚æ•°" class="headerlink" title="æ›´åŠ é«˜æ•ˆä½¿ç”¨argparseä¿®æ”¹è¶…å‚æ•°"></a>æ›´åŠ é«˜æ•ˆä½¿ç”¨argparseä¿®æ”¹è¶…å‚æ•°</h2><p>ä¸ºäº†ä½¿ä»£ç æ›´åŠ ç®€æ´å’Œæ¨¡å—åŒ–ï¼Œæˆ‘ä¸€èˆ¬ä¼šå°†æœ‰å…³è¶…å‚æ•°çš„æ“ä½œå†™åœ¨config.pyï¼Œç„¶ååœ¨train.pyæˆ–è€…å…¶ä»–æ–‡ä»¶å¯¼å…¥å°±å¯ä»¥ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_options</span>(<span class="params">parser=argparse.ArgumentParser(<span class="params"></span>)</span>):</span>  </span><br><span class="line">  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--workers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of data loading workers, you had better put it &#x27;</span>  </span><br><span class="line">                              <span class="string">&#x27;4 times of your gpu&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>, <span class="built_in">help</span>=<span class="string">&#x27;input batch size, default=64&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--niter&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of epochs to train for, default=10&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">3e-5</span>, <span class="built_in">help</span>=<span class="string">&#x27;select the learning rate, default=1e-3&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">118</span>, <span class="built_in">help</span>=<span class="string">&quot;random seed&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cuda&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;enables cuda&#x27;</span>)  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--checkpoint_path&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>,default=<span class="string">&#x27;&#x27;</span>,  </span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Path to load a previous trained model if not empty (default empty)&#x27;</span>)  </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--output&#x27;</span>,action=<span class="string">&#x27;store_true&#x27;</span>,default=<span class="literal">True</span>,<span class="built_in">help</span>=<span class="string">&quot;shows output&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">    opt = parser.parse_args()  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> opt.output:  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;num_workers: <span class="subst">&#123;opt.workers&#125;</span>&#x27;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;batch_size: <span class="subst">&#123;opt.batch_size&#125;</span>&#x27;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epochs (niters) : <span class="subst">&#123;opt.niter&#125;</span>&#x27;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;learning rate : <span class="subst">&#123;opt.lr&#125;</span>&#x27;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;manual_seed: <span class="subst">&#123;opt.seed&#125;</span>&#x27;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;cuda enable: <span class="subst">&#123;opt.cuda&#125;</span>&#x27;</span>)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;checkpoint_path: <span class="subst">&#123;opt.checkpoint_path&#125;</span>&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> opt  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    opt = get_options()</span><br></pre></td></tr></table></figure>
<p>éšååœ¨train.pyç­‰å…¶ä»–æ–‡ä»¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„è¿™æ ·çš„ç»“æ„æ¥è°ƒç”¨å‚æ•°ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¼å…¥å¿…è¦åº“</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line">opt = config.get_options()</span><br><span class="line"></span><br><span class="line">manual_seed = opt.seed</span><br><span class="line">num_workers = opt.workers</span><br><span class="line">batch_size = opt.batch_size</span><br><span class="line">lr = opt.lr</span><br><span class="line">niters = opt.niters</span><br><span class="line">checkpoint_path = opt.checkpoint_path</span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºæ•°çš„è®¾ç½®ï¼Œä¿è¯å¤ç°ç»“æœ</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_seed</span>(<span class="params">seed</span>):</span></span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	set_seed(manual_seed)</span><br><span class="line">	<span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(niters):</span><br><span class="line">		train(model,lr,batch_size,num_workers,checkpoint_path)</span><br><span class="line">		val(model,lr,batch_size,num_workers,checkpoint_path)</span><br></pre></td></tr></table></figure>

<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E5%85%AD%E7%AB%A0/index.html">æ·±å…¥æµ…å‡ºPyTorch</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-16T06:43:54.000Z" title="2022/10/16 ä¸‹åˆ2:43:54">2022-10-16</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-16T12:34:44.177Z" title="2022/10/16 ä¸‹åˆ8:34:44">2022-10-16</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">12 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦1837ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/16/pytorch-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89/">pytorch - æ¨¡å‹å®šä¹‰</a></h1><div class="content"><h1 id="æ¨¡å‹å®šä¹‰çš„æ–¹å¼"><a href="#æ¨¡å‹å®šä¹‰çš„æ–¹å¼" class="headerlink" title="æ¨¡å‹å®šä¹‰çš„æ–¹å¼"></a>æ¨¡å‹å®šä¹‰çš„æ–¹å¼</h1><p>åŸºäºnn.Moduleï¼Œå¯ä»¥é€šè¿‡Sequentialï¼ŒModuleListå’ŒModuleDictä¸‰ç§æ–¹å¼å®šä¹‰PyTorchæ¨¡å‹ã€‚</p>
<h2 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h2><p>å°†æ¨¡å‹çš„å±‚æŒ‰åºæ’åˆ—èµ·æ¥ï¼ŒæŒ‰é¡ºåºè¯»å–ï¼Œä¸ç”¨å†™forwardï¼Œä½†ä¸§å¤±çµæ´»æ€§</p>
<ol>
<li>Sequential<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Sequential: Direct list</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">net1 = nn.Sequential(</span><br><span class="line">        nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">10</span>), </span><br><span class="line">        )</span><br><span class="line"><span class="built_in">print</span>(net1)</span><br></pre></td></tr></table></figure>

<pre><code> Sequential(
   (0): Linear(in_features=784, out_features=256, bias=True)
   (1): ReLU()
   (2): Linear(in_features=256, out_features=10, bias=True)
 )
</code></pre>
</li>
<li>Ordered Dict<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">net2 = nn.Sequential(collections.OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;fc1&#x27;</span>, nn.Linear(<span class="number">784</span>, <span class="number">256</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">&#x27;fc2&#x27;</span>, nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line">          ]))</span><br><span class="line"><span class="built_in">print</span>(net2)</span><br></pre></td></tr></table></figure>

<pre><code> Sequential(
   (fc1): Linear(in_features=784, out_features=256, bias=True)
   (relu1): ReLU()
   (fc2): Linear(in_features=256, out_features=10, bias=True)
 )
</code></pre>
</li>
</ol>
<h2 id="ModuleList"><a href="#ModuleList" class="headerlink" title="ModuleList"></a>ModuleList</h2><p>ModuleList æ¥æ”¶ä¸€ä¸ªå­æ¨¡å—ï¼ˆæˆ–å±‚ï¼Œéœ€å±äºnn.Moduleç±»ï¼‰çš„ï¦œè¡¨ä½œä¸ºè¾“å…¥ï¼Œç±»ä¼¼Listé‚£æ ·è¿›è¡Œappendå’Œextendæ“ä½œã€‚åŒæ—¶ï¼Œå­æ¨¡å—æˆ–å±‚çš„æƒé‡ä¹Ÿä¼šè‡ªåŠ¨æ·»åŠ åˆ°ç½‘ç»œä¸­æ¥ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net3 = nn.ModuleList([nn.Linear(<span class="number">784</span>, <span class="number">256</span>), nn.ReLU()])</span><br><span class="line">net3.append(nn.Linear(<span class="number">256</span>, <span class="number">10</span>)) <span class="comment"># # ç±»ä¼¼Listçš„appendæ“ä½œ</span></span><br><span class="line"><span class="built_in">print</span>(net3[-<span class="number">1</span>])  <span class="comment"># ç±»ä¼¼Listçš„ç´¢å¼•è®¿é—®</span></span><br><span class="line"><span class="built_in">print</span>(net3)</span><br></pre></td></tr></table></figure>

<p>ModuleList å¹¶æ²¡æœ‰å®šä¹‰ä¸€ä¸ªç½‘ç»œï¼Œå®ƒåªæ˜¯å°†ä¸åŒçš„æ¨¡å—å‚¨å­˜åœ¨ä¸€èµ·ã€‚æŠŠmodellistå†™åˆ°åˆå§‹åŒ–ï¼Œå†å®šä¹‰forwardå‡½æ•°æ˜ç¡®ä¼ è¾“é¡ºåºã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.modulelist = nn.ModuleList([nn.Linear(<span class="number">784</span>, <span class="number">256</span>), nn.ReLU()])</span><br><span class="line">        self.modulelist.append(nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.modulelist:</span><br><span class="line">            x = layer(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">net3_ = Net3()</span><br><span class="line">out3_ = net3_(a)</span><br><span class="line"><span class="built_in">print</span>(out3_.shape)</span><br></pre></td></tr></table></figure>

<h2 id="ModuleDict"><a href="#ModuleDict" class="headerlink" title="ModuleDict"></a>ModuleDict</h2><p>ModuleDictå’ŒModuleListçš„ä½œç”¨ç±»ä¼¼ï¼Œåªæ˜¯ModuleDictèƒ½å¤Ÿæ›´æ–¹ä¾¿åœ°ä¸ºç¥ç»ç½‘ç»œçš„å±‚æ·»åŠ åç§°ã€‚åŒæ ·åœ°ï¼ŒModuleDictå¹¶æ²¡æœ‰å®šä¹‰ä¸€ä¸ªç½‘ç»œï¼Œå®ƒåªæ˜¯å°†ä¸åŒçš„æ¨¡å—å‚¨å­˜åœ¨ä¸€èµ·ï¼Œè¦å®šä¹‰forwardã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">net = nn.ModuleDict(&#123;</span><br><span class="line">    <span class="string">&#x27;linear&#x27;</span>: nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">    <span class="string">&#x27;act&#x27;</span>: nn.ReLU(),</span><br><span class="line">&#125;)</span><br><span class="line">net[<span class="string">&#x27;output&#x27;</span>] = nn.Linear(<span class="number">256</span>, <span class="number">10</span>) <span class="comment"># æ·»åŠ </span></span><br><span class="line"><span class="built_in">print</span>(net[<span class="string">&#x27;linear&#x27;</span>]) <span class="comment"># è®¿é—®</span></span><br><span class="line"><span class="built_in">print</span>(net.output)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<h1 id="åˆ©ç”¨æ¨¡å‹å—å¿«é€Ÿæ­å»ºå¤æ‚ç½‘ç»œ"><a href="#åˆ©ç”¨æ¨¡å‹å—å¿«é€Ÿæ­å»ºå¤æ‚ç½‘ç»œ" class="headerlink" title="åˆ©ç”¨æ¨¡å‹å—å¿«é€Ÿæ­å»ºå¤æ‚ç½‘ç»œ"></a>åˆ©ç”¨æ¨¡å‹å—å¿«é€Ÿæ­å»ºå¤æ‚ç½‘ç»œ</h1><p>å½“æ¨¡å‹æœ‰å¾ˆå¤šå±‚çš„æ—¶å€™ï¼Œå…¶ä¸­å¾ˆå¤šé‡å¤å‡ºç°çš„ç»“æ„å¯ä»¥å®šä¹‰ä¸ºä¸€ä¸ªæ¨¡å—ï¼Œä¾¿åˆ©æ¨¡å‹æ„å»ºã€‚<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/5.2.1unet.png"><br>å¦‚U-Netæ‰€ç¤ºï¼Œæ¨¡å‹å·¦å³å¯¹ç§°ï¼Œæ¯ä¸ªå­å±‚å†…éƒ¨æœ‰ä¸¤æ¬¡å·ç§¯ï¼Œå·¦ä¾§ä¸‹é‡‡æ ·è¿æ¥ï¼Œå³ä¾§ä¸Šé‡‡æ ·è¿æ¥ï¼Œæ¯å±‚æ¨¡å‹å—å’Œä¸Šä¸‹æ¨¡å‹å—è¿æ¥ï¼ŒåŒå±‚çš„å·¦å³æ¨¡å‹å—è¿æ¥ã€‚</p>
<ol>
<li>åŒæ¬¡å·ç§¯<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;(convolution =&gt; [BN] =&gt; ReLU) * 2&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, mid_channels=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mid_channels:</span><br><span class="line">            mid_channels = out_channels</span><br><span class="line">        self.double_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, mid_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(mid_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(mid_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.double_conv(x)</span><br></pre></td></tr></table></figure></li>
<li>ä¸‹é‡‡æ ·<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Down</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Downscaling with maxpool then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            DoubleConv(in_channels, out_channels)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br></pre></td></tr></table></figure></li>
<li>ä¸Šé‡‡æ ·<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Up</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Upscaling then double conv&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if bilinear, use the normal convolutions to reduce the number of channels</span></span><br><span class="line">        <span class="keyword">if</span> bilinear: <span class="comment"># æ’å€¼</span></span><br><span class="line">            self.up = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">True</span>)</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels, in_channels // <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.up = nn.ConvTranspose2d(in_channels, in_channels // <span class="number">2</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">            self.conv = DoubleConv(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x1, x2</span>):</span></span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        <span class="comment"># input is CHW</span></span><br><span class="line">        diffY = x2.size()[<span class="number">2</span>] - x1.size()[<span class="number">2</span>]</span><br><span class="line">        diffX = x2.size()[<span class="number">3</span>] - x1.size()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x1 = F.pad(x1, [diffX // <span class="number">2</span>, diffX - diffX // <span class="number">2</span>,</span><br><span class="line">                        diffY // <span class="number">2</span>, diffY - diffY // <span class="number">2</span>])</span><br><span class="line">        <span class="comment"># if you have padding issues, see</span></span><br><span class="line">        <span class="comment"># https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a</span></span><br><span class="line">        <span class="comment"># https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd</span></span><br><span class="line">        x = torch.cat([x2, x1], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># è¿æ¥å·¦ä¾§çš„æ•°æ®å†å·ç§¯</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure></li>
<li>è¾“å‡º<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OutConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(OutConv, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure></li>
<li>ç»„è£…<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line"></span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span> // factor)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        logits = self.outc(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line">unet = UNet(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">unet</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="æ¨¡å‹ä¿®æ”¹"><a href="#æ¨¡å‹ä¿®æ”¹" class="headerlink" title="æ¨¡å‹ä¿®æ”¹"></a>æ¨¡å‹ä¿®æ”¹</h1><p>å½“æœ‰ä¸€ä¸ªç°æˆçš„æ¨¡å‹éœ€è¦å¯¹ç»“æ„è¿›è¡Œä¿®æ”¹ä½¿ç”¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å·²æœ‰æ¨¡å‹ä¸Šä¿®æ”¹ã€‚</p>
<ol>
<li>ä¿®æ”¹æ¨¡å‹å±‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">unet1 = copy.deepcopy(unet)</span><br><span class="line">unet1.outc</span><br></pre></td></tr></table></figure>
å…ˆå¤åˆ¶ï¼Œç„¶åä¿®æ”¹outc<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">out_unet1 = unet1(b)</span><br><span class="line"><span class="built_in">print</span>(out_unet1.shape)</span><br></pre></td></tr></table></figure>
è¦æŠŠè¾“å‡ºChanelå˜æˆ5ï¼Œé‡æ–°å®ä¾‹åŒ–outc<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">unet1.outc = OutConv(<span class="number">64</span>, <span class="number">5</span>)</span><br><span class="line">unet1.outc</span><br><span class="line">out_unet1 = unet1(b)</span><br><span class="line"><span class="built_in">print</span>(out_unet1.shape)</span><br></pre></td></tr></table></figure></li>
<li>æ·»åŠ é¢å¤–è¾“å…¥<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet2</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(UNet2, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line"></span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span> // factor)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, add_variable</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        x = x + add_variable   <span class="comment">#ä¿®æ”¹ç‚¹</span></span><br><span class="line">        logits = self.outc(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line">unet2 = UNet2(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">c = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">out_unet2 = unet2(b, c)</span><br><span class="line"><span class="built_in">print</span>(out_unet2.shape)</span><br></pre></td></tr></table></figure>
æˆ–ç”¨torch.catå®ç°äº†tensorçš„æ‹¼æ¥ï¼Œå¦‚x &#x3D; torch.cat((self.dropout(self.relu(x)), add_variable.unsqueeze(1)),1)ã€‚</li>
<li>æ·»åŠ é¢å¤–è¾“å‡º<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UNet3</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, n_classes, bilinear=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(UNet3, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line"></span><br><span class="line">        self.inc = DoubleConv(n_channels, <span class="number">64</span>)</span><br><span class="line">        self.down1 = Down(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down2 = Down(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down3 = Down(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = Down(<span class="number">512</span>, <span class="number">1024</span> // factor)</span><br><span class="line">        self.up1 = Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear)</span><br><span class="line">        self.up2 = Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear)</span><br><span class="line">        self.up3 = Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear)</span><br><span class="line">        self.up4 = Up(<span class="number">128</span>, <span class="number">64</span>, bilinear)</span><br><span class="line">        self.outc = OutConv(<span class="number">64</span>, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        logits = self.outc(x)</span><br><span class="line">        <span class="keyword">return</span> logits, x5  <span class="comment"># ä¿®æ”¹ç‚¹</span></span><br><span class="line">unet3 = UNet3(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">c = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">out_unet3, mid_out = unet3(b)</span><br><span class="line"><span class="built_in">print</span>(out_unet3.shape, mid_out.shape)</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="æ¨¡å‹ä¿å­˜å’Œè¯»å–"><a href="#æ¨¡å‹ä¿å­˜å’Œè¯»å–" class="headerlink" title="æ¨¡å‹ä¿å­˜å’Œè¯»å–"></a>æ¨¡å‹ä¿å­˜å’Œè¯»å–</h1><p>å•å¡&#x2F;å¤šå¡ï¼Œæ•´ä¸ª&#x2F;éƒ¨åˆ†æ¨¡å‹, unet.state_dict()æŸ¥çœ‹æ¨¡å‹æƒé‡ï¼Œä¿å­˜çš„æ¨¡å‹æ ¼å¼ï¼š pt pth pklã€‚</p>
<ol>
<li><p>CPUæˆ–å•å¡ï¼šä¿å­˜&amp;è¯»å–æ•´ä¸ªæ¨¡å‹</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.save(unet, <span class="string">&quot;./unet_example.pth&quot;</span>)</span><br><span class="line">loaded_unet = torch.load(<span class="string">&quot;./unet_example.pth&quot;</span>)</span><br><span class="line">loaded_unet.state_dict()</span><br></pre></td></tr></table></figure></li>
<li><p>CPUæˆ–å•å¡ï¼šä¿å­˜&amp;è¯»å–æ¨¡å‹æƒé‡</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.save(unet.state_dict(), <span class="string">&quot;./unet_weight_example.pth&quot;</span>)</span><br><span class="line">loaded_unet_weights = torch.load(<span class="string">&quot;./unet_weight_example.pth&quot;</span>)</span><br><span class="line">unet.load_state_dict(loaded_unet_weights) <span class="comment"># ç”¨å·²ç»å®šä¹‰å¥½çš„æ¨¡å‹ç»“æ„åŠ è½½å˜é‡</span></span><br><span class="line">unet.state_dict()</span><br></pre></td></tr></table></figure></li>
<li><p>å¤šå¡ï¼šä¿å­˜&amp;è¯»å–æ•´ä¸ªæ¨¡å‹ã€‚æ³¨æ„æ¨¡å‹å±‚åç§°å‰å¤šäº†module<br>ä¸å»ºè®®ï¼Œå› ä¸ºä¿å­˜æ¨¡å‹çš„GPU_idç­‰ä¿¡æ¯å’Œè¯»å–åè®­ç»ƒç¯å¢ƒå¯èƒ½ä¸åŒï¼Œå°¤å…¶æ˜¯è¦æŠŠä¿å­˜çš„æ¨¡å‹äº¤ç»™å¦ä¸€ç”¨æˆ·ä½¿ç”¨çš„æƒ…å†µ</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;2,3&#x27;</span></span><br><span class="line">unet_mul = copy.deepcopy(unet)</span><br><span class="line">unet_mul = nn.DataParallel(unet_mul).cuda()</span><br><span class="line">torch.save(unet_mul, <span class="string">&quot;./unet_mul_example.pth&quot;</span>)</span><br><span class="line">loaded_unet_mul = torch.load(<span class="string">&quot;./unet_mul_example.pth&quot;</span>)</span><br><span class="line">loaded_unet_mul</span><br></pre></td></tr></table></figure>
</li>
<li><p>å¤šå¡ï¼šä¿å­˜&amp;è¯»å–æ¨¡å‹æƒé‡ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.save(unet_mul.state_dict(), <span class="string">&quot;./unet_weight_mul_example.pth&quot;</span>)</span><br><span class="line">loaded_unet_weights_mul = torch.load(<span class="string">&quot;./unet_weight_mul_example.pth&quot;</span>)</span><br><span class="line">unet_mul.load_state_dict(loaded_unet_weights_mul)</span><br><span class="line">unet_mul = nn.DataParallel(unet_mul).cuda()</span><br><span class="line">unet_mul.state_dict()</span><br></pre></td></tr></table></figure>
<p>å¦å¤–ï¼Œå¦‚æœä¿å­˜çš„æ˜¯æ•´ä¸ªæ¨¡å‹ï¼Œä¹Ÿå»ºè®®é‡‡ç”¨æå–æƒé‡çš„æ–¹å¼æ„å»ºæ–°çš„æ¨¡å‹ï¼š</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unet_mul.state_dict = loaded_unet_mul.state_dict</span><br><span class="line">unet_mul = nn.DataParallel(unet_mul).cuda()</span><br><span class="line">unet_mul.state_dict()</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%BA%94%E7%AB%A0/index.html">æ·±å…¥æµ…å‡ºPyTorch</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-12T06:43:54.000Z" title="2022/10/12 ä¸‹åˆ2:43:54">2022-10-12</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-12T15:33:48.906Z" title="2022/10/12 ä¸‹åˆ11:33:48">2022-10-12</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">1 å°æ—¶è¯»å®Œ (å¤§çº¦11579ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/12/pytorch-%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E5%92%8C%E5%AE%9E%E8%B7%B5/">pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ</a></h1><div class="content"><p>æœ¬ç« ä»‹ç»pytorchè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„å„ä¸ªç»„ä»¶å’Œå®è·µï¼Œå±‚å±‚æ­å»ºç¥ç»ç½‘ç»œæ¨¡å‹ã€‚</p>
<h1 id="ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶"><a href="#ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶" class="headerlink" title="ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶"></a>ç¥ç»ç½‘ç»œå­¦ä¹ æœºåˆ¶</h1><center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665563909211/D2B5CA33BD970F64A6301FA75AE2EB22" width="250">  
</center>

<ul>
<li>æ•°æ®é¢„å¤„ç†<br>å®Œæˆä¸€é¡¹æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶çš„æ­¥éª¤ï¼Œé¦–å…ˆéœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå…¶ä¸­é‡è¦çš„æ­¥éª¤åŒ…æ‹¬æ•°æ®æ ¼å¼çš„ç»Ÿä¸€å’Œå¿…è¦çš„æ•°æ®å˜æ¢ï¼ŒåŒæ—¶åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚</li>
<li>æ¨¡å‹è®¾è®¡<br>é€‰æ‹©æ¨¡å‹ã€‚</li>
<li>æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡<br>è®¾å®šæŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ï¼Œä»¥åŠå¯¹åº”çš„è¶…å‚æ•°ï¼ˆå½“ç„¶å¯ä»¥ä½¿ç”¨sklearnè¿™æ ·çš„æœºå™¨å­¦ä¹ åº“ä¸­æ¨¡å‹è‡ªå¸¦çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼‰ã€‚</li>
<li>å‰å‘ä¼ æ’­<br>ç”¨æ¨¡å‹å»æ‹Ÿåˆè®­ç»ƒé›†æ•°æ®ï¼Œ</li>
<li>åå‘ä¼ æ’­</li>
<li>æ›´æ–°å‚æ•°</li>
<li>æ¨¡å‹è¡¨ç°<br>åœ¨éªŒè¯é›†&#x2F;æµ‹è¯•é›†ä¸Šè®¡ç®—æ¨¡å‹è¡¨ç°ã€‚</li>
</ul>
<h1 id="æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§"><a href="#æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§" class="headerlink" title="æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§"></a>æ·±åº¦å­¦ä¹ åœ¨å®ç°ä¸Šçš„ç‰¹æ®Šæ€§</h1><ul>
<li>æ ·æœ¬é‡å¤§ï¼Œéœ€è¦åˆ†æ‰¹åŠ è½½<br>ç”±äºæ·±åº¦å­¦ä¹ æ‰€éœ€çš„æ ·æœ¬é‡å¾ˆå¤§ï¼Œä¸€æ¬¡åŠ è½½å…¨éƒ¨æ•°æ®è¿è¡Œå¯èƒ½ä¼šè¶…å‡ºå†…å­˜å®¹é‡è€Œæ— æ³•å®ç°ï¼›åŒæ—¶è¿˜æœ‰æ‰¹ï¼ˆbatchï¼‰è®­ç»ƒç­‰æé«˜æ¨¡å‹è¡¨ç°çš„ç­–ç•¥ï¼Œéœ€è¦æ¯æ¬¡è®­ç»ƒè¯»å–å›ºå®šæ•°é‡çš„æ ·æœ¬é€å…¥æ¨¡å‹ä¸­è®­ç»ƒã€‚</li>
<li>é€å±‚ã€æ¨¡å—åŒ–æ­å»ºç½‘ç»œï¼ˆå·ç§¯å±‚ã€å…¨è¿æ¥å±‚ã€LSTMç­‰ï¼‰<br>æ·±åº¦ç¥ç»ç½‘ç»œå¾€å¾€éœ€è¦â€œé€å±‚â€æ­å»ºï¼Œæˆ–è€…é¢„å…ˆå®šä¹‰å¥½å¯ä»¥å®ç°ç‰¹å®šåŠŸèƒ½çš„æ¨¡å—ï¼Œå†æŠŠè¿™äº›æ¨¡å—ç»„è£…èµ·æ¥ã€‚</li>
<li>å¤šæ ·åŒ–çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨è®¾è®¡<br>ç”±äºæ¨¡å‹è®¾å®šçš„çµæ´»æ€§ï¼Œå› æ­¤æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨è¦èƒ½å¤Ÿä¿è¯åå‘ä¼ æ’­èƒ½å¤Ÿåœ¨ç”¨æˆ·è‡ªè¡Œå®šä¹‰çš„æ¨¡å‹ç»“æ„ä¸Šå®ç°</li>
<li>GPUçš„ä½¿ç”¨<br>éœ€è¦æŠŠæ¨¡å‹å’Œæ•°æ®â€œæ”¾åˆ°â€GPUä¸Šå»åšè¿ç®—ï¼ŒåŒæ—¶è¿˜éœ€è¦ä¿è¯æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨èƒ½å¤Ÿåœ¨GPUä¸Šå·¥ä½œã€‚å¦‚æœä½¿ç”¨å¤šå¼ GPUè¿›è¡Œè®­ç»ƒï¼Œè¿˜éœ€è¦è€ƒè™‘æ¨¡å‹å’Œæ•°æ®åˆ†é…ã€æ•´åˆçš„é—®é¢˜ã€‚</li>
<li>å„ä¸ªæ¨¡å—ä¹‹é—´çš„é…åˆ<br>æ·±åº¦å­¦ä¹ ä¸­è®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹æœ€å¤§çš„ç‰¹ç‚¹åœ¨äºè¯»å…¥æ•°æ®æ˜¯æŒ‰æ‰¹çš„ï¼Œæ¯æ¬¡è¯»å…¥ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼Œæ”¾å…¥GPUä¸­è®­ç»ƒï¼Œç„¶åå°†æŸå¤±å‡½æ•°åå‘ä¼ æ’­å›ç½‘ç»œæœ€å‰é¢çš„å±‚ï¼ŒåŒæ—¶ä½¿ç”¨ä¼˜åŒ–å™¨è°ƒæ•´ç½‘ç»œå‚æ•°ã€‚è¿™é‡Œä¼šæ¶‰åŠåˆ°å„ä¸ªæ¨¡å—é…åˆçš„é—®é¢˜ã€‚è®­ç»ƒ&#x2F;éªŒè¯åè¿˜éœ€è¦æ ¹æ®è®¾å®šå¥½çš„æŒ‡æ ‡è®¡ç®—æ¨¡å‹è¡¨ç°ã€‚</li>
</ul>
<h1 id="pytorchæ·±åº¦å­¦ä¹ æ¨¡å—"><a href="#pytorchæ·±åº¦å­¦ä¹ æ¨¡å—" class="headerlink" title="pytorchæ·±åº¦å­¦ä¹ æ¨¡å—"></a>pytorchæ·±åº¦å­¦ä¹ æ¨¡å—</h1><p>å°†PyTorchå®Œæˆæ·±åº¦å­¦ä¹ çš„æ­¥éª¤æ‹†è§£ä¸ºå‡ ä¸ªä¸»è¦æ¨¡å—ï¼Œå®é™…ä½¿ç”¨æ ¹æ®è‡ªèº«éœ€æ±‚ä¿®æ”¹å¯¹åº”æ¨¡å—å³å¯ï¼Œæ·±åº¦å­¦ä¹ -&gt;æ­ç§¯æœ¨ã€‚</p>
<h2 id="ä¸€ã€-åŸºæœ¬é…ç½®"><a href="#ä¸€ã€-åŸºæœ¬é…ç½®" class="headerlink" title="ä¸€ã€ åŸºæœ¬é…ç½®"></a>ä¸€ã€ åŸºæœ¬é…ç½®</h2><p>é¦–å…ˆå¯¼å…¥å¿…è¦çš„åŒ…</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optimizer</span><br></pre></td></tr></table></figure>
<p>é…ç½®è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é…ç½®GPUï¼Œè¿™é‡Œæœ‰ä¸¤ç§æ–¹å¼</span></span><br><span class="line"><span class="comment">## æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨os.environï¼Œåç»­ç”¨.cuda()</span></span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line"><span class="comment"># æ–¹æ¡ˆäºŒï¼šä½¿ç”¨â€œdeviceâ€ï¼Œåç»­å¯¹è¦ä½¿ç”¨GPUçš„å˜é‡ç”¨.to(device)å³å¯</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:1&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## é…ç½®å…¶ä»–è¶…å‚æ•°ï¼Œå¦‚batch_size, num_workers, learning rate, ä»¥åŠæ€»çš„epochs</span></span><br><span class="line">batch_size = <span class="number">256</span> <span class="comment"># æ¯æ¬¡è®­ç»ƒè¯»å…¥çš„æ•°æ®é‡</span></span><br><span class="line">num_workers = <span class="number">4</span>   <span class="comment"># æœ‰å¤šå°‘çº¿ç¨‹æ¥è¯»å…¥æ•°æ®ï¼Œå¯¹äºWindowsç”¨æˆ·ï¼Œè¿™é‡Œåº”è®¾ç½®ä¸º0ï¼Œå¦åˆ™ä¼šå‡ºç°å¤šçº¿ç¨‹é”™è¯¯</span></span><br><span class="line">lr = <span class="number">1e-4</span> <span class="comment"># å‚æ•°æ›´æ–°çš„æ­¥é•¿</span></span><br><span class="line">epochs = <span class="number">20</span> <span class="comment"># è®­ç»ƒå¤šå°‘è½®</span></span><br></pre></td></tr></table></figure>
<h2 id="äºŒã€-æ•°æ®è¯»å…¥"><a href="#äºŒã€-æ•°æ®è¯»å…¥" class="headerlink" title="äºŒã€ æ•°æ®è¯»å…¥"></a>äºŒã€ æ•°æ®è¯»å…¥</h2><p>æœ‰ä¸¤ç§æ–¹å¼ï¼š</p>
<ul>
<li>ä¸‹è½½å¹¶ä½¿ç”¨PyTorchæä¾›çš„å†…ç½®æ•°æ®é›†<br>åªé€‚ç”¨äºå¸¸è§çš„æ•°æ®é›†ï¼Œå¦‚MNISTï¼ŒCIFAR10ç­‰ï¼ŒPyTorchå®˜æ–¹æä¾›äº†æ•°æ®ä¸‹è½½ã€‚è¿™ç§æ–¹å¼å¾€å¾€é€‚ç”¨äºå¿«é€Ÿæµ‹è¯•æ–¹æ³•ï¼ˆæ¯”å¦‚æµ‹è¯•ä¸‹æŸä¸ªideaåœ¨MNISTæ•°æ®é›†ä¸Šæ˜¯å¦æœ‰æ•ˆï¼‰<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é¦–å…ˆè®¾ç½®æ•°æ®å˜æ¢</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">28</span> </span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),   <span class="comment"># è¿™ä¸€æ­¥å–å†³äºåç»­çš„æ•°æ®è¯»å–æ–¹å¼ï¼Œå¦‚æœä½¿ç”¨å†…ç½®æ•°æ®é›†åˆ™ä¸éœ€è¦</span></span><br><span class="line">    transforms.Resize(image_size),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## è¯»å–æ–¹å¼ä¸€ï¼šä½¿ç”¨torchvisionè‡ªå¸¦æ•°æ®é›†ï¼Œä¸‹è½½å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">train_data = datasets.FashionMNIST(root=<span class="string">&#x27;./&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=data_transform)</span><br><span class="line">test_data = datasets.FashionMNIST(root=<span class="string">&#x27;./&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=data_transform)</span><br></pre></td></tr></table></figure></li>
<li>ä»ç½‘ç«™ä¸‹è½½ä»¥csvæ ¼å¼å­˜å‚¨çš„æ•°æ®ï¼Œè¯»å…¥å¹¶è½¬æˆé¢„æœŸçš„æ ¼å¼<br>éœ€è¦è‡ªå·±æ„å»ºDatasetï¼Œè¿™å¯¹äºPyTorchåº”ç”¨äºè‡ªå·±çš„å·¥ä½œä¸­ååˆ†é‡è¦,åŒæ—¶ï¼Œè¿˜éœ€è¦å¯¹æ•°æ®è¿›è¡Œå¿…è¦çš„å˜æ¢ï¼Œæ¯”å¦‚è¯´éœ€è¦å°†å›¾ç‰‡ç»Ÿä¸€ä¸ºä¸€è‡´çš„å¤§å°ï¼Œä»¥ä¾¿åç»­èƒ½å¤Ÿè¾“å…¥ç½‘ç»œè®­ç»ƒï¼›éœ€è¦å°†æ•°æ®æ ¼å¼è½¬ä¸ºTensorç±»ï¼Œç­‰ç­‰ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## è¯»å–æ–¹å¼äºŒï¼šè¯»å…¥csvæ ¼å¼çš„æ•°æ®ï¼Œè‡ªè¡Œæ„å»ºDatasetç±»</span></span><br><span class="line"><span class="comment"># csvæ•°æ®ä¸‹è½½é“¾æ¥ï¼šhttps://www.kaggle.com/zalando-research/fashionmnist</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FMDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, df, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.df = df</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.images = df.iloc[:,<span class="number">1</span>:].values.astype(np.uint8)</span><br><span class="line">        self.labels = df.iloc[:, <span class="number">0</span>].values</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        image = self.images[idx].reshape(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>) <span class="comment"># 1æ˜¯å•ä¸€é€šé“</span></span><br><span class="line">        label = <span class="built_in">int</span>(self.labels[idx])</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image = torch.tensor(image/<span class="number">255.</span>, dtype=torch.<span class="built_in">float</span>) <span class="comment"># image/255 æŠŠæ•°å€¼å½’ä¸€åŒ–</span></span><br><span class="line">        label = torch.tensor(label, dtype=torch.long)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">&quot;./fashion-mnist_train.csv&quot;</span>)</span><br><span class="line">test_df = pd.read_csv(<span class="string">&quot;./fashion-mnist_test.csv&quot;</span>)</span><br><span class="line">train_data = FMDataset(train_df, data_transform)</span><br><span class="line">test_data = FMDataset(test_df, data_transform)</span><br></pre></td></tr></table></figure>
PyTorchæ•°æ®è¯»å…¥æ˜¯é€šè¿‡Dataset+DataLoaderçš„æ–¹å¼å®Œæˆçš„ï¼ŒDatasetå®šä¹‰å¥½æ•°æ®çš„æ ¼å¼å’Œæ•°æ®å˜æ¢å½¢å¼ï¼ŒDataLoaderç”¨iterativeçš„æ–¹å¼ä¸æ–­è¯»å…¥æ‰¹æ¬¡æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„Datasetç±»æ¥å®ç°çµæ´»çš„æ•°æ®è¯»å–ï¼Œå®šä¹‰çš„ç±»éœ€è¦ç»§æ‰¿PyTorchè‡ªèº«çš„Datasetç±»ã€‚ä¸»è¦åŒ…å«ä¸‰ä¸ªå‡½æ•°ï¼š</li>
<li>_<em>init</em>_: ç”¨äºå‘ç±»ä¸­ä¼ å…¥å¤–éƒ¨å‚æ•°ï¼ŒåŒæ—¶å®šä¹‰æ ·æœ¬é›†</li>
<li>_<em>getitem</em>_: ç”¨äºé€ä¸ªè¯»å–æ ·æœ¬é›†åˆä¸­çš„å…ƒç´ ï¼Œå¯ä»¥è¿›è¡Œä¸€å®šçš„å˜æ¢ï¼Œå¹¶å°†è¿”å›è®­ç»ƒ&#x2F;éªŒè¯æ‰€éœ€çš„æ•°æ®</li>
<li>_<em>len</em>_: ç”¨äºè¿”å›æ•°æ®é›†çš„æ ·æœ¬æ•°<br>åœ¨æ„å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†å®Œæˆåï¼Œéœ€è¦å®šä¹‰DataLoaderç±»ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶åŠ è½½æ•°æ®:<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers, drop_last=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure>
è¯»å…¥åï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€äº›æ•°æ®å¯è§†åŒ–æ“ä½œï¼Œä¸»è¦æ˜¯éªŒè¯æˆ‘ä»¬è¯»å…¥çš„æ•°æ®æ˜¯å¦æ­£ç¡®:<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image, label = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="built_in">print</span>(image.shape, label.shape)</span><br><span class="line">plt.imshow(image[<span class="number">0</span>][<span class="number">0</span>], cmap=<span class="string">&quot;gray&quot;</span>)</span><br></pre></td></tr></table></figure>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665566323623/D2B5CA33BD970F64A6301FA75AE2EB22" width="250">  
</center></li>
</ul>
<h2 id="ä¸‰ã€-æ¨¡å‹æ„å»º"><a href="#ä¸‰ã€-æ¨¡å‹æ„å»º" class="headerlink" title="ä¸‰ã€ æ¨¡å‹æ„å»º"></a>ä¸‰ã€ æ¨¡å‹æ„å»º</h2><p>æˆ‘ä»¬è¿™é‡Œçš„ä»»åŠ¡æ˜¯å¯¹10ä¸ªç±»åˆ«çš„â€œæ—¶è£…â€å›¾åƒè¿›è¡Œåˆ†ç±»ï¼ŒFashionMNISTæ•°æ®é›†ä¸­åŒ…å«å·²ç»é¢„å…ˆåˆ’åˆ†å¥½çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­è®­ç»ƒé›†å…±60,000å¼ å›¾åƒï¼Œæµ‹è¯•é›†å…±10,000å¼ å›¾åƒã€‚æ¯å¼ å›¾åƒå‡ä¸ºå•é€šé“é»‘ç™½å›¾åƒï¼Œå¤§å°ä¸º32*32pixelï¼Œåˆ†å±10ä¸ªç±»åˆ«ã€‚ç”±äºä»»åŠ¡è¾ƒä¸ºç®€å•ï¼Œè¿™é‡Œæˆ‘ä»¬<strong>æ‰‹æ­ä¸€ä¸ªCNN</strong>ï¼Œè€Œä¸è€ƒè™‘å½“ä¸‹å„ç§æ¨¡å‹çš„å¤æ‚ç»“æ„ï¼Œæ¨¡å‹æ„å»ºå®Œæˆåï¼Œå°†æ¨¡å‹æ”¾åˆ°GPUä¸Šç”¨äºè®­ç»ƒã€‚<br>Module ç±»æ˜¯nnæ¨¡å—ï§©æä¾›çš„ä¸€ä¸ªæ¨¡å‹æ„é€ ç±»ï¼Œæ˜¯æ‰€æœ‰ç¥ç»â½¹ç½‘ç»œæ¨¡å—çš„åŸºç±»ï¼Œæˆ‘ä»¬å¯ä»¥ç»§æ‰¿å®ƒæ¥å®šä¹‰æˆ‘ä»¬æƒ³è¦çš„æ¨¡å‹ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__() </span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="comment"># x = nn.functional.normalize(x)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">model = model.cuda()</span><br><span class="line"><span class="comment"># model = nn.DataParallel(model).cuda()   # å¤šå¡è®­ç»ƒæ—¶çš„å†™æ³•ï¼Œä¹‹åçš„è¯¾ç¨‹ä¸­ä¼šè¿›ä¸€æ­¥è®²è§£</span></span><br></pre></td></tr></table></figure>
<pre><code>torch.nn.Conv2d(
  in_channels, 
  out_channels, 
  kernel_size, 
  stride=1, 
  padding=0, 
  dilation=1, 
  groups=1, 
  bias=True, 
  padding_mode=&#39;zeros&#39;, 
  device=None, 
  dtype=None)

torch.nn.MaxPool2d(
  kernel_size, 
  stride=None, 
  padding=0, 
  dilation=1, 
  return_indices=False, 
  ceil_mode=False)
</code></pre>
<p>$d_{out} &#x3D;(d_{in}âˆ’dilationâˆ—(kernelsizeâˆ’1)âˆ’1+2âˆ—padding)&#x2F;stride+1)$<br><strong>ä¸‹é¢å†ä¸¾ä¸€ä¸ªå…¶ä»–æ¨¡å‹MLPï¼š</strong><br>ç»§æ‰¿Moduleç±»æ„é€ å¤šå±‚æ„ŸçŸ¥æœº,è¿™ï§©å®šä¹‰çš„MLPç±»é‡è½½ï¦ºModuleç±»çš„initå‡½æ•°å’Œforwardå‡½æ•°ã€‚å®ƒä»¬åˆ†åˆ«ç”¨äºåˆ›å»ºæ¨¡å‹å‚æ•°å’Œå®šä¹‰å‰å‘è®¡ç®—ã€‚å‰å‘è®¡ç®—ä¹Ÿå³æ­£å‘ä¼ æ’­ã€‚ç³»ç»Ÿå°†é€šè¿‡â¾ƒåŠ¨æ±‚æ¢¯åº¦â½½è‡ªåŠ¨â½£æˆåå‘ä¼ æ’­æ‰€éœ€çš„ backward å‡½æ•°ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="comment"># å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨MLPçˆ¶ç±»Blockçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°</span></span><br><span class="line">    <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line">    self.hidden = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">    self.act = nn.ReLU()</span><br><span class="line">    self.output = nn.Linear(<span class="number">256</span>,<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">   <span class="comment"># å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    o = self.act(self.hidden(x))</span><br><span class="line">    <span class="keyword">return</span> self.output(o)   </span><br></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å¯ä»¥å®ä¾‹åŒ– MLP ç±»å¾—åˆ°æ¨¡å‹å˜ï¥¾ net ã€‚ä¸‹â¾¯çš„ä»£ç åˆå§‹åŒ– net å¹¶ä¼ å…¥è¾“â¼Šæ•°æ® X åšä¸€æ¬¡å‰å‘è®¡ç®—ã€‚å…¶ä¸­ï¼Œ net(X) ä¼šè°ƒç”¨ MLP ç»§æ‰¿â¾ƒè‡ª Module ç±»çš„ call å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°å°†è°ƒâ½¤ç”¨ MLP ç±»å®šä¹‰çš„forward å‡½æ•°æ¥å®Œæˆå‰å‘è®¡ç®—ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(<span class="number">2</span>,<span class="number">784</span>)</span><br><span class="line">net = MLP()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line">net(X)</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„ï¼Œè¿™ï§©å¹¶æ²¡æœ‰å°† Module ç±»å‘½åä¸º Layer (å±‚)æˆ–è€… Model (æ¨¡å‹)ä¹‹ç±»çš„åå­—ï¼Œè¿™æ˜¯å› ä¸ºè¯¥ç±»æ˜¯ä¸€ä¸ªå¯ä¾›â¾ƒç”±ç»„å»ºçš„éƒ¨ä»¶ã€‚å®ƒçš„å­ç±»æ—¢å¯ä»¥æ˜¯â¼€ä¸ªå±‚(å¦‚PyTorchæä¾›çš„ Linear ç±»)ï¼Œâ¼œå¯ä»¥æ˜¯ä¸€ä¸ªæ¨¡å‹(å¦‚è¿™ï§©å®šä¹‰çš„ MLP ç±»)ï¼Œæˆ–è€…æ˜¯æ¨¡å‹çš„â¼€ä¸ªéƒ¨åˆ†ã€‚<br><strong>ä¸‹é¢ä»‹ç»ä¸€äº›ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„å±‚ï¼š</strong><br>æ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªé­…ï¦Šåœ¨äºç¥ç»ç½‘ç»œä¸­å„å¼å„æ ·çš„å±‚ï¼Œä¾‹å¦‚å…¨è¿æ¥å±‚ã€å·ç§¯å±‚ã€æ± åŒ–å±‚ä¸å¾ªç¯å±‚ç­‰ç­‰ã€‚è™½ç„¶PyTorchæä¾›äº†â¼¤ï¥¾å¸¸ç”¨çš„å±‚ï¼Œä½†æœ‰æ—¶å€™æˆ‘ä»¬ä¾ç„¶å¸Œæœ›â¾ƒå®šä¹‰å±‚ã€‚</p>
<ol>
<li>ä¸å«æ¨¡å‹å‚æ•°çš„å±‚<br>ä¸‹â¾¯æ„é€ çš„ <strong>MyLayer</strong> ç±»é€šè¿‡ç»§æ‰¿ Module ç±»è‡ªå®šä¹‰ï¦ºä¸€ä¸ªå°†è¾“å…¥å‡æ‰å‡å€¼åè¾“å‡ºçš„å±‚ï¼Œå¹¶å°†å±‚çš„è®¡ç®—å®šä¹‰åœ¨ï¦º forward å‡½æ•°ï§©ã€‚è¿™ä¸ªå±‚ï§©ï¥§å«æ¨¡å‹å‚æ•°ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyLayer, self).__init__(**kwargs)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x - x.mean()  </span><br><span class="line"><span class="comment"># æµ‹è¯•ï¼Œå®ä¾‹åŒ–è¯¥å±‚ï¼Œç„¶ååšå‰å‘è®¡ç®—        </span></span><br><span class="line">layer = MyLayer()</span><br><span class="line">layer(torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>))</span><br></pre></td></tr></table></figure></li>
<li>å«æ¨¡å‹å‚æ•°çš„å±‚<br>è‡ªå®šä¹‰å«æ¨¡å‹å‚æ•°çš„è‡ªå®šä¹‰å±‚ï¼Œå…¶ä¸­çš„æ¨¡å‹å‚æ•°å¯ä»¥é€šè¿‡è®­ç»ƒå­¦å‡ºã€‚<strong>Parameter</strong> ç±»å…¶å®æ˜¯ Tensor çš„å­ç±»ï¼Œå¦‚æœä¸€ä¸ª Tensor æ˜¯ Parameter ï¼Œé‚£ä¹ˆå®ƒä¼šâ¾ƒåŠ¨è¢«æ·»åŠ åˆ°æ¨¡å‹çš„å‚æ•°ï¦œè¡¨ï§©ã€‚æ‰€ä»¥åœ¨â¾ƒå®šä¹‰å«æ¨¡å‹å‚æ•°çš„å±‚æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å°†å‚æ•°å®šä¹‰æˆ Parameter ï¼Œé™¤äº†ç›´æ¥å®šä¹‰æˆ Parameter ç±»å¤–ï¼Œè¿˜å¯ä»¥ä½¿â½¤ <strong>ParameterList</strong> å’Œ <strong>ParameterDict</strong> åˆ†åˆ«å®šä¹‰å‚æ•°çš„ï¦œè¡¨å’Œå­—å…¸ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyListDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyListDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">        self.params.append(nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.params)):</span><br><span class="line">            x = torch.mm(x, self.params[i]) <span class="comment"># torch.mmçŸ©é˜µç›¸ä¹˜ï¼Œä¸¤ä¸ªäºŒç»´å¼ é‡ç›¸ä¹˜</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">net = MyListDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDictDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyDictDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">                <span class="string">&#x27;linear1&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">                <span class="string">&#x27;linear2&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">        &#125;)</span><br><span class="line">        self.params.update(&#123;<span class="string">&#x27;linear3&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">2</span>))&#125;) <span class="comment"># æ–°å¢</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice=<span class="string">&#x27;linear1&#x27;</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(x, self.params[choice])</span><br><span class="line"></span><br><span class="line">net = MyDictDense()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>
ä¸‹é¢ç»™å‡ºå¸¸è§çš„ç¥ç»ç½‘ç»œçš„ä¸€äº›å±‚ï¼Œæ¯”å¦‚å·ç§¯å±‚ã€æ± åŒ–å±‚ï¼Œä»¥åŠè¾ƒä¸ºåŸºç¡€çš„AlexNetï¼ŒLeNetç­‰ã€‚</li>
<li>äºŒç»´å·ç§¯å±‚<br>äºŒç»´å·ç§¯å±‚å°†è¾“å…¥å’Œ<strong>å·ç§¯æ ¸</strong>åšäº’ç›¸å…³è¿ç®—ï¼Œå¹¶åŠ ä¸Šä¸€ä¸ª<strong>æ ‡ï¥¾åå·®</strong>æ¥å¾—åˆ°è¾“å‡ºã€‚å·ç§¯å±‚çš„æ¨¡å‹å‚æ•°åŒ…æ‹¬ï¦ºå·ç§¯æ ¸å’Œæ ‡ï¥¾åå·®ã€‚åœ¨è®­ç»ƒæ¨¡å‹çš„æ—¶å€™ï¼Œé€šå¸¸æˆ‘ä»¬å…ˆå¯¹å·ç§¯æ ¸éšæœºåˆå§‹åŒ–ï¼Œç„¶åï¥§æ–­è¿­ä»£å·ç§¯æ ¸å’Œåå·®ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># å·ç§¯è¿ç®—ï¼ˆäºŒç»´äº’ç›¸å…³ï¼‰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span>(<span class="params">X, K</span>):</span> </span><br><span class="line">    h, w = K.shape</span><br><span class="line">    X, K = X.<span class="built_in">float</span>(), K.<span class="built_in">float</span>()</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i: i + h, j: j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># äºŒç»´å·ç§¯å±‚</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Conv2D, self).__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(kernel_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure>
ä¸‹é¢çš„ï¦µå­é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªâ¾¼å’Œå®½ä¸º3çš„äºŒç»´å·ç§¯å±‚ï¼Œç„¶åè®¾è¾“â¼Šé«˜å’Œå®½ä¸¤ä¾§çš„å¡«å……æ•°åˆ†åˆ«ä¸º1ã€‚ç»™å®šä¸€ä¸ªé«˜å’Œå®½ä¸º8çš„è¾“å…¥ï¼Œæˆ‘ä»¬å‘ç°è¾“å‡ºçš„é«˜å’Œå®½ä¹Ÿæ˜¯8ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å·ç§¯å±‚ã€‚å®ƒå¯¹è¾“å…¥å’Œè¾“å‡ºåšç›¸åº”çš„å‡ç»´å’Œé™ç»´</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span></span><br><span class="line">    <span class="comment"># (1, 1)ä»£è¡¨æ‰¹é‡å¤§å°å’Œé€šé“æ•°</span></span><br><span class="line">    X = X.view((<span class="number">1</span>, <span class="number">1</span>) + X.shape) <span class="comment"># åŠ ä¸Šä¸¤ä¸ªç»´åº¦</span></span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="keyword">return</span> Y.view(Y.shape[<span class="number">2</span>:]) <span class="comment"># æ’é™¤ä¸å…³å¿ƒçš„å‰ä¸¤ç»´:æ‰¹é‡å’Œé€šé“</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ³¨æ„è¿™é‡Œæ˜¯ä¸¤ä¾§åˆ†åˆ«å¡«å……1â¾æˆ–åˆ—ï¼Œæ‰€ä»¥åœ¨ä¸¤ä¾§ä¸€å…±å¡«å……2â¾æˆ–åˆ—</span></span><br><span class="line">conv2d = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X = torch.rand(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure>
å½“å·ç§¯æ ¸çš„é«˜å’Œå®½ï¥§åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®é«˜å’Œå®½ä¸Šï¥§åŒçš„å¡«å……æ•°ä½¿è¾“å‡ºå’Œè¾“å…¥å…·æœ‰ç›¸åŒçš„é«˜å’Œå®½ã€‚å¡«å……å¯ä»¥å¢åŠ è¾“å‡ºçš„é«˜å’Œå®½ã€‚è¿™å¸¸ç”¨æ¥ä½¿è¾“å‡ºä¸è¾“å…¥å…·æœ‰ç›¸åŒçš„é«˜å’Œå®½ã€‚æ­¥å¹…å¯ä»¥å‡å°è¾“å‡ºçš„é«˜å’Œå®½ï¼Œï¦µå¦‚è¾“å‡ºçš„é«˜å’Œå®½ä»…ä¸ºè¾“å…¥çš„é«˜å’Œå®½çš„ ( ä¸ºå¤§äº1çš„æ•´æ•°)ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨é«˜ä¸º5ã€å®½ä¸º3çš„å·ç§¯æ ¸ã€‚åœ¨â¾¼å’Œå®½ä¸¤ä¾§çš„å¡«å……æ•°åˆ†åˆ«ä¸º2å’Œ1ï¼Œ-5+2*2=-3+2*1</span></span><br><span class="line">conv2d = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">3</span>), padding=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></table></figure></li>
<li>æ± åŒ–å±‚<br>æ± åŒ–å±‚æ¯æ¬¡å¯¹è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå›ºå®šå½¢çŠ¶çª—å£(â¼œç§°æ± åŒ–çª—å£)ä¸­çš„å…ƒç´ è®¡ç®—è¾“å‡ºã€‚ï¥§åŒäºå·ç§¯å±‚ï§©è®¡ç®—è¾“â¼Šå’Œæ ¸çš„äº’ç›¸å…³æ€§ï¼Œæ± åŒ–å±‚ç›´æ¥è®¡ç®—æ± åŒ–çª—å£å†…å…ƒç´ çš„æœ€å¤§å€¼æˆ–è€…å¹³å‡å€¼ã€‚è¯¥è¿ç®—ä¹Ÿåˆ†åˆ«å«åšæœ€å¤§æ± åŒ–æˆ–å¹³å‡æ± åŒ–ã€‚åœ¨äºŒç»´æœ€â¼¤æ± åŒ–ä¸­ï¼Œæ± åŒ–çª—å£ä»è¾“å…¥æ•°ç»„çš„æœ€å·¦ä¸Šæ–¹å¼€å§‹ï¼ŒæŒ‰ä»å·¦å¾€å³ã€ä»ä¸Šå¾€ä¸‹çš„é¡ºåºï¼Œä¾æ¬¡åœ¨è¾“â¼Šæ•°ç»„ä¸Šæ»‘åŠ¨ã€‚å½“æ± åŒ–çª—å£æ»‘åŠ¨åˆ°æŸâ¼€ä½ç½®æ—¶ï¼Œçª—å£ä¸­çš„è¾“å…¥å­æ•°ç»„çš„æœ€å¤§å€¼å³è¾“å‡ºæ•°ç»„ä¸­ç›¸åº”ä½ç½®çš„å…ƒç´ ã€‚ä¸‹é¢æŠŠæ± åŒ–å±‚çš„å‰å‘è®¡ç®—å®ç°åœ¨pool2då‡½æ•°é‡Œã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨torch.nnåŒ…æ¥æ„å»ºç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬å·²ç»ä»‹ç»äº†autogradåŒ…ï¼ŒnnåŒ…åˆ™ä¾èµ–äºautogradåŒ…æ¥å®šä¹‰æ¨¡å‹å¹¶å¯¹å®ƒä»¬æ±‚å¯¼ã€‚ä¸€ä¸ªnn.ModuleåŒ…å«å„ä¸ªå±‚å’Œä¸€ä¸ªforward(input)æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è¿”å›outputã€‚</li>
<li>LeNetæ¨¡å‹ç¤ºä¾‹<center> 
<img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.4.1.png" width="480">  
</center>
è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œ (feed-forward networkï¼‰ï¼ˆLeNetï¼‰ã€‚å®ƒæ¥å—ä¸€ä¸ªè¾“å…¥ï¼Œç„¶åå°†å®ƒé€å…¥ä¸‹ä¸€å±‚ï¼Œä¸€å±‚æ¥ä¸€å±‚çš„ä¼ é€’ï¼Œæœ€åç»™å‡ºè¾“å‡ºã€‚ä¸€ä¸ªç¥ç»ç½‘ç»œçš„å…¸å‹è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š
å®šä¹‰åŒ…å«ä¸€äº›å¯å­¦ä¹ å‚æ•°(æˆ–è€…å«æƒé‡ï¼‰çš„ç¥ç»ç½‘ç»œ
åœ¨è¾“å…¥æ•°æ®é›†ä¸Šè¿­ä»£
é€šè¿‡ç½‘ç»œå¤„ç†è¾“å…¥
è®¡ç®— loss (è¾“å‡ºå’Œæ­£ç¡®ç­”æ¡ˆçš„è·ç¦»ï¼‰
å°†æ¢¯åº¦åå‘ä¼ æ’­ç»™ç½‘ç»œçš„å‚æ•°
æ›´æ–°ç½‘ç»œçš„æƒé‡ï¼Œä¸€èˆ¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„è§„åˆ™ï¼šweight = weight - learning_rate * gradient
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># è¾“å…¥å›¾åƒchannelï¼š1ï¼›è¾“å‡ºchannelï¼š6ï¼›5x5å·ç§¯æ ¸</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 2x2 Max pooling</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># å¦‚æœæ˜¯æ–¹é˜µ,åˆ™å¯ä»¥åªä½¿ç”¨ä¸€ä¸ªæ•°å­—è¿›è¡Œå®šä¹‰</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># é™¤å»æ‰¹å¤„ç†ç»´åº¦çš„å…¶ä»–æ‰€æœ‰ç»´åº¦</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>

<pre><code> Net(
   (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
   (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
   (fc1): Linear(in_features=400, out_features=120, bias=True)
   (fc2): Linear(in_features=120, out_features=84, bias=True)
   (fc3): Linear(in_features=84, out_features=10, bias=True)
 )
</code></pre>
</li>
</ol>
<p>æˆ‘ä»¬åªéœ€è¦å®šä¹‰ forward å‡½æ•°ï¼Œbackwardå‡½æ•°ä¼šåœ¨ä½¿ç”¨autogradæ—¶è‡ªåŠ¨å®šä¹‰ï¼Œbackwardå‡½æ•°ç”¨æ¥è®¡ç®—å¯¼æ•°ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ forward å‡½æ•°ä¸­ä½¿ç”¨ä»»ä½•é’ˆå¯¹å¼ é‡çš„æ“ä½œå’Œè®¡ç®—ã€‚ä¸€ä¸ªæ¨¡å‹çš„å¯å­¦ä¹ å‚æ•°å¯ä»¥é€šè¿‡net.parameters()è¿”å›ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(params))</span><br><span class="line"><span class="built_in">print</span>(params[<span class="number">0</span>].size())  <span class="comment"># conv1çš„æƒé‡</span></span><br></pre></td></tr></table></figure>
<p>å°è¯•éšæœºè¾“å…¥</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="comment"># æ¸…é›¶æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ç¼“å­˜ï¼Œç„¶åè¿›è¡Œéšæœºæ¢¯åº¦çš„åå‘ä¼ æ’­ï¼š</span></span><br><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>torch.nnåªæ”¯æŒå°æ‰¹é‡å¤„ç† (mini-batchesï¼‰ã€‚æ•´ä¸ª torch.nn åŒ…åªæ”¯æŒå°æ‰¹é‡æ ·æœ¬çš„è¾“å…¥ï¼Œä¸æ”¯æŒå•ä¸ªæ ·æœ¬çš„è¾“å…¥ã€‚æ¯”å¦‚ï¼Œnn.Conv2d æ¥å—ä¸€ä¸ª4ç»´çš„å¼ é‡ï¼Œå³nSamples x nChannels x Height x Width å¦‚æœæ˜¯ä¸€ä¸ªå•ç‹¬çš„æ ·æœ¬ï¼Œåªéœ€è¦ä½¿ç”¨input.unsqueeze(0) æ¥æ·»åŠ ä¸€ä¸ªâ€œå‡çš„â€æ‰¹å¤§å°ç»´åº¦ã€‚<br>torch.Tensor - ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼Œæ”¯æŒè¯¸å¦‚backward()ç­‰çš„è‡ªåŠ¨æ±‚å¯¼æ“ä½œï¼ŒåŒæ—¶ä¹Ÿä¿å­˜äº†å¼ é‡çš„æ¢¯åº¦ã€‚<br>nn.Module - ç¥ç»ç½‘ç»œæ¨¡å—ã€‚æ˜¯ä¸€ç§æ–¹ä¾¿å°è£…å‚æ•°çš„æ–¹å¼ï¼Œå…·æœ‰å°†å‚æ•°ç§»åŠ¨åˆ°GPUã€å¯¼å‡ºã€åŠ è½½ç­‰åŠŸèƒ½ã€‚<br>nn.Parameter - å¼ é‡çš„ä¸€ç§ï¼Œå½“å®ƒä½œä¸ºä¸€ä¸ªå±æ€§åˆ†é…ç»™ä¸€ä¸ªModuleæ—¶ï¼Œå®ƒä¼šè¢«è‡ªåŠ¨æ³¨å†Œä¸ºä¸€ä¸ªå‚æ•°ã€‚<br>autograd.Function - å®ç°äº†è‡ªåŠ¨æ±‚å¯¼å‰å‘å’Œåå‘ä¼ æ’­çš„å®šä¹‰ï¼Œæ¯ä¸ªTensorè‡³å°‘åˆ›å»ºä¸€ä¸ªFunctionèŠ‚ç‚¹ï¼Œè¯¥èŠ‚ç‚¹è¿æ¥åˆ°åˆ›å»ºTensorçš„å‡½æ•°å¹¶å¯¹å…¶å†å²è¿›è¡Œç¼–ç ã€‚</p>
<ol>
<li>AlexNetæ¨¡å‹ç¤ºä¾‹<center> 
<img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.4.2.png" width="480">  
</center></li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, <span class="number">11</span>, <span class="number">4</span>), <span class="comment"># in_channels, out_channels, kernel_size, stride, padding</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>), <span class="comment"># kernel_size, stride</span></span><br><span class="line">            <span class="comment"># å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°</span></span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">            <span class="comment"># è¿ç»­3ä¸ªå·ç§¯å±‚ï¼Œä¸”ä½¿ç”¨æ›´å°çš„å·ç§¯çª—å£ã€‚é™¤äº†æœ€åçš„å·ç§¯å±‚å¤–ï¼Œè¿›ä¸€æ­¥å¢å¤§äº†è¾“å‡ºé€šé“æ•°ã€‚</span></span><br><span class="line">            <span class="comment"># å‰ä¸¤ä¸ªå·ç§¯å±‚åä¸ä½¿ç”¨æ± åŒ–å±‚æ¥å‡å°è¾“å…¥çš„é«˜å’Œå®½</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">         <span class="comment"># è¿™é‡Œå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°æ¯”LeNetä¸­çš„å¤§æ•°å€ã€‚ä½¿ç”¨ä¸¢å¼ƒå±‚æ¥ç¼“è§£è¿‡æ‹Ÿåˆ</span></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">256</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            <span class="comment"># è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000</span></span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        feature = self.conv(img)</span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">net = AlexNet()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>
<pre><code>AlexNet(
  (conv): Sequential(
    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU()
    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU()
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=6400, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
</code></pre>
<h2 id="å››ã€-æ¨¡å‹åˆå§‹åŒ–"><a href="#å››ã€-æ¨¡å‹åˆå§‹åŒ–" class="headerlink" title="å››ã€ æ¨¡å‹åˆå§‹åŒ–"></a>å››ã€ æ¨¡å‹åˆå§‹åŒ–</h2><ol>
<li>torch.nn.initä½¿ç”¨<br>é€šå¸¸ä½¿ç”¨isinstanceæ¥è¿›è¡Œåˆ¤æ–­æ¨¡å—<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">conv = nn.Conv2d(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">linear = nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">isinstance</span>(conv,nn.Conv2d)</span><br><span class="line"><span class="built_in">isinstance</span>(linear,nn.Conv2d)</span><br></pre></td></tr></table></figure>
æŸ¥çœ‹ä¸åŒåˆå§‹åŒ–å‚æ•°<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŸ¥çœ‹éšæœºåˆå§‹åŒ–çš„convå‚æ•°</span></span><br><span class="line">conv.weight.data</span><br><span class="line"><span class="comment"># æŸ¥çœ‹linearçš„å‚æ•°</span></span><br><span class="line">linear.weight.data</span><br></pre></td></tr></table></figure>
å¯¹ä¸åŒç±»å‹å±‚è¿›è¡Œåˆå§‹åŒ–<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¹convè¿›è¡Œkaimingåˆå§‹åŒ–</span></span><br><span class="line">torch.nn.init.kaiming_normal_(conv.weight.data)</span><br><span class="line">conv.weight.data</span><br><span class="line"><span class="comment"># å¯¹linearè¿›è¡Œå¸¸æ•°åˆå§‹åŒ–</span></span><br><span class="line">torch.nn.init.constant_(linear.weight.data,<span class="number">0.3</span>)</span><br><span class="line">linear.weight.data</span><br></pre></td></tr></table></figure></li>
<li>åˆå§‹åŒ–å‡½æ•°çš„å°è£…<br>äººä»¬å¸¸å¸¸å°†å„ç§åˆå§‹åŒ–æ–¹æ³•å®šä¹‰ä¸ºä¸€ä¸ªinitialize_weights()çš„å‡½æ•°å¹¶åœ¨æ¨¡å‹åˆå§‹åè¿›è¡Œä½¿ç”¨ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">	<span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">		<span class="comment"># åˆ¤æ–­æ˜¯å¦å±äºConv2d</span></span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">			torch.nn.init.xavier_normal_(m.weight.data)</span><br><span class="line">			<span class="comment"># åˆ¤æ–­æ˜¯å¦æœ‰åç½®</span></span><br><span class="line">			<span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">				torch.nn.init.constant_(m.bias.data,<span class="number">0.3</span>)</span><br><span class="line">		<span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">			torch.nn.init.normal_(m.weight.data, <span class="number">0.1</span>)</span><br><span class="line">			<span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">				torch.nn.init.zeros_(m.bias.data)</span><br><span class="line">		<span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">			m.weight.data.fill_(<span class="number">1</span>) 		 </span><br><span class="line">			m.bias.data.zeros_()	</span><br></pre></td></tr></table></figure>
è¿™æ®µä»£ç æµç¨‹æ˜¯éå†å½“å‰æ¨¡å‹çš„æ¯ä¸€å±‚ï¼Œç„¶ååˆ¤æ–­å„å±‚å±äºä»€ä¹ˆç±»å‹ï¼Œç„¶åæ ¹æ®ä¸åŒç±»å‹å±‚ï¼Œè®¾å®šä¸åŒçš„æƒå€¼åˆå§‹åŒ–æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä¾‹ç¨‹è¿›è¡Œä¸€ä¸ªç®€çŸ­çš„æ¼”ç¤ºï¼š<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ¨¡å‹çš„å®šä¹‰</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="comment"># å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨MLPçˆ¶ç±»Blockçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°</span></span><br><span class="line">    <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line">    self.hidden = nn.Conv2d(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    self.act = nn.ReLU()</span><br><span class="line">    self.output = nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">   <span class="comment"># å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    o = self.act(self.hidden(x))</span><br><span class="line">    <span class="keyword">return</span> self.output(o)</span><br><span class="line"></span><br><span class="line">mlp = MLP()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(mlp.parameters()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-------åˆå§‹åŒ–-------&quot;</span>)</span><br><span class="line"></span><br><span class="line">initialize_weights(mlp)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(mlp.parameters()))</span><br></pre></td></tr></table></figure>

<pre><code> [Parameter containing:
 tensor([[[[ 0.2103, -0.1679,  0.1757],
           [-0.0647, -0.0136, -0.0410],
           [ 0.1371, -0.1738, -0.0850]]]], requires_grad=True), Parameter containing:
 tensor([0.2507], requires_grad=True), Parameter containing:
 tensor([[ 0.2790, -0.1247,  0.2762,  0.1149, -0.2121, -0.3022, -0.1859,  0.2983,
         -0.0757, -0.2868]], requires_grad=True), Parameter containing:
 tensor([-0.0905], requires_grad=True)]
 &quot;-------åˆå§‹åŒ–-------&quot;
 [Parameter containing:
 tensor([[[[-0.3196, -0.0204, -0.5784],
           [ 0.2660,  0.2242, -0.4198],
           [-0.0952,  0.6033, -0.8108]]]], requires_grad=True),
 Parameter containing:
 tensor([0.3000], requires_grad=True),
 Parameter containing:
 tensor([[ 0.7542,  0.5796,  2.2963, -0.1814, -0.9627,  1.9044,  0.4763,  1.2077,
           0.8583,  1.9494]], requires_grad=True),
 Parameter containing:
 tensor([0.], requires_grad=True)]
</code></pre>
</li>
</ol>
<h2 id="äº”ã€-æŸå¤±å‡½æ•°"><a href="#äº”ã€-æŸå¤±å‡½æ•°" class="headerlink" title="äº”ã€ æŸå¤±å‡½æ•°"></a>äº”ã€ æŸå¤±å‡½æ•°</h2><p>è¿™é‡Œä½¿ç”¨torch.nnæ¨¡å—è‡ªå¸¦çš„CrossEntropyæŸå¤±ï¼ŒPyTorchä¼šè‡ªåŠ¨æŠŠæ•´æ•°å‹çš„labelè½¬ä¸ºone-hotå‹ï¼Œç”¨äºè®¡ç®—CE lossï¼Œè¿™é‡Œéœ€è¦ç¡®ä¿labelæ˜¯ä»0å¼€å§‹çš„ï¼ŒåŒæ—¶æ¨¡å‹ä¸åŠ softmaxå±‚ï¼ˆä½¿ç”¨logitsè®¡ç®—ï¼‰,è¿™ä¹Ÿè¯´æ˜äº†PyTorchè®­ç»ƒä¸­å„ä¸ªéƒ¨åˆ†ä¸æ˜¯ç‹¬ç«‹çš„ï¼Œéœ€è¦é€šç›˜è€ƒè™‘ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h3 id="1-äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"><a href="#1-äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°" class="headerlink" title="1. äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"></a>1. äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BCELoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½</strong>ï¼šè®¡ç®—äºŒåˆ†ç±»ä»»åŠ¡æ—¶çš„äº¤å‰ç†µï¼ˆCross Entropyï¼‰å‡½æ•°ã€‚åœ¨äºŒåˆ†ç±»ä¸­ï¼Œlabelæ˜¯{0,1}ã€‚å¯¹äºè¿›å…¥äº¤å‰ç†µå‡½æ•°çš„inputä¸ºæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œinputä¸ºsigmoidæ¿€æ´»å±‚çš„è¾“å‡ºï¼Œæˆ–è€…softmaxçš„è¾“å‡ºã€‚<br><strong>ä¸»è¦å‚æ•°</strong>ï¼š<br><code>weight</code>:æ¯ä¸ªç±»åˆ«çš„lossè®¾ç½®æƒå€¼<br><code>size_average</code>:æ•°æ®ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚<br><code>reduce</code>:æ•°æ®ç±»å‹ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œlossçš„è¿”å›æ˜¯æ ‡é‡ã€‚<br>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665580819001/D2B5CA33BD970F64A6301FA75AE2EB22" width="290">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Sigmoid()</span><br><span class="line">loss = nn.BCELoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.empty(<span class="number">3</span>).random_(<span class="number">2</span>)</span><br><span class="line">output = loss(m(<span class="built_in">input</span>), target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;BCELossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>BCELossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.5732, grad_fn=&lt;BinaryCrossEntropyBackward&gt;)
</code></pre>
<h3 id="2-äº¤å‰ç†µæŸå¤±å‡½æ•°"><a href="#2-äº¤å‰ç†µæŸå¤±å‡½æ•°" class="headerlink" title="2. äº¤å‰ç†µæŸå¤±å‡½æ•°"></a>2. äº¤å‰ç†µæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½</strong>ï¼šè®¡ç®—äº¤å‰ç†µå‡½æ•°<br><strong>ä¸»è¦å‚æ•°</strong>ï¼š<br><code>weight</code>:æ¯ä¸ªç±»åˆ«çš„lossè®¾ç½®æƒå€¼ã€‚<br><code>size_average</code>:æ•°æ®ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œã€‚<br><code>ignore_index</code>:å¿½ç•¥æŸä¸ªç±»çš„æŸå¤±å‡½æ•°ã€‚<br><code>reduce</code>:æ•°æ®ç±»å‹ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œlossçš„è¿”å›æ˜¯æ ‡é‡ã€‚<br>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š<br>$<br>\operatorname{loss}(x, \text { class })&#x3D;-\log \left(\frac{\exp (x[\text { class }])}{\sum_{j} \exp (x[j])}\right)&#x3D;-x[\text { class }]+\log \left(\sum_{j} \exp (x[j])\right)<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.empty(<span class="number">3</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<pre><code>tensor(2.0115, grad_fn=&lt;NllLossBackward&gt;)
</code></pre>
<h3 id="3-L1æŸå¤±å‡½æ•°"><a href="#3-L1æŸå¤±å‡½æ•°" class="headerlink" title="3. L1æŸå¤±å‡½æ•°"></a>3. L1æŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.L1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—è¾“å‡º<code>y</code>å’ŒçœŸå®æ ‡ç­¾<code>target</code>ä¹‹é—´çš„å·®å€¼çš„ç»å¯¹å€¼ã€‚<code>reduction</code>å‚æ•°å†³å®šäº†è®¡ç®—æ¨¡å¼ã€‚æœ‰ä¸‰ç§è®¡ç®—æ¨¡å¼å¯é€‰ï¼šnoneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚meanï¼šåŠ æƒå¹³å‡ï¼Œè¿”å›æ ‡é‡ã€‚å¦‚æœé€‰æ‹©<code>none</code>ï¼Œé‚£ä¹ˆè¿”å›çš„ç»“æœæ˜¯å’Œè¾“å…¥å…ƒç´ ç›¸åŒå°ºå¯¸çš„ã€‚é»˜è®¤è®¡ç®—æ–¹å¼æ˜¯æ±‚å¹³å‡ã€‚<br><strong>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</strong><br>$<br>L_{n} &#x3D; |x_{n}-y_{n}|<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.L1Loss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;L1æŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>L1æŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(1.5729, grad_fn=&lt;L1LossBackward&gt;)
</code></pre>
<h3 id="4-MSEæŸå¤±å‡½æ•°"><a href="#4-MSEæŸå¤±å‡½æ•°" class="headerlink" title="4. MSEæŸå¤±å‡½æ•°"></a>4. MSEæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MSELoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—è¾“å‡º<code>y</code>å’ŒçœŸå®æ ‡ç­¾<code>target</code>ä¹‹å·®çš„å¹³æ–¹ã€‚</p>
<p>å’Œ<code>L1Loss</code>ä¸€æ ·ï¼Œ<code>MSELoss</code>æŸå¤±å‡½æ•°ä¸­ï¼Œ<code>reduction</code>å‚æ•°å†³å®šäº†è®¡ç®—æ¨¡å¼ã€‚æœ‰ä¸‰ç§è®¡ç®—æ¨¡å¼å¯é€‰ï¼šnoneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚é»˜è®¤è®¡ç®—æ–¹å¼æ˜¯æ±‚å¹³å‡ã€‚</p>
<p><strong>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</strong></p>
<p>$<br>l_{n}&#x3D;\left(x_{n}-y_{n}\right)^{2}<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MSEæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MSEæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(1.6968, grad_fn=&lt;MseLossBackward&gt;)
</code></pre>
<h3 id="5-å¹³æ»‘L1-Smooth-L1-æŸå¤±å‡½æ•°"><a href="#5-å¹³æ»‘L1-Smooth-L1-æŸå¤±å‡½æ•°" class="headerlink" title="5. å¹³æ»‘L1 (Smooth L1)æŸå¤±å‡½æ•°"></a>5. å¹³æ»‘L1 (Smooth L1)æŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.SmoothL1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, beta=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> L1çš„å¹³æ»‘è¾“å‡ºï¼Œå…¶åŠŸèƒ½æ˜¯å‡è½»ç¦»ç¾¤ç‚¹å¸¦æ¥çš„å½±å“</p>
<p><code>reduction</code>å‚æ•°å†³å®šäº†è®¡ç®—æ¨¡å¼ã€‚æœ‰ä¸‰ç§è®¡ç®—æ¨¡å¼å¯é€‰ï¼šnoneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚é»˜è®¤è®¡ç®—æ–¹å¼æ˜¯æ±‚å¹³å‡ã€‚</p>
<p><strong>æé†’ï¼š</strong> ä¹‹åçš„æŸå¤±å‡½æ•°ä¸­ï¼Œå…³äº<code>reduction</code> è¿™ä¸ªå‚æ•°ä¾æ—§ä¼šå­˜åœ¨ã€‚æ‰€ä»¥ï¼Œä¹‹åå°±ä¸å†å•ç‹¬è¯´æ˜ã€‚</p>
<p><strong>è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\frac{1}{n} \sum_{i&#x3D;1}^{n} z_{i}<br>$<br>å…¶ä¸­ï¼Œ</p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665580768639/D2B5CA33BD970F64A6301FA75AE2EB22" width="290">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.SmoothL1Loss()</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">output = loss(<span class="built_in">input</span>, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;SmoothL1LossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>SmoothL1LossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7808, grad_fn=&lt;SmoothL1LossBackward&gt;)
</code></pre>
<p><strong>å¹³æ»‘L1ä¸L1çš„å¯¹æ¯”</strong></p>
<p>è¿™é‡Œæˆ‘ä»¬é€šè¿‡å¯è§†åŒ–ä¸¤ç§æŸå¤±å‡½æ•°æ›²çº¿æ¥å¯¹æ¯”å¹³æ»‘L1å’ŒL1ä¸¤ç§æŸå¤±å‡½æ•°çš„åŒºåˆ«ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.linspace(-<span class="number">10</span>, <span class="number">10</span>, steps=<span class="number">5000</span>)</span><br><span class="line">target = torch.zeros_like(inputs)</span><br><span class="line"></span><br><span class="line">loss_f_smooth = nn.SmoothL1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_smooth = loss_f_smooth(inputs, target)</span><br><span class="line">loss_f_l1 = nn.L1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_l1 = loss_f_l1(inputs,target)</span><br><span class="line"></span><br><span class="line">plt.plot(inputs.numpy(), loss_smooth.numpy(), label=<span class="string">&#x27;Smooth L1 Loss&#x27;</span>)</span><br><span class="line">plt.plot(inputs.numpy(), loss_l1, label=<span class="string">&#x27;L1 loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x_i - y_i&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss value&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.5.2.png"><br>å¯ä»¥çœ‹å‡ºï¼Œå¯¹äº<code>smoothL1</code>æ¥è¯´ï¼Œåœ¨ 0 è¿™ä¸ªå°–ç«¯å¤„ï¼Œè¿‡æ¸¡æ›´ä¸ºå¹³æ»‘ã€‚</p>
<h3 id="6-ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±"><a href="#6-ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±" class="headerlink" title="6. ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±"></a>6. ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.PoissonNLLLoss(log_input=<span class="literal">True</span>, full=<span class="literal">False</span>, size_average=<span class="literal">None</span>, eps=<span class="number">1e-08</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±å‡½æ•°<br><strong>ä¸»è¦å‚æ•°ï¼š</strong><br><code>log_input</code>ï¼šè¾“å…¥æ˜¯å¦ä¸ºå¯¹æ•°å½¢å¼ï¼Œå†³å®šè®¡ç®—å…¬å¼ã€‚<br><code>full</code>ï¼šè®¡ç®—æ‰€æœ‰ lossï¼Œé»˜è®¤ä¸º Falseã€‚<br><code>eps</code>ï¼šä¿®æ­£é¡¹ï¼Œé¿å… input ä¸º 0 æ—¶ï¼Œlog(input) ä¸º nan çš„æƒ…å†µã€‚<br><strong>æ•°å­¦å…¬å¼ï¼š</strong></p>
<ul>
<li>å½“å‚æ•°<code>log_input=True</code>ï¼š<br>$<br>\operatorname{loss}\left(x_{n}, y_{n}\right)&#x3D;e^{x_{n}}-x_{n} \cdot y_{n}<br>$</li>
<li>å½“å‚æ•°<code>log_input=False</code>ï¼š<br>  $<br>  \operatorname{loss}\left(x_{n}, y_{n}\right)&#x3D;x_{n}-y_{n} \cdot \log \left(x_{n}+\text { eps }\right)<br>  $</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.PoissonNLLLoss()</span><br><span class="line">log_input = torch.randn(<span class="number">5</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">output = loss(log_input, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;PoissonNLLLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>PoissonNLLLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7358, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h3 id="7-KLæ•£åº¦"><a href="#7-KLæ•£åº¦" class="headerlink" title="7. KLæ•£åº¦"></a>7. KLæ•£åº¦</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.KLDivLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, log_target=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—KLæ•£åº¦ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—ç›¸å¯¹ç†µã€‚ç”¨äºè¿ç»­åˆ†å¸ƒçš„è·ç¦»åº¦é‡ï¼Œå¹¶ä¸”å¯¹ç¦»æ•£é‡‡ç”¨çš„è¿ç»­è¾“å‡ºç©ºé—´åˆ†å¸ƒè¿›è¡Œå›å½’é€šå¸¸å¾ˆæœ‰ç”¨ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º <code>none</code>&#x2F;<code>sum</code>&#x2F;<code>mean</code>&#x2F;<code>batchmean</code>ã€‚</p>
<pre><code>noneï¼šé€ä¸ªå…ƒç´ è®¡ç®—ã€‚
sumï¼šæ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡ã€‚
meanï¼šåŠ æƒå¹³å‡ï¼Œè¿”å›æ ‡é‡ã€‚
batchmeanï¼šbatchsize ç»´åº¦æ±‚å¹³å‡å€¼ã€‚
</code></pre>
<p><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582006862/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">0.9</span>, <span class="number">0.05</span>, <span class="number">0.05</span>], [<span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.2</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">loss = nn.KLDivLoss()</span><br><span class="line">output = loss(inputs,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;KLDivLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>KLDivLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(-0.3335)
</code></pre>
<h3 id="8-MarginRankingLoss"><a href="#8-MarginRankingLoss" class="headerlink" title="8. MarginRankingLoss"></a>8. MarginRankingLoss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MarginRankingLoss(margin=<span class="number">0.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç”¨äºæ’åºä»»åŠ¡ã€‚è¯¥æ–¹æ³•ç”¨äºè®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„å·®å¼‚ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>margin</code>ï¼šè¾¹ç•Œå€¼ï¼Œ$x_{1}$ ä¸$x_{2}$ ä¹‹é—´çš„å·®å¼‚å€¼ã€‚<br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x 1, x 2, y)&#x3D;\max (0,-y *(x 1-x 2)+\operatorname{margin})<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MarginRankingLoss()</span><br><span class="line">input1 = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">input2 = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.randn(<span class="number">3</span>).sign()</span><br><span class="line">output = loss(input1, input2, target)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MarginRankingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MarginRankingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7740, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h3 id="9-å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°"><a href="#9-å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°" class="headerlink" title="9. å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°"></a>9. å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiLabelMarginLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> å¯¹äºå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜è®¡ç®—æŸå¤±å‡½æ•°ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\sum_{i j} \frac{\max (0,1-x[y[j]]-x[i])}{x \cdot \operatorname{size}(0)}<br>$<br>$<br>\begin{array}{l}<br>\text { å…¶ä¸­, } i&#x3D;0, \ldots, x \cdot \operatorname{size}(0), j&#x3D;0, \ldots, y \cdot \operatorname{size}(0), \text { å¯¹äºæ‰€æœ‰çš„ } i \text { å’Œ } j \text {, éƒ½æœ‰ } y[j] \geq 0 \text { å¹¶ä¸” }\<br>i \neq y[j]<br>\end{array}<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.MultiLabelMarginLoss()</span><br><span class="line">x = torch.FloatTensor([[<span class="number">0.9</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.8</span>]])</span><br><span class="line"><span class="comment"># for target y, only consider labels 3 and 0, not after label -1</span></span><br><span class="line">y = torch.LongTensor([[<span class="number">3</span>, <span class="number">0</span>, -<span class="number">1</span>, <span class="number">1</span>]])<span class="comment"># çœŸå®çš„åˆ†ç±»æ˜¯ï¼Œç¬¬3ç±»å’Œç¬¬0ç±»</span></span><br><span class="line">output = loss(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MultiLabelMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MultiLabelMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.4500)
</code></pre>
<h3 id="10-äºŒåˆ†ç±»æŸå¤±å‡½æ•°"><a href="#10-äºŒåˆ†ç±»æŸå¤±å‡½æ•°" class="headerlink" title="10. äºŒåˆ†ç±»æŸå¤±å‡½æ•°"></a>10. äºŒåˆ†ç±»æŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.SoftMarginLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)torch.nn.(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—äºŒåˆ†ç±»çš„ logistic æŸå¤±ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\sum_{i} \frac{\log (1+\exp (-y[i] \cdot x[i]))}{x \cdot \operatorname{nelement}()}<br>$<br>$<br><br>\text { å…¶ä¸­, } x . \text { nelement() ä¸ºè¾“å…¥ } x \text { ä¸­çš„æ ·æœ¬ä¸ªæ•°ã€‚æ³¨æ„è¿™é‡Œ } y \text { ä¹Ÿæœ‰ } 1 \text { å’Œ }-1 \text { ä¸¤ç§æ¨¡å¼ã€‚ }<br><br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.7</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>]])  <span class="comment"># ä¸¤ä¸ªæ ·æœ¬ï¼Œä¸¤ä¸ªç¥ç»å…ƒ</span></span><br><span class="line">target = torch.tensor([[-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)  <span class="comment"># è¯¥ loss ä¸ºé€ä¸ªç¥ç»å…ƒè®¡ç®—ï¼Œéœ€è¦ä¸ºæ¯ä¸ªç¥ç»å…ƒå•ç‹¬è®¾ç½®æ ‡ç­¾</span></span><br><span class="line"></span><br><span class="line">loss_f = nn.SoftMarginLoss()</span><br><span class="line">output = loss_f(inputs, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;SoftMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>SoftMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.6764)
</code></pre>
<h3 id="11-å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±"><a href="#11-å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±" class="headerlink" title="11. å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±"></a>11. å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiMarginLoss(p=<span class="number">1</span>, margin=<span class="number">1.0</span>, weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>pï¼š</code>å¯é€‰ 1 æˆ– 2ã€‚<br><code>weight</code>ï¼šå„ç±»åˆ«çš„ loss è®¾ç½®æƒå€¼ã€‚<br><code>margin</code>ï¼šè¾¹ç•Œå€¼<br><strong>è®¡ç®—å…¬å¼ï¼š</strong><br>$<br>\operatorname{loss}(x, y)&#x3D;\frac{\sum_{i} \max (0, \operatorname{margin}-x[y]+x[i])^{p}}{x \cdot \operatorname{size}(0)}<br>$<br>$<br>\begin{array}{l}<br>\text { å…¶ä¸­, } x \in{0, \ldots, x \cdot \operatorname{size}(0)-1}, y \in{0, \ldots, y \cdot \operatorname{size}(0)-1} \text {, å¹¶ä¸”å¯¹äºæ‰€æœ‰çš„ } i \text { å’Œ } j \text {, }\<br>\text { éƒ½æœ‰ } 0 \leq y[j] \leq x \cdot \operatorname{size}(0)-1, \text { ä»¥åŠ } i \neq y[j] \text { ã€‚ }<br>\end{array}<br>$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.7</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>]]) </span><br><span class="line">target = torch.tensor([<span class="number">0</span>, <span class="number">1</span>], dtype=torch.long) </span><br><span class="line"></span><br><span class="line">loss_f = nn.MultiMarginLoss()</span><br><span class="line">output = loss_f(inputs, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;MultiMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>MultiMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.6000)
</code></pre>
<h3 id="12-ä¸‰å…ƒç»„æŸå¤±"><a href="#12-ä¸‰å…ƒç»„æŸå¤±" class="headerlink" title="12. ä¸‰å…ƒç»„æŸå¤±"></a>12. ä¸‰å…ƒç»„æŸå¤±</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.TripletMarginLoss(margin=<span class="number">1.0</span>, p=<span class="number">2.0</span>, eps=<span class="number">1e-06</span>, swap=<span class="literal">False</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> è®¡ç®—ä¸‰å…ƒç»„æŸå¤±ã€‚<br><strong>ä¸‰å…ƒç»„:</strong> è¿™æ˜¯ä¸€ç§æ•°æ®çš„å­˜å‚¨æˆ–è€…ä½¿ç”¨æ ¼å¼ã€‚&lt;å®ä½“1ï¼Œå…³ç³»ï¼Œå®ä½“2&gt;ã€‚åœ¨é¡¹ç›®ä¸­ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºä¸º&lt; <code>anchor</code>, <code>positive examples</code> , <code>negative examples</code>&gt;<br>åœ¨è¿™ä¸ªæŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›å»<code>anchor</code>çš„è·ç¦»æ›´æ¥è¿‘<code>positive examples</code>ï¼Œè€Œè¿œç¦»<code>negative examples </code><br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>pï¼š</code>å¯é€‰ 1 æˆ– 2ã€‚<br><code>margin</code>ï¼šè¾¹ç•Œå€¼<br><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582222120/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">triplet_loss = nn.TripletMarginLoss(margin=<span class="number">1.0</span>, p=<span class="number">2</span>)</span><br><span class="line">anchor = torch.randn(<span class="number">100</span>, <span class="number">128</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">positive = torch.randn(<span class="number">100</span>, <span class="number">128</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">negative = torch.randn(<span class="number">100</span>, <span class="number">128</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">output = triplet_loss(anchor, positive, negative)</span><br><span class="line">output.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;TripletMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>TripletMarginLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(1.1667, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h3 id="13-HingEmbeddingLoss"><a href="#13-HingEmbeddingLoss" class="headerlink" title="13. HingEmbeddingLoss"></a>13. HingEmbeddingLoss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.HingeEmbeddingLoss(margin=<span class="number">1.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> å¯¹è¾“å‡ºçš„embeddingç»“æœåšHingæŸå¤±è®¡ç®—<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>margin</code>ï¼šè¾¹ç•Œå€¼<br><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582284050/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<p><strong>æ³¨æ„äº‹é¡¹ï¼š</strong> è¾“å…¥xåº”ä¸ºä¸¤ä¸ªè¾“å…¥ä¹‹å·®çš„ç»å¯¹å€¼ã€‚<br>å¯ä»¥è¿™æ ·ç†è§£ï¼Œè®©ä¸ªè¾“å‡ºçš„æ˜¯æ­£ä¾‹yn&#x3D;1,é‚£ä¹ˆlosså°±æ˜¯xï¼Œå¦‚æœè¾“å‡ºçš„æ˜¯è´Ÿä¾‹y&#x3D;-1ï¼Œé‚£ä¹ˆè¾“å‡ºçš„losså°±æ˜¯è¦åšä¸€ä¸ªæ¯”è¾ƒã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss_f = nn.HingeEmbeddingLoss()</span><br><span class="line">inputs = torch.tensor([[<span class="number">1.</span>, <span class="number">0.8</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">output = loss_f(inputs,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;HingEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>HingEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.7667)
</code></pre>
<h3 id="14-ä½™å¼¦ç›¸ä¼¼åº¦"><a href="#14-ä½™å¼¦ç›¸ä¼¼åº¦" class="headerlink" title="14. ä½™å¼¦ç›¸ä¼¼åº¦"></a>14. ä½™å¼¦ç›¸ä¼¼åº¦</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CosineEmbeddingLoss(margin=<span class="number">0.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> å¯¹ä¸¤ä¸ªå‘é‡åšä½™å¼¦ç›¸ä¼¼åº¦<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>margin</code>ï¼šå¯å–å€¼[-1,1] ï¼Œæ¨èä¸º[0,0.5] ã€‚<br><strong>è®¡ç®—å…¬å¼ï¼š</strong></p>
<center> 
<img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665582351089/D2B5CA33BD970F64A6301FA75AE2EB22" width="350">  
</center>

<p>è¿™ä¸ªæŸå¤±å‡½æ•°åº”è¯¥æ˜¯æœ€å¹¿ä¸ºäººçŸ¥çš„ã€‚å¯¹äºä¸¤ä¸ªå‘é‡ï¼Œåšä½™å¼¦ç›¸ä¼¼åº¦ã€‚å°†ä½™å¼¦ç›¸ä¼¼åº¦ä½œä¸ºä¸€ä¸ªè·ç¦»çš„è®¡ç®—æ–¹å¼ï¼Œå¦‚æœä¸¤ä¸ªå‘é‡çš„è·ç¦»è¿‘ï¼Œåˆ™æŸå¤±å‡½æ•°å€¼å°ï¼Œåä¹‹äº¦ç„¶ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss_f = nn.CosineEmbeddingLoss()</span><br><span class="line">inputs_1 = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.7</span>], [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.7</span>]])</span><br><span class="line">inputs_2 = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>], [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, -<span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">output = loss_f(inputs_1,inputs_2,target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;CosineEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,output)</span><br></pre></td></tr></table></figure>

<pre><code>CosineEmbeddingLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(0.5000)
</code></pre>
<h3 id="15-CTCæŸå¤±å‡½æ•°"><a href="#15-CTCæŸå¤±å‡½æ•°" class="headerlink" title="15.CTCæŸå¤±å‡½æ•°"></a>15.CTCæŸå¤±å‡½æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CTCLoss(blank=<span class="number">0</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, zero_infinity=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠŸèƒ½ï¼š</strong> ç”¨äºè§£å†³æ—¶åºç±»æ•°æ®çš„åˆ†ç±»<br>è®¡ç®—è¿ç»­æ—¶é—´åºåˆ—å’Œç›®æ ‡åºåˆ—ä¹‹é—´çš„æŸå¤±ã€‚CTCLosså¯¹è¾“å…¥å’Œç›®æ ‡çš„å¯èƒ½æ’åˆ—çš„æ¦‚ç‡è¿›è¡Œæ±‚å’Œï¼Œäº§ç”Ÿä¸€ä¸ªæŸå¤±å€¼ï¼Œè¿™ä¸ªæŸå¤±å€¼å¯¹æ¯ä¸ªè¾“å…¥èŠ‚ç‚¹æ¥è¯´æ˜¯å¯åˆ†çš„ã€‚è¾“å…¥ä¸ç›®æ ‡çš„å¯¹é½æ–¹å¼è¢«å‡å®šä¸º â€œå¤šå¯¹ä¸€â€ï¼Œè¿™å°±é™åˆ¶äº†ç›®æ ‡åºåˆ—çš„é•¿åº¦ï¼Œä½¿å…¶å¿…é¡»æ˜¯â‰¤è¾“å…¥é•¿åº¦ã€‚<br><strong>ä¸»è¦å‚æ•°:</strong><br><code>reduction</code>ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸º none&#x2F;sum&#x2F;meanã€‚<br><code>blank</code>ï¼šblank labelã€‚<br><code>zero_infinity</code>ï¼šæ— ç©·å¤§çš„å€¼æˆ–æ¢¯åº¦å€¼ä¸º </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Target are to be padded</span></span><br><span class="line">T = <span class="number">50</span>      <span class="comment"># Input sequence length</span></span><br><span class="line">C = <span class="number">20</span>      <span class="comment"># Number of classes (including blank)</span></span><br><span class="line">N = <span class="number">16</span>      <span class="comment"># Batch size</span></span><br><span class="line">S = <span class="number">30</span>      <span class="comment"># Target sequence length of longest target in batch (padding length)</span></span><br><span class="line">S_min = <span class="number">10</span>  <span class="comment"># Minimum target length, for demonstration purposes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of input vectors, for *size = (T,N,C)</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(T, N, C).log_softmax(<span class="number">2</span>).detach().requires_grad_()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of targets (0 = blank, 1:C = classes)</span></span><br><span class="line">target = torch.randint(low=<span class="number">1</span>, high=C, size=(N, S), dtype=torch.long)</span><br><span class="line"></span><br><span class="line">input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)</span><br><span class="line">target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)</span><br><span class="line">ctc_loss = nn.CTCLoss()</span><br><span class="line">loss = ctc_loss(<span class="built_in">input</span>, target, input_lengths, target_lengths)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Target are to be un-padded</span></span><br><span class="line">T = <span class="number">50</span>      <span class="comment"># Input sequence length</span></span><br><span class="line">C = <span class="number">20</span>      <span class="comment"># Number of classes (including blank)</span></span><br><span class="line">N = <span class="number">16</span>      <span class="comment"># Batch size</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of input vectors, for *size = (T,N,C)</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(T, N, C).log_softmax(<span class="number">2</span>).detach().requires_grad_()</span><br><span class="line">input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random batch of targets (0 = blank, 1:C = classes)</span></span><br><span class="line">target_lengths = torch.randint(low=<span class="number">1</span>, high=T, size=(N,), dtype=torch.long)</span><br><span class="line">target = torch.randint(low=<span class="number">1</span>, high=C, size=(<span class="built_in">sum</span>(target_lengths),), dtype=torch.long)</span><br><span class="line">ctc_loss = nn.CTCLoss()</span><br><span class="line">loss = ctc_loss(<span class="built_in">input</span>, target, input_lengths, target_lengths)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;CTCLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º&#x27;</span>,loss)</span><br></pre></td></tr></table></figure>

<pre><code>CTCLossæŸå¤±å‡½æ•°çš„è®¡ç®—ç»“æœä¸º tensor(16.0885, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<h2 id="å…­ã€-ä¼˜åŒ–å™¨"><a href="#å…­ã€-ä¼˜åŒ–å™¨" class="headerlink" title="å…­ã€ ä¼˜åŒ–å™¨"></a>å…­ã€ ä¼˜åŒ–å™¨</h2><p>è¿™é‡Œä½¿ç”¨Adamä¼˜åŒ–å™¨</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<p>Pytorchå¾ˆäººæ€§åŒ–çš„ç»™æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªä¼˜åŒ–å™¨çš„åº“torch.optimï¼Œåœ¨è¿™é‡Œé¢æä¾›äº†åç§ä¼˜åŒ–å™¨ã€‚</p>
<ul>
<li>torch.optim.ASGD</li>
<li>torch.optim.Adadelta</li>
<li>torch.optim.Adagrad</li>
<li>torch.optim.Adam</li>
<li>torch.optim.AdamW</li>
<li>torch.optim.Adamax</li>
<li>torch.optim.LBFGS</li>
<li>torch.optim.RMSprop</li>
<li>torch.optim.Rprop</li>
<li>torch.optim.SGD</li>
<li>torch.optim.SparseAdam</li>
</ul>
<p>è€Œä»¥ä¸Šè¿™äº›ä¼˜åŒ–ç®—æ³•å‡ç»§æ‰¿äº<code>Optimizer</code>ï¼Œä¸‹é¢æˆ‘ä»¬å…ˆæ¥çœ‹ä¸‹æ‰€æœ‰ä¼˜åŒ–å™¨çš„åŸºç±»<code>Optimizer</code>ã€‚å®šä¹‰å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, params, defaults</span>):</span>        </span><br><span class="line">        self.defaults = defaults</span><br><span class="line">        self.state = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">        self.param_groups = []</span><br></pre></td></tr></table></figure>

<p><strong><code>Optimizer</code>æœ‰ä¸‰ä¸ªå±æ€§ï¼š</strong></p>
<ul>
<li><code>defaults</code>ï¼šå­˜å‚¨çš„æ˜¯ä¼˜åŒ–å™¨çš„è¶…å‚æ•°ï¼Œä¾‹å­å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>state</code>ï¼šå‚æ•°çš„ç¼“å­˜ï¼Œä¾‹å­å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">defaultdict(&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">dict</span>&#x27;&gt;, &#123;<span class="title">tensor</span>(<span class="params">[[ <span class="number">0.3864</span>, -<span class="number">0.0131</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">        [-<span class="number">0.1911</span>, -<span class="number">0.4511</span>]], requires_grad=<span class="literal">True</span></span>):</span> &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>param_groups</code>ï¼šç®¡ç†çš„å‚æ•°ç»„ï¼Œæ˜¯ä¸€ä¸ªlistï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé¡ºåºæ˜¯paramsï¼Œlrï¼Œmomentumï¼Œdampeningï¼Œweight_decayï¼Œnesterovï¼Œä¾‹å­å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">0.1022</span>, -<span class="number">1.6890</span>],[-<span class="number">1.5116</span>, -<span class="number">1.7846</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;]</span><br></pre></td></tr></table></figure>

<p><strong><code>Optimizer</code>è¿˜æœ‰ä»¥ä¸‹çš„æ–¹æ³•ï¼š</strong></p>
<ul>
<li><code>zero_grad()</code>ï¼šæ¸…ç©ºæ‰€ç®¡ç†å‚æ•°çš„æ¢¯åº¦ï¼ŒPyTorchçš„ç‰¹æ€§æ˜¯å¼ é‡çš„æ¢¯åº¦ä¸è‡ªåŠ¨æ¸…é›¶ï¼Œå› æ­¤æ¯æ¬¡åå‘ä¼ æ’­åéƒ½éœ€è¦æ¸…ç©ºæ¢¯åº¦ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zero_grad</span>(<span class="params">self, set_to_none: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> self.param_groups:</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> group[<span class="string">&#x27;params&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> p.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  <span class="comment">#æ¢¯åº¦ä¸ä¸ºç©º</span></span><br><span class="line">                <span class="keyword">if</span> set_to_none: </span><br><span class="line">                    p.grad = <span class="literal">None</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> p.grad.grad_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        p.grad.detach_()</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        p.grad.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">                    p.grad.zero_()<span class="comment"># æ¢¯åº¦è®¾ç½®ä¸º0</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>step()</code>ï¼šæ‰§è¡Œä¸€æ­¥æ¢¯åº¦æ›´æ–°ï¼Œå‚æ•°æ›´æ–°</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, closure</span>):</span> </span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>

<ul>
<li><code>add_param_group()</code>ï¼šæ·»åŠ å‚æ•°ç»„</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_param_group</span>(<span class="params">self, param_group</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(param_group, <span class="built_in">dict</span>), <span class="string">&quot;param group must be a dict&quot;</span></span><br><span class="line"><span class="comment"># æ£€æŸ¥ç±»å‹æ˜¯å¦ä¸ºtensor</span></span><br><span class="line">    params = param_group[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(params, torch.Tensor):</span><br><span class="line">        param_group[<span class="string">&#x27;params&#x27;</span>] = [params]</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(params, <span class="built_in">set</span>):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">&#x27;optimizer parameters need to be organized in ordered collections, but &#x27;</span></span><br><span class="line">                        <span class="string">&#x27;the ordering of tensors in sets will change between runs. Please use a list instead.&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        param_group[<span class="string">&#x27;params&#x27;</span>] = <span class="built_in">list</span>(params)</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> param_group[<span class="string">&#x27;params&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(param, torch.Tensor):</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&quot;optimizer can only optimize Tensors, &quot;</span></span><br><span class="line">                            <span class="string">&quot;but one of the params is &quot;</span> + torch.typename(param))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> param.is_leaf:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;can&#x27;t optimize a non-leaf Tensor&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name, default <span class="keyword">in</span> self.defaults.items():</span><br><span class="line">        <span class="keyword">if</span> default <span class="keyword">is</span> required <span class="keyword">and</span> name <span class="keyword">not</span> <span class="keyword">in</span> param_group:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;parameter group didn&#x27;t specify a value of required optimization parameter &quot;</span> +</span><br><span class="line">                             name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            param_group.setdefault(name, default)</span><br><span class="line"></span><br><span class="line">    params = param_group[<span class="string">&#x27;params&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(params) != <span class="built_in">len</span>(<span class="built_in">set</span>(params)):</span><br><span class="line">        warnings.warn(<span class="string">&quot;optimizer contains a parameter group with duplicate parameters; &quot;</span></span><br><span class="line">                      <span class="string">&quot;in future, this will cause an error; &quot;</span></span><br><span class="line">                      <span class="string">&quot;see github.com/pytorch/pytorch/issues/40967 for more information&quot;</span>, stacklevel=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># ä¸Šé¢å¥½åƒéƒ½åœ¨è¿›è¡Œä¸€äº›ç±»çš„æ£€æµ‹ï¼ŒæŠ¥Warningå’ŒError</span></span><br><span class="line">    param_set = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> self.param_groups:</span><br><span class="line">        param_set.update(<span class="built_in">set</span>(group[<span class="string">&#x27;params&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> param_set.isdisjoint(<span class="built_in">set</span>(param_group[<span class="string">&#x27;params&#x27;</span>])):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;some parameters appear in more than one parameter group&quot;</span>)</span><br><span class="line"><span class="comment"># æ·»åŠ å‚æ•°</span></span><br><span class="line">    self.param_groups.append(param_group)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>load_state_dict()</code> ï¼šåŠ è½½çŠ¶æ€å‚æ•°å­—å…¸ï¼Œå¯ä»¥ç”¨æ¥è¿›è¡Œæ¨¡å‹çš„æ–­ç‚¹ç»­è®­ç»ƒï¼Œç»§ç»­ä¸Šæ¬¡çš„å‚æ•°è¿›è¡Œè®­ç»ƒ</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_state_dict</span>(<span class="params">self, state_dict</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Loads the optimizer state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        state_dict (dict): optimizer state. Should be an object returned</span></span><br><span class="line"><span class="string">            from a call to :meth:`state_dict`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># deepcopy, to be consistent with module API</span></span><br><span class="line">    state_dict = deepcopy(state_dict)</span><br><span class="line">    <span class="comment"># Validate the state_dict</span></span><br><span class="line">    groups = self.param_groups</span><br><span class="line">    saved_groups = state_dict[<span class="string">&#x27;param_groups&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(groups) != <span class="built_in">len</span>(saved_groups):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;loaded state dict has a different number of &quot;</span></span><br><span class="line">                         <span class="string">&quot;parameter groups&quot;</span>)</span><br><span class="line">    param_lens = (<span class="built_in">len</span>(g[<span class="string">&#x27;params&#x27;</span>]) <span class="keyword">for</span> g <span class="keyword">in</span> groups)</span><br><span class="line">    saved_lens = (<span class="built_in">len</span>(g[<span class="string">&#x27;params&#x27;</span>]) <span class="keyword">for</span> g <span class="keyword">in</span> saved_groups)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">any</span>(p_len != s_len <span class="keyword">for</span> p_len, s_len <span class="keyword">in</span> <span class="built_in">zip</span>(param_lens, saved_lens)):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;loaded state dict contains a parameter group &quot;</span></span><br><span class="line">                         <span class="string">&quot;that doesn&#x27;t match the size of optimizer&#x27;s group&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update the state</span></span><br><span class="line">    id_map = &#123;old_id: p <span class="keyword">for</span> old_id, p <span class="keyword">in</span></span><br><span class="line">              <span class="built_in">zip</span>(chain.from_iterable((g[<span class="string">&#x27;params&#x27;</span>] <span class="keyword">for</span> g <span class="keyword">in</span> saved_groups)),</span><br><span class="line">                  chain.from_iterable((g[<span class="string">&#x27;params&#x27;</span>] <span class="keyword">for</span> g <span class="keyword">in</span> groups)))&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cast</span>(<span class="params">param, value</span>):</span></span><br><span class="line">        <span class="string">r&quot;&quot;&quot;Make a deep copy of value, casting all tensors to device of param.&quot;&quot;&quot;</span></span><br><span class="line">   		.....</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Copy state assigned to params (and cast tensors to appropriate types).</span></span><br><span class="line">    <span class="comment"># State that is not assigned to params is copied as is (needed for</span></span><br><span class="line">    <span class="comment"># backward compatibility).</span></span><br><span class="line">    state = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> state_dict[<span class="string">&#x27;state&#x27;</span>].items():</span><br><span class="line">        <span class="keyword">if</span> k <span class="keyword">in</span> id_map:</span><br><span class="line">            param = id_map[k]</span><br><span class="line">            state[param] = cast(param, v)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            state[k] = v</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update parameter groups, setting their &#x27;params&#x27; value</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_group</span>(<span class="params">group, new_group</span>):</span></span><br><span class="line">       ...</span><br><span class="line">    param_groups = [</span><br><span class="line">        update_group(g, ng) <span class="keyword">for</span> g, ng <span class="keyword">in</span> <span class="built_in">zip</span>(groups, saved_groups)]</span><br><span class="line">    self.__setstate__(&#123;<span class="string">&#x27;state&#x27;</span>: state, <span class="string">&#x27;param_groups&#x27;</span>: param_groups&#125;)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>state_dict()</code>ï¼šè·å–ä¼˜åŒ–å™¨å½“å‰çŠ¶æ€ä¿¡æ¯å­—å…¸</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Returns the state of the optimizer as a :class:`dict`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It contains two entries:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    * state - a dict holding current optimization state. Its content</span></span><br><span class="line"><span class="string">        differs between optimizer classes.</span></span><br><span class="line"><span class="string">    * param_groups - a dict containing all parameter groups</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Save order indices instead of Tensors</span></span><br><span class="line">    param_mappings = &#123;&#125;</span><br><span class="line">    start_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pack_group</span>(<span class="params">group</span>):</span></span><br><span class="line">		......</span><br><span class="line">    param_groups = [pack_group(g) <span class="keyword">for</span> g <span class="keyword">in</span> self.param_groups]</span><br><span class="line">    <span class="comment"># Remap state to use order indices as keys</span></span><br><span class="line">    packed_state = &#123;(param_mappings[<span class="built_in">id</span>(k)] <span class="keyword">if</span> <span class="built_in">isinstance</span>(k, torch.Tensor) <span class="keyword">else</span> k): v</span><br><span class="line">                    <span class="keyword">for</span> k, v <span class="keyword">in</span> self.state.items()&#125;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;state&#x27;</span>: packed_state,</span><br><span class="line">        <span class="string">&#x27;param_groups&#x27;</span>: param_groups,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="å®é™…æ“ä½œ"><a href="#å®é™…æ“ä½œ" class="headerlink" title="å®é™…æ“ä½œ"></a>å®é™…æ“ä½œ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®æƒé‡ï¼Œæœä»æ­£æ€åˆ†å¸ƒ  --&gt; 2 x 2</span></span><br><span class="line">weight = torch.randn((<span class="number">2</span>, <span class="number">2</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># è®¾ç½®æ¢¯åº¦ä¸ºå…¨1çŸ©é˜µ  --&gt; 2 x 2</span></span><br><span class="line">weight.grad = torch.ones((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># è¾“å‡ºç°æœ‰çš„weightå’Œdata</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The data of weight before step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.data))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The grad of weight before step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.grad))</span><br><span class="line"><span class="comment"># å®ä¾‹åŒ–ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = torch.optim.SGD([weight], lr=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment"># è¿›è¡Œä¸€æ­¥æ“ä½œ</span></span><br><span class="line">optimizer.step()</span><br><span class="line"><span class="comment"># æŸ¥çœ‹è¿›è¡Œä¸€æ­¥åçš„å€¼ï¼Œæ¢¯åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The data of weight after step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.data))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The grad of weight after step:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.grad))</span><br><span class="line"><span class="comment"># æƒé‡æ¸…é›¶</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"><span class="comment"># æ£€éªŒæƒé‡æ˜¯å¦ä¸º0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The grad of weight after optimizer.zero_grad():\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(weight.grad))</span><br><span class="line"><span class="comment"># è¾“å‡ºå‚æ•°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;optimizer.params_group is \n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups))</span><br><span class="line"><span class="comment"># æŸ¥çœ‹å‚æ•°ä½ç½®ï¼Œoptimizerå’Œweightçš„ä½ç½®ä¸€æ ·ï¼Œæˆ‘è§‰å¾—è¿™é‡Œå¯ä»¥å‚è€ƒPythonæ˜¯åŸºäºå€¼ç®¡ç†</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weight in optimizer:&#123;&#125;\nweight in weight:&#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(<span class="built_in">id</span>(optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;params&#x27;</span>][<span class="number">0</span>]), <span class="built_in">id</span>(weight)))</span><br><span class="line"><span class="comment"># æ·»åŠ å‚æ•°ï¼šweight2</span></span><br><span class="line">weight2 = torch.randn((<span class="number">3</span>, <span class="number">3</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">optimizer.add_param_group(&#123;<span class="string">&quot;params&quot;</span>: weight2, <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line"><span class="comment"># æŸ¥çœ‹ç°æœ‰çš„å‚æ•°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;optimizer.param_groups is\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups))</span><br><span class="line"><span class="comment"># æŸ¥çœ‹å½“å‰çŠ¶æ€ä¿¡æ¯</span></span><br><span class="line">opt_state_dict = optimizer.state_dict()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;state_dict before step:\n&quot;</span>, opt_state_dict)</span><br><span class="line"><span class="comment"># è¿›è¡Œ5æ¬¡stepæ“ä½œ</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    optimizer.step()</span><br><span class="line"><span class="comment"># è¾“å‡ºç°æœ‰çŠ¶æ€ä¿¡æ¯</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;state_dict after step:\n&quot;</span>, optimizer.state_dict())</span><br><span class="line"><span class="comment"># ä¿å­˜å‚æ•°ä¿¡æ¯</span></span><br><span class="line">torch.save(optimizer.state_dict(),os.path.join(<span class="string">r&quot;D:\pythonProject\Attention_Unet&quot;</span>, <span class="string">&quot;optimizer_state_dict.pkl&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;----------done-----------&quot;</span>)</span><br><span class="line"><span class="comment"># åŠ è½½å‚æ•°ä¿¡æ¯</span></span><br><span class="line">state_dict = torch.load(<span class="string">r&quot;D:\pythonProject\Attention_Unet\optimizer_state_dict.pkl&quot;</span>) <span class="comment"># éœ€è¦ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„è·¯å¾„</span></span><br><span class="line">optimizer.load_state_dict(state_dict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;load state_dict successfully\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(state_dict))</span><br><span class="line"><span class="comment"># è¾“å‡ºæœ€åå±æ€§ä¿¡æ¯</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.defaults))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.state))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(optimizer.param_groups))</span><br></pre></td></tr></table></figure>

<h2 id="è¾“å‡ºç»“æœ"><a href="#è¾“å‡ºç»“æœ" class="headerlink" title="è¾“å‡ºç»“æœ"></a>è¾“å‡ºç»“æœ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°å‰çš„æ•°æ®ï¼Œæ¢¯åº¦</span></span><br><span class="line">The data of weight before step:</span><br><span class="line">tensor([[-<span class="number">0.3077</span>, -<span class="number">0.1808</span>],</span><br><span class="line">        [-<span class="number">0.7462</span>, -<span class="number">1.5556</span>]])</span><br><span class="line">The grad of weight before step:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°åçš„æ•°æ®ï¼Œæ¢¯åº¦</span></span><br><span class="line">The data of weight after step:</span><br><span class="line">tensor([[-<span class="number">0.4077</span>, -<span class="number">0.2808</span>],</span><br><span class="line">        [-<span class="number">0.8462</span>, -<span class="number">1.6556</span>]])</span><br><span class="line">The grad of weight after step:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="comment"># è¿›è¡Œæ¢¯åº¦æ¸…é›¶çš„æ¢¯åº¦</span></span><br><span class="line">The grad of weight after optimizer.zero_grad():</span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"><span class="comment"># è¾“å‡ºä¿¡æ¯</span></span><br><span class="line">optimizer.params_group <span class="keyword">is</span> </span><br><span class="line">[&#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">0.4077</span>, -<span class="number">0.2808</span>],</span><br><span class="line">        [-<span class="number">0.8462</span>, -<span class="number">1.6556</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯æ˜äº†ä¼˜åŒ–å™¨çš„å’Œweightçš„å‚¨å­˜æ˜¯åœ¨ä¸€ä¸ªåœ°æ–¹ï¼ŒPythonåŸºäºå€¼ç®¡ç†</span></span><br><span class="line">weight <span class="keyword">in</span> optimizer:<span class="number">1841923407424</span></span><br><span class="line">weight <span class="keyword">in</span> weight:<span class="number">1841923407424</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># è¾“å‡ºå‚æ•°</span></span><br><span class="line">optimizer.param_groups <span class="keyword">is</span></span><br><span class="line">[&#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">0.4077</span>, -<span class="number">0.2808</span>],</span><br><span class="line">        [-<span class="number">0.8462</span>, -<span class="number">1.6556</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;, &#123;<span class="string">&#x27;params&#x27;</span>: [tensor([[ <span class="number">0.4539</span>, -<span class="number">2.1901</span>, -<span class="number">0.6662</span>],</span><br><span class="line">        [ <span class="number">0.6630</span>, -<span class="number">1.5178</span>, -<span class="number">0.8708</span>],</span><br><span class="line">        [-<span class="number">2.0222</span>,  <span class="number">1.4573</span>,  <span class="number">0.8657</span>]], requires_grad=<span class="literal">True</span>)], <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°å‰çš„å‚æ•°æŸ¥çœ‹ï¼Œç”¨state_dict</span></span><br><span class="line">state_dict before step:</span><br><span class="line"> &#123;<span class="string">&#x27;state&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])&#125;&#125;, <span class="string">&#x27;param_groups&#x27;</span>: [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">0</span>]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">1</span>]&#125;]&#125;</span><br><span class="line"><span class="comment"># è¿›è¡Œæ›´æ–°åçš„å‚æ•°æŸ¥çœ‹ï¼Œç”¨state_dict</span></span><br><span class="line">state_dict after step:</span><br><span class="line"> &#123;<span class="string">&#x27;state&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;, <span class="string">&#x27;param_groups&#x27;</span>: [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">0</span>]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">1</span>]&#125;]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># å­˜å‚¨ä¿¡æ¯å®Œæ¯•</span></span><br><span class="line">----------done-----------</span><br><span class="line"><span class="comment"># åŠ è½½å‚æ•°ä¿¡æ¯æˆåŠŸ</span></span><br><span class="line">load state_dict successfully</span><br><span class="line"><span class="comment"># åŠ è½½å‚æ•°ä¿¡æ¯</span></span><br><span class="line">&#123;<span class="string">&#x27;state&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;, <span class="string">&#x27;param_groups&#x27;</span>: [&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">0</span>]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [<span class="number">1</span>]&#125;]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># defaultsçš„å±æ€§è¾“å‡º</span></span><br><span class="line">&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># stateå±æ€§è¾“å‡º</span></span><br><span class="line">defaultdict(&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">dict</span>&#x27;&gt;, &#123;<span class="title">tensor</span>(<span class="params">[[-<span class="number">1.3031</span>, -<span class="number">1.1761</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">        [-<span class="number">1.7415</span>, -<span class="number">2.5510</span>]], requires_grad=<span class="literal">True</span></span>):</span> &#123;<span class="string">&#x27;momentum_buffer&#x27;</span>: tensor([[<span class="number">0.0052</span>, <span class="number">0.0052</span>],</span><br><span class="line">        [<span class="number">0.0052</span>, <span class="number">0.0052</span>]])&#125;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># param_groupså±æ€§è¾“å‡º</span></span><br><span class="line">[&#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">False</span>, <span class="string">&#x27;params&#x27;</span>: [tensor([[-<span class="number">1.3031</span>, -<span class="number">1.1761</span>],</span><br><span class="line">        [-<span class="number">1.7415</span>, -<span class="number">2.5510</span>]], requires_grad=<span class="literal">True</span>)]&#125;, &#123;<span class="string">&#x27;lr&#x27;</span>: <span class="number">0.0001</span>, <span class="string">&#x27;nesterov&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;dampening&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;params&#x27;</span>: [tensor([[ <span class="number">0.4539</span>, -<span class="number">2.1901</span>, -<span class="number">0.6662</span>],</span><br><span class="line">        [ <span class="number">0.6630</span>, -<span class="number">1.5178</span>, -<span class="number">0.8708</span>],</span><br><span class="line">        [-<span class="number">2.0222</span>,  <span class="number">1.4573</span>,  <span class="number">0.8657</span>]], requires_grad=<span class="literal">True</span>)]&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>æ³¨æ„ï¼š</strong></p>
<ol>
<li><p>æ¯ä¸ªä¼˜åŒ–å™¨éƒ½æ˜¯ä¸€ä¸ªç±»ï¼Œæˆ‘ä»¬ä¸€å®šè¦è¿›è¡Œå®ä¾‹åŒ–æ‰èƒ½ä½¿ç”¨ï¼Œæ¯”å¦‚ä¸‹æ–¹å®ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Moddule</span>):</span></span><br><span class="line">    Â·Â·Â·</span><br><span class="line">net = Net()</span><br><span class="line">optim = torch.optim.SGD(net.parameters(),lr=lr)</span><br><span class="line">optim.step()</span><br></pre></td></tr></table></figure>
</li>
<li><p>optimizeråœ¨ä¸€ä¸ªç¥ç»ç½‘ç»œçš„epochä¸­éœ€è¦å®ç°ä¸‹é¢ä¸¤ä¸ªæ­¥éª¤ï¼š</p>
<ol>
<li>æ¢¯åº¦ç½®é›¶</li>
<li>æ¢¯åº¦æ›´æ–°<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">1e-5</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH):</span><br><span class="line">	...</span><br><span class="line">	optimizer.zero_grad()  <span class="comment">#æ¢¯åº¦ç½®é›¶</span></span><br><span class="line">	loss = ...             <span class="comment">#è®¡ç®—loss</span></span><br><span class="line">	loss.backward()        <span class="comment">#BPåå‘ä¼ æ’­</span></span><br><span class="line">	optimizer.step()       <span class="comment">#æ¢¯åº¦æ›´æ–°</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>ç»™ç½‘ç»œä¸åŒçš„å±‚èµ‹äºˆä¸åŒçš„ä¼˜åŒ–å™¨å‚æ•°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"></span><br><span class="line">net = resnet18()</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([</span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>:net.fc.parameters()&#125;,<span class="comment">#fcçš„lrä½¿ç”¨é»˜è®¤çš„1e-5</span></span><br><span class="line">    &#123;<span class="string">&#x27;params&#x27;</span>:net.layer4[<span class="number">0</span>].conv1.parameters(),<span class="string">&#x27;lr&#x27;</span>:<span class="number">1e-2</span>&#125;],lr=<span class="number">1e-5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯ä»¥ä½¿ç”¨param_groupsæŸ¥çœ‹å±æ€§</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><p>ä¸ºäº†æ›´å¥½çš„äº†è§£ä¼˜åŒ–å™¨ï¼Œå¯¹PyTorchä¸­çš„ä¼˜åŒ–å™¨è¿›è¡Œäº†ä¸€ä¸ªå°æµ‹è¯•</p>
<p><strong>æ•°æ®ç”Ÿæˆ</strong>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line"><span class="comment"># å‡ç»´æ“ä½œ</span></span><br><span class="line">x = torch.unsqueeze(a, dim=<span class="number">1</span>)</span><br><span class="line">y = x.<span class="built_in">pow</span>(<span class="number">2</span>) + <span class="number">0.1</span> * torch.normal(torch.zeros(x.size()))</span><br></pre></td></tr></table></figure>

<p><strong>æ•°æ®åˆ†å¸ƒæ›²çº¿</strong>ï¼š<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.6.1.png"></p>
<p><strong>ç½‘ç»œç»“æ„</strong>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line">        self.predict = nn.Linear(<span class="number">20</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.hidden(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.predict(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ä¸‹é¢è¿™éƒ¨åˆ†æ˜¯æµ‹è¯•å›¾ï¼Œçºµåæ ‡ä»£è¡¨Lossï¼Œæ¨ªåæ ‡ä»£è¡¨çš„æ˜¯Stepï¼š<br><img src="https://datawhalechina.github.io/thorough-pytorch/_images/3.6.2.png"><br>åœ¨ä¸Šé¢çš„å›¾ç‰‡ä¸Šï¼Œæ›²çº¿ä¸‹é™çš„è¶‹åŠ¿å’Œå¯¹åº”çš„stepsä»£è¡¨äº†åœ¨è¿™è½®æ•°æ®ï¼Œæ¨¡å‹ä¸‹çš„æ”¶æ•›é€Ÿåº¦</p>
<p><strong>æ³¨æ„:</strong></p>
<p>ä¼˜åŒ–å™¨çš„é€‰æ‹©æ˜¯éœ€è¦æ ¹æ®æ¨¡å‹è¿›è¡Œæ”¹å˜çš„ï¼Œä¸å­˜åœ¨ç»å¯¹çš„å¥½åä¹‹åˆ†ï¼Œæˆ‘ä»¬éœ€è¦å¤šè¿›è¡Œä¸€äº›æµ‹è¯•ã€‚<br>åç»­ä¼šæ·»åŠ SparseAdamï¼ŒLBFGSè¿™ä¸¤ä¸ªä¼˜åŒ–å™¨çš„å¯è§†åŒ–ç»“æœ</p>
<h2 id="ä¸ƒã€-è®­ç»ƒä¸è¯„ä¼°"><a href="#ä¸ƒã€-è®­ç»ƒä¸è¯„ä¼°" class="headerlink" title="ä¸ƒã€ è®­ç»ƒä¸è¯„ä¼°"></a>ä¸ƒã€ è®­ç»ƒä¸è¯„ä¼°</h2><p>å…³æ³¨ä¸¤è€…çš„ä¸»è¦åŒºåˆ«ï¼š<br>æ¨¡å‹çŠ¶æ€è®¾ç½®<br>æ˜¯å¦éœ€è¦åˆå§‹åŒ–ä¼˜åŒ–å™¨<br>æ˜¯å¦éœ€è¦å°†lossä¼ å›åˆ°ç½‘ç»œ<br>æ˜¯å¦éœ€è¦æ¯æ­¥æ›´æ–°optimizer<br>æ­¤å¤–ï¼Œå¯¹äºæµ‹è¯•æˆ–éªŒè¯è¿‡ç¨‹ï¼Œå¯ä»¥è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        data, label = data.cuda(), label.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data) <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line">        loss.backward() <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">        optimizer.step() <span class="comment"># ä¼˜åŒ–å™¨æ›´æ–°æƒé‡</span></span><br><span class="line">        train_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    train_loss = train_loss/<span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss))</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val</span>(<span class="params">epoch</span>):</span>       </span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># æµ‹è¯•å’Œè®­ç»ƒä¸ä¸€æ ·</span></span><br><span class="line">    val_loss = <span class="number">0</span></span><br><span class="line">    gt_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment"># ä¸è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, label = data.cuda(), label.cuda()</span><br><span class="line">            output = model(data)</span><br><span class="line">            preds = torch.argmax(output, <span class="number">1</span>) <span class="comment"># å¾—åˆ°é¢„æµ‹çš„ç»“æœæ˜¯å“ªä¸€ç±»</span></span><br><span class="line">            gt_labels.append(label.cpu().data.numpy()) <span class="comment"># æ‹¼æ¥èµ·æ¥</span></span><br><span class="line">            pred_labels.append(preds.cpu().data.numpy())</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            val_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    val_loss = val_loss/<span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)</span><br><span class="line">    acc = np.<span class="built_in">sum</span>(gt_labels==pred_labels)/<span class="built_in">len</span>(pred_labels) <span class="comment"># preå’Œlabelç›¸ç­‰çš„æ¬¡æ•°é™¤ä¸Šæ€»æ•°</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tValidation Loss: &#123;:.6f&#125;, Accuracy: &#123;:6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, val_loss, acc))</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs+<span class="number">1</span>):</span><br><span class="line">    train(epoch)</span><br><span class="line">    val(epoch)</span><br></pre></td></tr></table></figure>
<p><img src="https://uploadfiles.nowcoder.com/images/20221012/799168342_1665568130565/D2B5CA33BD970F64A6301FA75AE2EB22"></p>
<h2 id="å…«ã€-å¯è§†åŒ–"><a href="#å…«ã€-å¯è§†åŒ–" class="headerlink" title="å…«ã€ å¯è§†åŒ–"></a>å…«ã€ å¯è§†åŒ–</h2><p>è§åç»­ä¸“é¢˜</p>
<h2 id="ä¹ã€-ä¿å­˜æ¨¡å‹"><a href="#ä¹ã€-ä¿å­˜æ¨¡å‹" class="headerlink" title="ä¹ã€ ä¿å­˜æ¨¡å‹"></a>ä¹ã€ ä¿å­˜æ¨¡å‹</h2><p>è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨torch.saveä¿å­˜æ¨¡å‹å‚æ•°æˆ–è€…æ•´ä¸ªæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜æ¨¡å‹:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">save_path = <span class="string">&quot;./FahionModel.pkl&quot;</span></span><br><span class="line">torch.save(model, save_path)</span><br></pre></td></tr></table></figure>
<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%B8%89%E7%AB%A0/3.4%20%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA.html">æ·±å…¥æµ…å‡ºPyTorch</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-10T06:43:54.000Z" title="2022/10/10 ä¸‹åˆ2:43:54">2022-10-10</time>å‘è¡¨</span><span class="level-item"><time dateTime="2022-10-16T12:31:05.794Z" title="2022/10/16 ä¸‹åˆ8:31:05">2022-10-16</time>æ›´æ–°</span><span class="level-item"><a class="link-muted" href="/categories/Pytorch/">Pytorch</a></span><span class="level-item">15 åˆ†é’Ÿè¯»å®Œ (å¤§çº¦2297ä¸ªå­—)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/10/pytorch-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">pytorch - åŸºç¡€çŸ¥è¯†</a></h1><div class="content"><p>ç”±äºå¼ é‡æ˜¯å¯¹æ•°æ®çš„æè¿°ï¼Œåœ¨ç¥ç»ç½‘ç»œä¸­é€šå¸¸å°†æ•°æ®ä»¥å¼ é‡çš„å½¢å¼è¡¨ç¤ºï¼Œå¦‚é›¶ç»´å¼ é‡è¡¨ç¤ºæ ‡é‡ï¼Œä¸€ç»´å¼ é‡è¡¨ç¤ºå‘é‡ï¼ŒäºŒç»´è¡¨ç¤ºçŸ©é˜µï¼Œä¸‰ç»´å¼ é‡è¡¨ç¤ºå›¾åƒï¼Œå››ç»´è¡¨ç¤ºè§†é¢‘ï¼Œè¿™ç« é¦–å…ˆä»‹ç»å¼ é‡ï¼Œç„¶åä»‹ç»å®ƒçš„è¿ç®—ï¼Œå†æ˜¯æ ¸å¿ƒåŒ…autogradè‡ªåŠ¨å¾®åˆ†ã€‚</p>
<h1 id="å¼ é‡"><a href="#å¼ é‡" class="headerlink" title="å¼ é‡"></a>å¼ é‡</h1><h2 id="å¼ é‡çš„ç®€ä»‹"><a href="#å¼ é‡çš„ç®€ä»‹" class="headerlink" title="å¼ é‡çš„ç®€ä»‹"></a>å¼ é‡çš„ç®€ä»‹</h2><p>pytorchçš„torch.Tensorå’ŒNumpyçš„å¤šç»´æ•°ç»„éå¸¸ç›¸ä¼¼ï¼Œç”±äºtensoræä¾›GPUçš„è‡ªåŠ¨æ±‚æ¢¯åº¦å’Œè®¡ç®—ï¼Œå®ƒæ›´é€‚åˆæ·±åº¦å­¦ä¹ ã€‚</p>
<ol>
<li><p>ç”¨dtypeæŒ‡å®šç±»å‹åˆ›å»ºtensorï¼Œdetypeæœ‰tensor.float&#x2F;longç­‰</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor(<span class="number">1</span>,dtype=torch.int8)</span><br></pre></td></tr></table></figure>
</li>
<li><p>ä½¿ç”¨æŒ‡å®šç±»å‹éšæœºåˆå§‹åŒ–</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.IntTensor(<span class="number">2</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>tensorå’Œnumpy array äº’ç›¸è½¬åŒ–ï¼Œtorch.tensoråˆ›å»ºçš„å¼ é‡æ˜¯ä¸å…±äº«å†…å­˜çš„ï¼Œä½†torch.from_numpy()å’Œtorch.as_tensor()ä»numpy arrayåˆ›å»ºå¾—åˆ°çš„å¼ é‡å’ŒåŸæ•°æ®æ˜¯å…±äº«å†…å­˜çš„ï¼Œä¿®æ”¹numpy arrayä¼šå¯¼è‡´å¯¹åº”tensorçš„æ”¹å˜</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">array = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">tensor = torch.tensor(array)</span><br><span class="line">array2tensor = torch.from_numpy(array)</span><br><span class="line">tensor2array = tensor.numpy()</span><br><span class="line"><span class="comment"># ä¿®æ”¹arrayï¼Œå¯¹åº”çš„tensorä¹Ÿä¼šæ”¹å˜</span></span><br><span class="line">array[<span class="number">0</span>,<span class="number">0</span>] = <span class="number">100</span></span><br><span class="line"><span class="built_in">print</span>(array2tensor)</span><br></pre></td></tr></table></figure></li>
<li><p>ä»å·²å­˜åœ¨çš„tensoråˆ›å»º</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line">x = x.new_ones(<span class="number">4</span>, <span class="number">3</span>, dtype=torch.double) </span><br><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªæ–°çš„å…¨1çŸ©é˜µtensorï¼Œè¿”å›çš„tensoré»˜è®¤å…·æœ‰ç›¸åŒçš„torch.dtypeå’Œtorch.device</span></span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># é‡ç½®æ•°æ®ç±»å‹</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># ç»“æœä¼šæœ‰ä¸€æ ·çš„size</span></span><br></pre></td></tr></table></figure></li>
<li><p>åˆ›å»ºtensorçš„å‡½æ•°<br>  åŸºç¡€æ„é€  torch.tensor([1,2,3,4])<br>  éšæœºåˆå§‹åŒ– torch.rand(2,3) [0,1)çš„å‡åŒ€åˆ†å¸ƒï¼Œ torch.randn(2,3) N(0,1)çš„æ­£æ€åˆ†å¸ƒï¼Œrandperm(10) éšæœºæ’åˆ—<br>  æ­£æ€åˆ†å¸ƒ torch.normal(2,3) å‡å€¼ä¸º2æ ‡å‡†å·®ä¸º3çš„æ­£æ€åˆ†å¸ƒ<br>  å…¨1çŸ©é˜µ torch.ones(2,3)<br>  å…¨0çŸ©é˜µ torch.zeros(2,3)<br>  å¯¹è§’å•ä½é˜µ torch.eye(2,3)<br>  æœ‰åºåºåˆ— torch.arange(2,10,2) ä»2åˆ°10ï¼Œæ­¥é•¿2<br>  å‡åˆ†åºåˆ— torch.linspace(2,10,2) ä»2åˆ°10ï¼Œå‡åˆ†æˆ2ä»½</p>
</li>
<li><p>æŸ¥çœ‹tensorçš„ç»´åº¦</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">k = torch.tensor(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(k.shape) </span><br><span class="line"><span class="built_in">print</span>(k.size())</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="å¼ é‡çš„æ“ä½œ"><a href="#å¼ é‡çš„æ“ä½œ" class="headerlink" title="å¼ é‡çš„æ“ä½œ"></a>å¼ é‡çš„æ“ä½œ</h2><ol>
<li><p>åŠ æ³•</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">k = torch.rand(<span class="number">2</span>, <span class="number">3</span>) </span><br><span class="line">l = torch.ones(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(k+l)</span><br><span class="line"></span><br><span class="line">torch.add(k,l)</span><br><span class="line"></span><br><span class="line">k.add(l) <span class="comment"># åŸå€¼ä¿®æ”¹</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ç´¢å¼•æ“ä½œ<br>ä¸åŸæ•°æ®å†…å­˜å…±äº«ï¼Œç”¨clone()ä¸ä¼šä¿®æ”¹</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># å–ç¬¬äºŒåˆ—</span></span><br><span class="line"><span class="built_in">print</span>(x[:, <span class="number">1</span>]) </span><br><span class="line"></span><br><span class="line">y = x[<span class="number">0</span>,:]</span><br><span class="line">y += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>, :]) <span class="comment"># æºtensorä¹Ÿè¢«æ”¹äº†äº†</span></span><br><span class="line"></span><br><span class="line">y -= <span class="number">1</span></span><br><span class="line">a = y.clone()</span><br><span class="line">a += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>, :])</span><br></pre></td></tr></table></figure>
</li>
<li><p>ç»´åº¦å˜æ¢</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">y += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>
<p>view()å…±äº«å†…å­˜ï¼Œä»…æ˜¯æ›´æ”¹äº†å¯¹å¼ é‡çš„è§‚å¯Ÿè§’åº¦ï¼Œè€Œreshape()ä¸å…±äº«å†…å­˜ï¼Œä½†åŸå§‹tensorå¦‚æœä¸è¿ç»­ï¼Œå®ƒä¼šè¿”å›åŸå€¼çš„copyï¼Œæ‰€ä»¥æ¨èå…ˆç”¨cloneåˆ›å»ºå‰¯æœ¬å†viewï¼Œç”¨cloneèƒ½è®°å½•åˆ°è®¡ç®—å›¾ä¸­ï¼Œæ¢¯åº¦å›ä¼ åˆ°å‰¯æœ¬æ—¶ä¹Ÿä¼šä¼ åˆ°æºtensor</p>
<p> æ‰©å±•&#x2F;å‹ç¼©tensor</p>
 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">o = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(o)</span><br><span class="line">r = o.unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br><span class="line"><span class="built_in">print</span>(r.shape)</span><br><span class="line"></span><br><span class="line">s = r.squeeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(s)</span><br><span class="line"><span class="built_in">print</span>(s.shape)</span><br></pre></td></tr></table></figure></li>
<li><p>å–å€¼æ“ä½œ</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.randn(<span class="number">1</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(x)) </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(x.item()))</span><br></pre></td></tr></table></figure>
<p>å…¶ä»–æ“ä½œè§<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/tensors.html">å®˜æ–¹æ–‡æ¡£</a></p>
</li>
</ol>
<h2 id="å¼ é‡çš„å¹¿æ’­æœºåˆ¶"><a href="#å¼ é‡çš„å¹¿æ’­æœºåˆ¶" class="headerlink" title="å¼ é‡çš„å¹¿æ’­æœºåˆ¶"></a>å¼ é‡çš„å¹¿æ’­æœºåˆ¶</h2><p>ä¸¤ä¸ªå½¢çŠ¶ï¥§åŒçš„TensoræŒ‰å…ƒç´ è¿ç®—æ—¶ï¼Œå¯èƒ½ä¼šè§¦å‘å¹¿æ’­(broadcasting)æœºåˆ¶ï¼šå…ˆé€‚å½“å¤åˆ¶å…ƒç´ ä½¿è¿™ä¸¤ä¸ªTensorå½¢çŠ¶ç›¸åŒåï¼Œå†æŒ‰å…ƒç´ è¿ç®—ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p = torch.arange(<span class="number">1</span>, <span class="number">3</span>).view(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(p)</span><br><span class="line">q = torch.arange(<span class="number">1</span>, <span class="number">4</span>).view(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(q)</span><br><span class="line"><span class="built_in">print</span>(p + q)</span><br></pre></td></tr></table></figure>

<h1 id="è‡ªåŠ¨æ±‚å¯¼"><a href="#è‡ªåŠ¨æ±‚å¯¼" class="headerlink" title="è‡ªåŠ¨æ±‚å¯¼"></a>è‡ªåŠ¨æ±‚å¯¼</h1><h2 id="Autograd"><a href="#Autograd" class="headerlink" title="Autograd"></a>Autograd</h2><p>å®ƒæ˜¯torch.tensorçš„æ ¸å¿ƒç±»ï¼Œè®¾ç½®å®ƒçš„å±æ€§requires_grad&#x3D;Trueæ¥è¿½è¸ªå¼ é‡ï¼Œå®Œæˆè®¡ç®—åè°ƒç”¨backward()æ¥è‡ªåŠ¨è®¡ç®—æ‰€æœ‰æ¢¯åº¦ï¼Œå¯¼æ•°ä¼šè‡ªåŠ¨ç´¯ç§¯åˆ°gradï¼Œç”±é“¾å¼æ³•åˆ™å¯ä»¥è®¡ç®—å¯¼æ•°ï¼Œtorch.autogradå°±æ˜¯è®¡ç®—é›…å¯æ¯”çŸ©é˜µä¹˜ç§¯çš„ã€‚</p>
<ul>
<li>requires_grad<br>å¦‚æœæ²¡æœ‰æŒ‡å®šçš„è¯ï¼Œé»˜è®¤è¾“å…¥çš„è¿™ä¸ªæ ‡å¿—æ˜¯ Falseã€‚</li>
<li>grad_fn<br>æ¯ä¸ªå¼ é‡éƒ½æœ‰ä¸€ä¸ªgrad_fnå±æ€§ï¼Œè¯¥å±æ€§å¼•ç”¨äº†åˆ›å»ºTensorè‡ªèº«çš„Function(é™¤éè¿™ä¸ªå¼ é‡æ˜¯ç”¨æˆ·æ‰‹åŠ¨åˆ›å»ºçš„ï¼Œå³è¿™ä¸ªå¼ é‡çš„grad_fnæ˜¯None)ã€‚Tensor å’Œ Function äº’ç›¸è¿æ¥ç”Ÿæˆäº†ä¸€ä¸ªæ— ç¯å›¾ (acyclic graph)ï¼Œå®ƒç¼–ç äº†å®Œæ•´çš„è®¡ç®—å†å²ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># ç¼ºå¤±æƒ…å†µä¸‹é»˜è®¤ requires_grad = False</span></span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">a.requires_grad_(<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(a.requires_grad)</span><br><span class="line">b = (a * a).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(b.grad_fn)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>ä¸‹é¢ä¸¾ä¸ªä¾‹å­è¯´æ˜æ¢¯åº¦è®¡ç®—è¿‡ç¨‹</p>
<ol>
<li>åˆ›å»ºä¸€ä¸ªå¼ é‡å¹¶è®¾ç½®requires_grad&#x3D;Trueç”¨æ¥è¿½è¸ªå…¶è®¡ç®—å†å²<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">y = x**<span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(y.grad_fn)</span><br><span class="line"></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"><span class="built_in">print</span>(z, out)</span><br></pre></td></tr></table></figure></li>
<li>ç°åœ¨å¼€å§‹è¿›è¡Œåå‘ä¼ æ’­ï¼Œå› ä¸ºoutæ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå› æ­¤out.backward()å’Œ out.backward(torch.tensor(1.)) ç­‰ä»·ã€‚ç”±äºgradåœ¨åå‘ä¼ æ’­æ˜¯ç´¯åŠ çš„ï¼Œæ‰€ä»¥åœ¨backwardä¹‹å‰è¦æ¸…é›¶.grad.data.zero_()ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">out.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å†æ¥åå‘ä¼ æ’­â¼€ä¸€æ¬¡ï¼Œæ³¨æ„gradæ˜¯ç´¯åŠ çš„</span></span><br><span class="line">out2 = x.<span class="built_in">sum</span>()</span><br><span class="line">out2.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">out3 = x.<span class="built_in">sum</span>()</span><br><span class="line">x.grad.data.zero_()</span><br><span class="line">out3.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>
é›…å¯æ¯”å‘é‡ç§¯ï¼Œ.data.norm()å®ƒå¯¹å¼ é‡yæ¯ä¸ªå…ƒç´ è¿›è¡Œå¹³æ–¹ï¼Œç„¶åå¯¹å®ƒä»¬æ±‚å’Œï¼Œæœ€åå–å¹³æ–¹æ ¹ï¼Œè¿™äº›æ“ä½œè®¡ç®—å°±æ˜¯æ‰€è°“çš„L2æˆ–æ¬§å‡ é‡Œå¾·èŒƒæ•°ã€‚<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span></span><br><span class="line">    i = i + <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>
å½“yä¸å†æ˜¯æ ‡é‡ï¼Œtorch.autogradä¸èƒ½ç›´æ¥è®¡ç®—å®Œæ•´çš„é›…å¯æ¯”çŸ©é˜µï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬åªæƒ³è¦é›…å¯æ¯”å‘é‡ç§¯ï¼Œåªéœ€å°†è¿™ä¸ªå‘é‡ä½œä¸ºå‚æ•°ä¼ ç»™backwardï¼š<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v)</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>
è‹¥ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œé˜»æ­¢autogradè·Ÿè¸ªè®¾ç½®.requires_grad&#x3D;Trueçš„å¼ é‡çš„å†å²è®°å½•<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x.requires_grad)</span><br><span class="line"><span class="built_in">print</span>((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="built_in">print</span>((x ** <span class="number">2</span>).requires_grad)</span><br></pre></td></tr></table></figure>
è‹¥æƒ³ä¿®æ”¹tensorçš„æ•°å€¼ï¼Œåˆï¥§å¸Œæœ›è¢«autogradè®°å½•(å³ï¥§ä¼šå½±å“åå‘ä¼ æ’­)ï¼Œ é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å¯¹tensor.dataè¿›ï¨ˆæ“ä½œ<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">1</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.data) <span class="comment"># è¿˜æ˜¯ä¸€ä¸ªtensor</span></span><br><span class="line"><span class="built_in">print</span>(x.data.requires_grad) <span class="comment"># ä½†æ˜¯å·²ç»æ˜¯ç‹¬ç«‹äºè®¡ç®—å›¾ä¹‹å¤–,è¿”å›false</span></span><br><span class="line"></span><br><span class="line">y = <span class="number">2</span> * x</span><br><span class="line">x.data *= <span class="number">100</span> <span class="comment"># åªæ”¹å˜äº†å€¼ï¼Œä¸ä¼šè®°å½•åœ¨è®¡ç®—å›¾ï¼Œæ‰€ä»¥ä¸ä¼šå½±å“æ¢¯åº¦ä¼ æ’­</span></span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x) <span class="comment"># æ›´æ”¹dataçš„å€¼ä¹Ÿä¼šå½±å“tensorçš„å€¼,xä¸º100</span></span><br><span class="line"><span class="built_in">print</span>(x.grad) <span class="comment"># ä¸ä¼šå—åˆ°å€¼æ”¹å˜çš„å½±å“</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="å¹¶è¡Œè®¡ç®—ç®€ä»‹"><a href="#å¹¶è¡Œè®¡ç®—ç®€ä»‹" class="headerlink" title="å¹¶è¡Œè®¡ç®—ç®€ä»‹"></a>å¹¶è¡Œè®¡ç®—ç®€ä»‹</h1><p>PyTorchå¯ä»¥åœ¨ç¼–å†™å®Œæ¨¡å‹ä¹‹åï¼Œè®©å¤šä¸ªGPUæ¥å‚ä¸è®­ç»ƒï¼Œå‡å°‘è®­ç»ƒæ—¶é—´ã€‚CUDAæ˜¯æˆ‘ä»¬ä½¿ç”¨GPUçš„æä¾›å•†â€”â€”NVIDIAæä¾›çš„GPUå¹¶è¡Œè®¡ç®—æ¡†æ¶ã€‚å¯¹äºGPUæœ¬èº«çš„ç¼–ç¨‹ï¼Œä½¿ç”¨çš„æ˜¯CUDAè¯­è¨€æ¥å®ç°çš„ã€‚è€Œpytorchç¼–å†™æ·±åº¦å­¦ä¹ ä»£ç ä½¿ç”¨çš„CUDAæ˜¯è¡¨ç¤ºå¼€å§‹è¦æ±‚æˆ‘ä»¬çš„æ¨¡å‹æˆ–è€…æ•°æ®å¼€å§‹ä½¿ç”¨GPUäº†ã€‚å½“æˆ‘ä»¬ä½¿ç”¨äº†.cuda()æ—¶ï¼Œå…¶åŠŸèƒ½æ˜¯è®©æˆ‘ä»¬çš„æ¨¡å‹æˆ–è€…æ•°æ®ä»CPUè¿ç§»åˆ°GPU(0)å½“ä¸­ï¼Œé€šè¿‡GPUå¼€å§‹è®¡ç®—ã€‚</p>
<p>æ³¨ï¼šæ•°æ®åœ¨GPUå’ŒCPUä¹‹é—´è¿›è¡Œä¼ é€’æ—¶ä¼šæ¯”è¾ƒè€—æ—¶ï¼Œæˆ‘ä»¬åº”å½“å°½é‡é¿å…æ•°æ®çš„åˆ‡æ¢ã€‚GPUè¿ç®—å¾ˆå¿«ï¼Œä½†æ˜¯åœ¨ä½¿ç”¨ç®€å•çš„æ“ä½œæ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å°½é‡ä½¿ç”¨CPUå»å®Œæˆã€‚å½“æˆ‘ä»¬çš„æœåŠ¡å™¨ä¸Šæœ‰å¤šä¸ªGPUï¼Œæˆ‘ä»¬åº”è¯¥æŒ‡æ˜æˆ‘ä»¬ä½¿ç”¨çš„GPUæ˜¯å“ªä¸€å—ï¼Œå¦‚æœæˆ‘ä»¬ä¸è®¾ç½®çš„è¯ï¼Œtensor.cuda()æ–¹æ³•ä¼šé»˜è®¤å°†tensorä¿å­˜åˆ°ç¬¬ä¸€å—GPUä¸Šï¼Œç­‰ä»·äºtensor.cuda(0)ï¼Œè¿™å°†ä¼šå¯¼è‡´çˆ†å‡ºout of memoryçš„é”™è¯¯ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹å¼ç»§ç»­è®¾ç½®ã€‚</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">#è®¾ç½®åœ¨æ–‡ä»¶æœ€å¼€å§‹éƒ¨åˆ†</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICE&quot;</span>] = <span class="string">&quot;2&quot;</span> <span class="comment"># è®¾ç½®é»˜è®¤çš„æ˜¾å¡</span></span><br><span class="line">CUDA_VISBLE_DEVICE=<span class="number">0</span>,<span class="number">1</span> python train.py <span class="comment"># ä½¿ç”¨0ï¼Œ1ä¸¤å—GPU</span></span><br></pre></td></tr></table></figure>

<p>å¸¸è§çš„å¹¶è¡Œæ–¹æ³•ï¼š</p>
<ul>
<li><p>ç½‘ç»œç»“æ„åˆ†å¸ƒåˆ°ä¸åŒçš„è®¾å¤‡ä¸­(Network partitioning)<br>å°†ä¸€ä¸ªæ¨¡å‹çš„å„ä¸ªéƒ¨åˆ†æ‹†åˆ†ï¼Œç„¶åå°†ä¸åŒçš„éƒ¨åˆ†æ”¾å…¥åˆ°GPUæ¥åšä¸åŒä»»åŠ¡çš„è®¡ç®—ã€‚è¿™é‡Œé‡åˆ°çš„é—®é¢˜å°±æ˜¯ï¼Œä¸åŒæ¨¡å‹ç»„ä»¶åœ¨ä¸åŒçš„GPUä¸Šæ—¶ï¼ŒGPUä¹‹é—´çš„ä¼ è¾“å°±å¾ˆé‡è¦ï¼Œå¯¹äºGPUä¹‹é—´çš„é€šä¿¡æ˜¯ä¸€ä¸ªè€ƒéªŒã€‚ä½†æ˜¯GPUçš„é€šä¿¡åœ¨è¿™ç§å¯†é›†ä»»åŠ¡ä¸­å¾ˆéš¾åŠåˆ°ï¼Œæ‰€ä»¥è¿™ä¸ªæ–¹å¼æ…¢æ…¢æ·¡å‡ºäº†è§†é‡ã€‚</p>
</li>
<li><p>åŒä¸€å±‚çš„ä»»åŠ¡åˆ†å¸ƒåˆ°ä¸åŒæ•°æ®ä¸­(Layer-wise partitioning)<br>åŒä¸€å±‚çš„æ¨¡å‹åšä¸€ä¸ªæ‹†åˆ†ï¼Œè®©ä¸åŒçš„GPUå»è®­ç»ƒåŒä¸€å±‚æ¨¡å‹çš„éƒ¨åˆ†ä»»åŠ¡ã€‚è¿™æ ·å¯ä»¥ä¿è¯åœ¨ä¸åŒç»„ä»¶ä¹‹é—´ä¼ è¾“çš„é—®é¢˜ï¼Œä½†æ˜¯åœ¨æˆ‘ä»¬éœ€è¦å¤§é‡çš„è®­ç»ƒï¼ŒåŒæ­¥ä»»åŠ¡åŠ é‡çš„æƒ…å†µä¸‹ï¼Œä¼šå‡ºç°å’Œç¬¬ä¸€ç§æ–¹å¼ä¸€æ ·çš„é—®é¢˜ã€‚</p>
</li>
<li><p>ä¸åŒçš„æ•°æ®åˆ†å¸ƒåˆ°ä¸åŒçš„è®¾å¤‡ä¸­ï¼Œæ‰§è¡Œç›¸åŒçš„ä»»åŠ¡(Data parallelism)<br>å®ƒçš„é€»è¾‘æ˜¯ï¼Œä¸å†æ‹†åˆ†æ¨¡å‹ï¼Œè®­ç»ƒçš„æ—¶å€™æ¨¡å‹éƒ½æ˜¯ä¸€æ•´ä¸ªæ¨¡å‹ã€‚ä½†æ˜¯æˆ‘å°†è¾“å…¥çš„æ•°æ®æ‹†åˆ†ã€‚æ‰€è°“çš„æ‹†åˆ†æ•°æ®å°±æ˜¯ï¼ŒåŒä¸€ä¸ªæ¨¡å‹åœ¨ä¸åŒGPUä¸­è®­ç»ƒä¸€éƒ¨åˆ†æ•°æ®ï¼Œç„¶åå†åˆ†åˆ«è®¡ç®—ä¸€éƒ¨åˆ†æ•°æ®ä¹‹åï¼Œåªéœ€è¦å°†è¾“å‡ºçš„æ•°æ®åšä¸€ä¸ªæ±‡æ€»ï¼Œç„¶åå†åä¼ ï¼Œè¿™ç§æ–¹å¼å¯ä»¥è§£å†³ä¹‹å‰æ¨¡å¼é‡åˆ°çš„é€šè®¯é—®é¢˜ï¼Œæ˜¯ç°åœ¨ä¸»æµæ–¹å¼ã€‚</p>
<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%BA%8C%E7%AB%A0/index.html">æ·±å…¥æµ…å‡ºPyTorch</a></p>
</li>
</ul>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="ğŸ"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">ğŸ</p><p class="is-size-6 is-block">DubistmeinAugenstern</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>WuHan,China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ–‡ç« </p><a href="/archives"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">åˆ†ç±»</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">æ ‡ç­¾</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Yang-Emily" target="_blank" rel="noopener">å…³æ³¨æˆ‘</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Yang-Emily"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/wuyangemily/"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Youtube" href="https://www.youtube.com/channel/UCSnojGpH9om-xzl-og2_AZQ/featured"><i class="fab fa-youtube"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="twitter" href="https://twitter.com/wuyangemily"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1047772929&amp;site=qq&amp;menu=yes"><i class="fab fa-qq"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">é“¾æ¥</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://leetcode-cn.com/u/wuyangemily/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Leetcode</span></span><span class="level-right"><span class="level-item tag">leetcode-cn.com</span></span></a></li><li><a class="level is-mobile" href="https://blog.csdn.net/qq_44729001" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">blog.csdn.net</span></span></a></li><li><a class="level is-mobile" href="https://www.kaggle.com/wuyangemily" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Kaggle</span></span><span class="level-right"><span class="level-item tag">www.kaggle.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">åˆ†ç±»</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Pytorch/"><span class="level-start"><span class="level-item">Pytorch</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E5%AD%A6/"><span class="level-start"><span class="level-item">æ•°å­¦</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">æœºå™¨å­¦ä¹ </span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9D%82/"><span class="level-start"><span class="level-item">æ‚</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">æ·±åº¦å­¦ä¹ </span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">æ·±åº¦å¼ºåŒ–å­¦ä¹ </span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">è‡ªç„¶è¯­è¨€å¤„ç†</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">è®ºæ–‡é˜…è¯»</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">æœ€æ–°æ–‡ç« </h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-23T06:43:54.000Z">2022-10-23</time></p><p class="title"><a href="/2022/10/23/pytorch-%E7%94%9F%E6%80%81%E9%83%A8%E7%BD%B2/">pytorch - ç”Ÿæ€å’Œéƒ¨ç½²</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-22T06:43:54.000Z">2022-10-22</time></p><p class="title"><a href="/2022/10/22/pytorch-%E5%8F%AF%E8%A7%86%E5%8C%96/">pytorch - å¯è§†åŒ–</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-20T06:43:54.000Z">2022-10-20</time></p><p class="title"><a href="/2022/10/20/pytorch-%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/">pytorch - è®­ç»ƒæŠ€å·§</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-16T06:43:54.000Z">2022-10-16</time></p><p class="title"><a href="/2022/10/16/pytorch-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89/">pytorch - æ¨¡å‹å®šä¹‰</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-12T06:43:54.000Z">2022-10-12</time></p><p class="title"><a href="/2022/10/12/pytorch-%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E5%92%8C%E5%AE%9E%E8%B7%B5/">pytorch - å„ä¸ªç»„ä»¶å’Œå®è·µ</a></p><p class="categories"><a href="/categories/Pytorch/">Pytorch</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">å½’æ¡£</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">åæœˆ 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">ä¹æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">å…«æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">å…­æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">ä¸‰æœˆ 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">åæœˆ 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/08/"><span class="level-start"><span class="level-item">å…«æœˆ 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">ä¸€æœˆ 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">æ ‡ç­¾</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DRL/"><span class="tag">DRL</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Draft/"><span class="tag">Draft</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Intelligence-Code/"><span class="tag">Intelligence Code</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">6</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="ğŸ&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 Yang</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Yang-Emily/Yang-Emily.github.io"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="å›åˆ°é¡¶ç«¯" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "æ­¤ç½‘ç«™ä½¿ç”¨Cookieæ¥æ”¹å–„æ‚¨çš„ä½“éªŒã€‚",
          dismiss: "çŸ¥é“äº†ï¼",
          allow: "å…è®¸ä½¿ç”¨Cookie",
          deny: "æ‹’ç»",
          link: "äº†è§£æ›´å¤š",
          policy: "Cookieæ”¿ç­–",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"æƒ³è¦æŸ¥æ‰¾ä»€ä¹ˆ...","untitled":"(æ— æ ‡é¢˜)","posts":"æ–‡ç« ","pages":"é¡µé¢","categories":"åˆ†ç±»","tags":"æ ‡ç­¾"});
        });</script></body></html>